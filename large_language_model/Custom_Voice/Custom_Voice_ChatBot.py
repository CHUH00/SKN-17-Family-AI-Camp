import os
from pathlib import Path
import tempfile
import time

import mimetypes, base64, streamlit as st, os
from audio_recorder_streamlit import audio_recorder
from dotenv import load_dotenv
from IPython.display import Audio, display

from openai import OpenAI
from TTS.api import TTS
from pydub import AudioSegment

# -----------------------------------------------------------
# ê¸°ë³¸ ì„¤ì • / ìŠ¤íƒ€ì¼
# -----------------------------------------------------------
st.set_page_config(
    page_title="í•™ìš°ë“¤ ë³´ì´ìŠ¤ ê¸°ë°˜ ê³ ë¯¼ ìƒë‹´ ì±—ë´‡",
    page_icon="ğŸ™ï¸",
    layout="wide",
)

st.markdown("""
<style>
@import url('https://fonts.googleapis.com/css2?family=Pretendard:wght@300;400;600;700&display=swap');
html, body, [class*="css"]  { font-family: 'Pretendard', system-ui, -apple-system, Segoe UI, Roboto, Helvetica, Arial, 'Apple SD Gothic Neo', 'Noto Sans KR', 'Malgun Gothic', sans-serif; }
.kicker { font-size: 14px; letter-spacing: .12em; text-transform: uppercase; opacity: .75; }
.hero-title { font-size: 28px; font-weight: 700; margin-top: 6px; }
.hero-sub { font-size: 15px; opacity: .85; margin-top: 4px; }
.chip { display: inline-block; padding: 6px 10px; border-radius: 999px; background: rgba(255,255,255,.06); border: 1px solid rgba(255,255,255,.08); margin-right: 8px; font-size: 12px; }
.msg-row { display: flex; gap: 12px; margin-bottom: 14px; }
.msg-user, .msg-assistant {
  max-width: 100%;
  border-radius: 14px; padding: 12px 14px; border: 1px solid rgba(255,255,255,.08);
  box-shadow: 0 6px 18px rgba(0,0,0,.25);
}
.msg-user { background: rgba(59,130,246,.10); }
.msg-assistant { background: rgba(16,185,129,.10); }
.avatar { width: 36px; height: 36px; border-radius: 999px; background: rgba(255,255,255,.12); display:flex; align-items:center; justify-content:center; }
.small { font-size: 12px; opacity: .8; }
.btn-row { display:flex; gap:10px; }
.spacer16 { height: 16px; }
.spacer8 { height: 8px; }
.audio-wrapper { border-radius: 12px; overflow: hidden; border:1px solid rgba(255,255,255,.08); }
hr.smooth { border: none; border-top: 1px solid rgba(255,255,255,.08); margin: 14px 0; }
</style>
""", unsafe_allow_html=True)

# -----------------------------------------------------------
# í™˜ê²½/ë¦¬ì†ŒìŠ¤ ë¡œë“œ
# -----------------------------------------------------------
load_dotenv()
OPENAI_API_KEY = os.getenv("OPENAI_API_KEY", "")

@st.cache_resource(show_spinner=False)
def get_openai():
    if not OPENAI_API_KEY:
        st.error("OPENAI_API_KEYê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤ (.env í™•ì¸).")
    return OpenAI(api_key=OPENAI_API_KEY)

@st.cache_resource(show_spinner=False)
def load_tts_model():
    # í„°ë¯¸ë„ì—ì„œ ì“°ë˜ XTTS v2
    return TTS(model_name="tts_models/multilingual/multi-dataset/xtts_v2")

client = get_openai()
tts = load_tts_model()

# -----------------------------------------------------------
# ìƒìˆ˜/ìœ í‹¸ (ì§§ì€ ë…¹ìŒ ë°©ì§€)
# -----------------------------------------------------------
MIN_REC_SECONDS = 0.30

def wav_duration_sec(path: Path) -> float:
    """WAV ê¸¸ì´ë¥¼ ì´ˆ ë‹¨ìœ„ë¡œ ë°˜í™˜ (ì—ëŸ¬ ì‹œ 0)"""
    try:
        seg = AudioSegment.from_file(path)
        return len(seg) / 1000.0
    except Exception:
        return 0.0

# -----------------------------------------------------------
# ìŠ¤í”¼ì»¤ ë ˆí¼ëŸ°ìŠ¤ í´ë”
# -----------------------------------------------------------
BASE_SPK_DIR = Path("dataset/wavs")
BASE_SPK_DIR.mkdir(parents=True, exist_ok=True)

def list_reference_wavs():
    if not BASE_SPK_DIR.exists():
        return []
    return sorted([p for p in BASE_SPK_DIR.glob("*.wav") if p.is_file()])

# -----------------------------------------------------------
# ìœ í‹¸: íŒŒì¼ ì €ì¥ / ASR / LLM / TTS / ìë™ì¬ìƒ
# -----------------------------------------------------------
def _save_audio_bytes_to_wav(audio_bytes: bytes, out_path: Path) -> Path:
    out_path = out_path.with_suffix(".wav")
    with open(out_path, "wb") as f:
        f.write(audio_bytes)
    return out_path

def transcribe_wav_with_openai(wav_path: Path) -> str:
    if wav_duration_sec(wav_path) < 0.10:
        raise ValueError("ë…¹ìŒì´ ë„ˆë¬´ ì§§ìŠµë‹ˆë‹¤. 0.3ì´ˆ ì´ìƒ ë§ì”€í•´ ì£¼ì„¸ìš”.")

    with open(wav_path, "rb") as f:
        transcript = client.audio.transcriptions.create(
            model="whisper-1",
            file=f,
            language="ko"
        )
    return transcript.text.strip()

def chat_reply(messages, temperature: float = 0.3) -> str:
    completion = client.chat.completions.create(
        model="gpt-4o-mini",
        temperature=temperature,
        messages=messages
    )
    return completion.choices[0].message.content.strip()

def synthesize_tts_ko(text: str, speaker_refs, out_path: Path):
    out_path = out_path.with_suffix(".wav")
    spk_ref_paths = [str(p) for p in speaker_refs] if speaker_refs else None
    tts.tts_to_file(
        text=text,
        file_path=str(out_path),
        speaker_wav=spk_ref_paths,
        language="ko"
    )
    return out_path

def autoplay_audio(file_path: str, hidden: bool = True):
    if not os.path.exists(file_path):
        st.error(f"ì˜¤ë””ì˜¤ íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {file_path}")
        return

    mime, _ = mimetypes.guess_type(file_path)
    if mime is None:
        ext = os.path.splitext(file_path)[1].lower()
        mime = "audio/mpeg" if ext == ".mp3" else "audio/wav" if ext in (".wav", ".wave") else "audio/mp4"

    with open(file_path, "rb") as f:
        b64 = base64.b64encode(f.read()).decode()

    hidden_attr = " hidden" if hidden else ""
    html = f"""
    <audio id="intro-audio" autoplay muted playsinline{hidden_attr}>
        <source src="data:{mime};base64,{b64}" type="{mime}">
    </audio>
    <script>
      const a = document.getElementById('intro-audio');
      // iOS/Chrome ì •ì±…: ì²« ì œìŠ¤ì²˜ ë•Œ ì†Œë¦¬ ì¼œê³  ì¬ìƒ ì‹œë„
      function resume() {{
        try {{
          a.muted = false;
          if (a.paused) a.play().catch(()=>{{}});
        }} catch(_) {{}}
        window.removeEventListener('pointerdown', resume);
        window.removeEventListener('keydown', resume);
        window.removeEventListener('touchstart', resume);
      }}
      window.addEventListener('pointerdown', resume, {{once:true}});
      window.addEventListener('keydown', resume, {{once:true}});
      window.addEventListener('touchstart', resume, {{once:true}});
    </script>
    """
    st.markdown(html, unsafe_allow_html=True)

def autoplay_audio(file_path, hidden=False):
    """
    ì˜¤ë””ì˜¤ íŒŒì¼ì„ ìë™ ì¬ìƒí•˜ëŠ” í•¨ìˆ˜.
    - file_path: ë¬¸ìì—´(ë‹¨ì¼ íŒŒì¼) ë˜ëŠ” ë¦¬ìŠ¤íŠ¸(ì—¬ëŸ¬ íŒŒì¼)
    - hidden: Trueë©´ í”Œë ˆì´ì–´ ìˆ¨ê¹€, Falseë©´ í”Œë ˆì´ì–´ í‘œì‹œ
    """
    
    def _play_single(f):
        if not os.path.exists(f):
            raise FileNotFoundError(f"{f} not found.")
        audio = Audio(f, autoplay=True)
        display(audio)
    
    if isinstance(file_path, list):
        for f in file_path:
            _play_single(f)
    else:
        _play_single(file_path)

# -----------------------------------------------------------
# ì„¸ì…˜ ìŠ¤í…Œì´íŠ¸
# -----------------------------------------------------------
if "messages" not in st.session_state:
    st.session_state.messages = [
        {"role": "system", "content": "ë„ˆëŠ” ì¹œì ˆí•œ ê³ ë¯¼ ìƒë‹´ê°€ì•¼. í•œêµ­ì–´ë¡œ ê³µê°í•˜ê³  êµ¬ì²´ì ì¸ ì¡°ì–¸ì„ ì œê³µí•´."}
    ]
if "temperature" not in st.session_state:
    st.session_state.temperature = 0.3
if "last_user_audio" not in st.session_state:
    st.session_state.last_user_audio = None
if "autoplay" not in st.session_state:
    st.session_state.autoplay = True

# -----------------------------------------------------------
# í—¤ë” / ì¸íŠ¸ë¡œ
# -----------------------------------------------------------
with st.container():
    st.markdown('<div class="kicker">Intro</div>', unsafe_allow_html=True)
    st.markdown('<div class="hero-title">í•™ìš°ë“¤ ë³´ì´ìŠ¤ ë°ì´í„° ê¸°ë°˜ ê³ ë¯¼ ìƒë‹´ ì±—ë´‡</div>', unsafe_allow_html=True)
    st.markdown('<div class="hero-sub">ë°ì´í„° ì¶œì²˜ â€” ì •ì˜ì¤‘ë‹˜, ìµœë™í˜„ë‹˜ ëª©ì†Œë¦¬</div>', unsafe_allow_html=True)
    st.markdown('<div class="spacer8"></div>', unsafe_allow_html=True)
    st.markdown('<span class="chip">ğŸ™ï¸ ë§ˆì´í¬ë¡œ ê³ ë¯¼ì„ ë§í•´ë³´ì„¸ìš”</span> <span class="chip">ğŸ§  LLM ì‘ë‹µ</span> <span class="chip">ğŸ”Š ë³´ì´ìŠ¤ ì‘ë‹µ(ìë™ ì¬ìƒ)</span>', unsafe_allow_html=True)
    st.markdown("</div>", unsafe_allow_html=True)
            
        
st.markdown('<div class="spacer16"></div>', unsafe_allow_html=True)

# -----------------------------------------------------------
# ì‚¬ì´ë“œë°”: ì„¤ì •
# -----------------------------------------------------------
with st.sidebar:
    st.header("âš™ï¸ ì„¤ì •")
    st.session_state.temperature = st.slider("ì°½ì˜ì„± (temperature)", 0.0, 1.5, st.session_state.temperature, 0.1)

    ref_list = list_reference_wavs()
    if ref_list:
        ref_labels = [p.name for p in ref_list]
        sel = st.multiselect("ìŠ¤í”¼ì»¤ ë ˆí¼ëŸ°ìŠ¤(.wav)", ref_labels, default=ref_labels[:1])
        speaker_refs = [p for p in ref_list if p.name in sel]
    else:
        st.info("dataset/wavs í´ë”ì— í™”ì ë ˆí¼ëŸ°ìŠ¤ .wavë¥¼ ë„£ìœ¼ë©´ ë³´ì´ìŠ¤ê°€ ë” ìì—°ìŠ¤ëŸ½ìŠµë‹ˆë‹¤.")
        speaker_refs = []

    st.toggle("ğŸ”Š ë‹µë³€ ìë™ ì¬ìƒ", value=st.session_state.autoplay, key="autoplay")

    st.markdown("---")
    if st.button("ğŸ—‘ï¸ ëŒ€í™” ì´ˆê¸°í™”"):
        st.session_state.messages = [
            {"role": "system", "content": "ë„ˆëŠ” ì¹œì ˆí•œ ê³ ë¯¼ ìƒë‹´ê°€ì•¼. í•œêµ­ì–´ë¡œ ê³µê°í•˜ê³  êµ¬ì²´ì ì¸ ì¡°ì–¸ì„ ì œê³µí•´."}
        ]
        st.rerun()

# -----------------------------------------------------------
# ë©”ì¸: ë…¹ìŒ â†’ í…ìŠ¤íŠ¸ â†’ ì‘ë‹µ â†’ TTS(ìë™ ì¬ìƒ)
# -----------------------------------------------------------
col_left, col_right = st.columns([1.1, 1])

with col_left:
    st.subheader("ğŸ§ ë…¹ìŒ")
    st.caption("ë²„íŠ¼ì„ ëˆ„ë¥´ê³  ê³ ë¯¼ì„ ë§í•˜ì„¸ìš”. ë§ì´ ëë‚˜ë©´ ë²„íŠ¼ì„ ë‹¤ì‹œ ëˆŒëŸ¬ ë…¹ìŒì„ ì¢…ë£Œí•©ë‹ˆë‹¤.")
    audio_bytes = audio_recorder(
        pause_threshold=1.0,
        sample_rate=44100,
        text="",
        icon_size="2x",
        recording_color="#22c55e",
        neutral_color="#374151"
    )

    if audio_bytes:
        if len(audio_bytes) < 4000:
            st.warning("ë…¹ìŒì´ ë„ˆë¬´ ì§§ì•„ìš”. ìµœì†Œ 0.3ì´ˆ ì´ìƒ ë§í•´ì£¼ì„¸ìš”.")
            st.stop()

        tmp_wav_path = Path(tempfile.gettempdir()) / f"user_rec_{int(time.time())}.wav"
        _save_audio_bytes_to_wav(audio_bytes, tmp_wav_path)

        st.session_state.last_user_audio = str(tmp_wav_path)

        try:
            with st.spinner("â³ ìŒì„± â†’ í…ìŠ¤íŠ¸ ë³€í™˜ ì¤‘..."):
                user_input = transcribe_wav_with_openai(tmp_wav_path)
        except Exception as e:
            st.error(f"ìŒì„± ì¸ì‹ ì¤‘ ì˜¤ë¥˜: {e}")
            st.stop()

        with st.container():
            st.markdown("**ë‚˜:**")
            st.write(user_input)
            st.markdown('<div class="audio-wrapper">', unsafe_allow_html=True)
            st.audio(audio_bytes, format="audio/wav")
            st.markdown('</div>', unsafe_allow_html=True)
            st.markdown('</div>', unsafe_allow_html=True)

        st.session_state.messages.append({"role": "user", "content": user_input})

with col_right:
    st.subheader("ğŸ’¬ ëŒ€í™”")
    hist = [m for m in st.session_state.messages if m["role"] in ("user", "assistant")]
    for m in hist:
        if m["role"] == "user":
            st.markdown('<div class="msg-row">', unsafe_allow_html=True)
            st.markdown('<div class="avatar">ğŸ§‘</div>', unsafe_allow_html=True)
            st.markdown(f'<div class="msg-user">{m["content"]}</div>', unsafe_allow_html=True)
            st.markdown('</div>', unsafe_allow_html=True)
        else:
            st.markdown('<div class="msg-row">', unsafe_allow_html=True)
            st.markdown('<div class="avatar">ğŸ¤–</div>', unsafe_allow_html=True)
            st.markdown(f'<div class="msg-assistant">{m["content"]}</div>', unsafe_allow_html=True)
            st.markdown('</div>', unsafe_allow_html=True)

    if 'audio_bytes' in locals() and audio_bytes:
        with st.spinner("ğŸ§  ìƒê° ì¤‘..."):
            assistant_text = chat_reply(st.session_state.messages, temperature=st.session_state.temperature)

        st.session_state.messages.append({"role": "assistant", "content": assistant_text})

        with st.spinner("ğŸ”Š ë³´ì´ìŠ¤ ìƒì„± ì¤‘..."):
            out_path = Path(tempfile.gettempdir()) / f"assistant_{int(time.time())}.wav"
            synthesize_tts_ko(assistant_text, speaker_refs, out_path)
            out_path_str = str(out_path)

        st.markdown("**ğŸ§”ğŸ»â€â™‚ï¸ ì •ì˜ì¤‘(ë³´ì´ìŠ¤):**")
        st.write(assistant_text)

        if st.session_state.autoplay:
            autoplay_audio(out_path_str)

        st.markdown('<div class="audio-wrapper">', unsafe_allow_html=True)
        st.audio(out_path_str)
        st.markdown('</div>', unsafe_allow_html=True)
        st.markdown('</div>', unsafe_allow_html=True)
