{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0c7a4e2c",
   "metadata": {},
   "source": [
    "# DPO (Direct Preference Optimization)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6bb451f7",
   "metadata": {},
   "source": [
    "### 0. 환경 설정"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0fcafcb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "!python -m pip install --upgrade pip\n",
    "!pip install typing_extensions==4.7.1 --upgrade\n",
    "!pip install transformers peft datasets bitsandbytes accelerate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2dba8b06",
   "metadata": {},
   "outputs": [],
   "source": [
    "from huggingface_hub import login\n",
    "import os\n",
    "import torch\n",
    "\n",
    "login(token=\"hf_xxx\")\n",
    "\n",
    "os.environ[\"WANDB_DISABLED\"] = \"true\"\n",
    "os.environ[\"PYTORCH_CUDA_ALLOC_CONF\"] = \"expandable_segments:True\"\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "486bfff0",
   "metadata": {},
   "source": [
    "### 1. 모델 로드"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a955cdc",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = \"Bllossom/llama-3.2-Korean-Bllossom-3B\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "814585cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import BitsAndBytesConfig\n",
    "\n",
    "bnb_config = BitsAndBytesConfig(\n",
    "    load_in_4bit=True,\n",
    "    bnb_4bit_quant_type=\"nf4\",\n",
    "    bnb_4bit_use_double_quant=True,\n",
    "    bnb_4bit_compute_dtype=torch.bfloat16\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d8c3246",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
    "\n",
    "model = AutoModelForCausalLM.from_pretrained(\n",
    "    model_name,\n",
    "    quantization_config=bnb_config,\n",
    "    torch_dtype=torch.bfloat16,\n",
    "    device_map=\"auto\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "459b0231",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "\n",
    "if tokenizer.pad_token is None:\n",
    "    tokenizer.pad_token = tokenizer.eos_token"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a6528ad",
   "metadata": {},
   "source": [
    "### 2. 학습 준비"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19cfd15d",
   "metadata": {},
   "source": [
    "##### (1) 모델 준비"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6d7a0d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from peft import LoraConfig\n",
    "\n",
    "lora_config = LoraConfig(\n",
    "    r=8,\n",
    "    lora_alpha=32,\n",
    "    target_modules=[\"q_proj\", \"k_proj\", \"v_proj\", \"o_proj\", \"gate_proj\", \"down_proj\", \"up_proj\"],\n",
    "    bias=\"none\",\n",
    "    task_type=\"CAUSAL_LM\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "049ad893",
   "metadata": {},
   "outputs": [],
   "source": [
    "from peft import prepare_model_for_kbit_training, get_peft_model\n",
    "\n",
    "model = prepare_model_for_kbit_training(model)\n",
    "model = get_peft_model(model, lora_config)\n",
    "\n",
    "model.print_trainable_parameters()\n",
    "model.train()\n",
    "model.gradient_checkpointing_enable()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29e3af5a",
   "metadata": {},
   "source": [
    "##### (2) 데이터 준비"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15742b08",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset\n",
    "\n",
    "dataset = load_dataset('mncai/orca_dpo_pairs_ko')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "962dd12f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 데이터 전처리 함수 정의\n",
    "def preprocess_text(sample):\n",
    "    input_enc = tokenizer(sample[\"question\"], padding=\"max_length\", max_length=256, truncation=True)\n",
    "    preferred_enc = tokenizer(sample[\"chosen\"], padding=\"max_length\", max_length=256, truncation=True)\n",
    "    despreferred_enc = tokenizer(sample[\"rejected\"], padding=\"max_length\", max_length=256, truncation=True)\n",
    "\n",
    "    return {\n",
    "        \"input_ids\": input_enc[\"input_ids\"],\n",
    "        \"attention_mask\": input_enc[\"attention_mask\"],\n",
    "        \"preferred_ids\": preferred_enc[\"input_ids\"],\n",
    "        \"despreferred_ids\": despreferred_enc[\"input_ids\"]\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c36b9f03",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenized_dataset = dataset[\"train\"].map(\n",
    "    preprocess_text,\n",
    "    remove_columns=[\"id\", \"system\", \"question\", \"chosen\", \"rejected\"]\n",
    ")\n",
    "\n",
    "tokenized_dataset.set_format(type=\"torch\", columns=[\"input_ids\", \"attention_mask\", \"preferred_ids\", \"despreferred_ids\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26009570",
   "metadata": {},
   "outputs": [],
   "source": [
    "def collate_fn(batch):\n",
    "    input_ids = torch.stack([item[\"input_ids\"].clone().detach() for item in batch])\n",
    "    attention_mask = torch.stack([item[\"attention_mask\"].clone().detach() for item in batch])\n",
    "    \n",
    "    max_length = max(max(len(item['preferred_ids']) for item in batch), 1)\n",
    "\n",
    "    preferred_ids = torch.stack([\n",
    "        torch.tensor(\n",
    "            item[\"preferred_ids\"].tolist() + [tokenizer.pad_token_id] * (max_length - len(item['preferred_ids'])),\n",
    "            dtype=torch.long\n",
    "        ) if isinstance(item[\"preferred_ids\"], torch.Tensor) else\n",
    "        torch.tensor(\n",
    "            item[\"preferred_ids\"] + [tokenizer.pad_token_id] * (max_length - len(item[\"preferred_ids\"])),\n",
    "            dtype=torch.long\n",
    "        )\n",
    "        for item in batch\n",
    "    ]).clone().detach()\n",
    "\n",
    "    despreferred_ids = torch.stack([\n",
    "        torch.tensor(\n",
    "            item[\"despreferred_ids\"].tolist() + [tokenizer.pad_token_id] * (max_length - len(item['despreferred_ids'])),\n",
    "            dtype=torch.long\n",
    "        ) if isinstance(item[\"despreferred_ids\"], torch.Tensor) else\n",
    "        torch.tensor(\n",
    "            item[\"despreferred_ids\"] + [tokenizer.pad_token_id] * (max_length - len(item[\"despreferred_ids\"])),\n",
    "            dtype=torch.long\n",
    "        )\n",
    "        for item in batch\n",
    "    ]).clone().detach()\n",
    "\n",
    "    return {\n",
    "        \"input_ids\": input_ids,\n",
    "        \"attention_mask\": attention_mask,\n",
    "        \"preferred_ids\": preferred_ids,\n",
    "        \"despreferred_ids\": despreferred_ids\n",
    "    }"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35a2b98d",
   "metadata": {},
   "source": [
    "##### (3) Trainer 준비 및 train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "080af912",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import Trainer\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class DTOTrainer(Trainer):\n",
    "    def compute_loss(self, model, inputs, beta=0.1, *args, **kwargs):\n",
    "        input_ids = inputs[\"input_ids\"].to(model.device)\n",
    "        attention_mask = inputs[\"attention_mask\"].to(model.device)\n",
    "        preferred_ids = inputs[\"preferred_ids\"].to(model.device)\n",
    "        despreferred_ids = inputs[\"despreferred_ids\"].to(model.device)\n",
    "\n",
    "        preferred_outputs = model(input_ids=input_ids, attention_mask=attention_mask, labels=preferred_ids)\n",
    "        despreferred_outputs = model(input_ids=input_ids, attention_mask=attention_mask, labels=despreferred_ids)\n",
    "        \n",
    "        preferred_loss = preferred_outputs.loss\n",
    "        despreferred_loss = despreferred_outputs.loss\n",
    "\n",
    "        loss = -F.logsigmoid(beta * (despreferred_loss - preferred_loss)).mean()\n",
    "        return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0548919a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import TrainingArguments\n",
    "\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=\"./dpo_llama3_korean\",\n",
    "    per_device_train_batch_size=1,\n",
    "    gradient_accumulation_steps=16,\n",
    "    learning_rate=1e-4,\n",
    "    num_train_epochs=3,\n",
    "    save_total_limit=2,\n",
    "    save_strategy=\"steps\",\n",
    "    save_steps=200,\n",
    "    logging_steps=50,\n",
    "    remove_unused_columns=False,\n",
    "    fp16=True,\n",
    "    optim=\"adamw_bnb_8bit\",\n",
    "    max_grad_norm=0    \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0c01480",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer = DTOTrainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=tokenized_dataset,\n",
    "    data_collator=collate_fn\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e90f9a73",
   "metadata": {},
   "source": [
    "### 3. 학습"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "922bd531",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.train()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "083914d5",
   "metadata": {},
   "source": [
    "### 4. 학습된 모델 응답 생성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ecccf7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from peft import PeftModel\n",
    "\n",
    "checkpoint_path = \"./dpo_llama3_korean/checkpoint-xxx\"\n",
    "\n",
    "model = PeftModel.from_pretrained(model, checkpoint_path)\n",
    "model.eval()\n",
    "\n",
    "sample_data = dataset[\"train\"].select(range(5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5924f9ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_response(question):\n",
    "    inputs = tokenizer(question, return_tensors=\"pt\", padding=True, truncation=True, max_length=256).to(model.device)\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        output_ids = model.generate(\n",
    "            input_ids=inputs[\"input_ids\"],\n",
    "            attention_mask=inputs[\"attention_mask\"],\n",
    "            max_length=256,\n",
    "            temperature=0.7,\n",
    "            top_p=0.9,\n",
    "            do_sample=True\n",
    "        )\n",
    "        \n",
    "    return tokenizer.decode(output_ids[0], skip_special_tokens=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afdecf8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, example in enumerate(sample_data):\n",
    "    question = example[\"question\"]\n",
    "    preferred_answer = example[\"chosen\"]\n",
    "\n",
    "    generated_reseponse = generate_response(question)\n",
    "\n",
    "    print(f\"{i}번째 질문: {question}\")\n",
    "    print(f\"정답 (선호 응답): {preferred_answer}\")\n",
    "    print(f\"실제 모델 응답: {generated_reseponse}\")\n",
    "    print(\"=\" * 100)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "llm_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
