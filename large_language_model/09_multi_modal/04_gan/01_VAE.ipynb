{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GkR4hlrmciNq"
      },
      "source": [
        "# VAE (Variational AutoEncoder)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 1. 데이터 로드 및 설정"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "Ii2hZRtrcQ7D"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "\n",
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "s6c6V_jpdfNz",
        "outputId": "0162d5da-bfb5-47d5-d484-7043688d74d7"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 9.91M/9.91M [00:00<00:00, 16.3MB/s]\n",
            "100%|██████████| 28.9k/28.9k [00:00<00:00, 482kB/s]\n",
            "100%|██████████| 1.65M/1.65M [00:00<00:00, 4.48MB/s]\n",
            "100%|██████████| 4.54k/4.54k [00:00<00:00, 7.73MB/s]\n"
          ]
        }
      ],
      "source": [
        "import torchvision.datasets as datasets\n",
        "from torchvision import transforms\n",
        "from torch.utils.data import DataLoader\n",
        "\n",
        "dataset = datasets.MNIST(root='dataset/', train=True, transform=transforms.ToTensor(), download=True)\n",
        "train_loader = DataLoader(dataset=dataset, batch_size=32, shuffle=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 2. 모델 생성"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "qqYzj1EOeb5v"
      },
      "outputs": [],
      "source": [
        "import torch.nn as nn\n",
        "\n",
        "class VAE(nn.Module):\n",
        "  def __init__(self, input_dim, hidden_dim=200, z_dim=20):\n",
        "    super(VAE, self).__init__()\n",
        "\n",
        "    self.img2hid = nn.Linear(input_dim, hidden_dim)\n",
        "    self.hid2mu = nn.Linear(hidden_dim, z_dim)\n",
        "    self.hid2sigma = nn.Linear(hidden_dim, z_dim)\n",
        "\n",
        "    self.z2hid = nn.Linear(z_dim, hidden_dim)\n",
        "    self.hid2img = nn.Linear(hidden_dim, input_dim)\n",
        "\n",
        "    self.relu = nn.ReLU()\n",
        "\n",
        "  def encoder(self, x):\n",
        "    x = self.img2hid(x)\n",
        "    x = self.relu(x)\n",
        "    mu = self.hid2mu(x)\n",
        "    sigma = self.hid2sigma(x)\n",
        "    return mu, sigma\n",
        "\n",
        "  def decoder(self, z):\n",
        "    z = self.z2hid(z)\n",
        "    z = self.relu(z)\n",
        "    x = self.hid2img(z)\n",
        "    x = torch.sigmoid(x)\n",
        "    return x\n",
        "\n",
        "  def forward(self, x):\n",
        "    mu, sigma = self.encoder(x)\n",
        "    epsilon = torch.randn_like(sigma)\n",
        "    z_reparam = mu + sigma * epsilon\n",
        "    x_reconst = self.decoder(z_reparam)\n",
        "    return x_reconst, mu, sigma"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "1ITklBR8iRvY"
      },
      "outputs": [],
      "source": [
        "model = VAE(784, 200, 20).to(device)\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=3e-4)\n",
        "criterion = nn.BCELoss(reduction=\"sum\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 3. 모델 학습"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WwRbpZFKjCa4",
        "outputId": "eda24f12-1249-4139-bfcf-0c006f21aaf3"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "1875it [00:11, 158.03it/s]\n",
            "1875it [00:10, 172.13it/s]\n",
            "1875it [00:10, 171.78it/s]\n",
            "1875it [00:10, 172.66it/s]\n",
            "1875it [00:10, 177.99it/s]\n",
            "1875it [00:10, 172.16it/s]\n",
            "1875it [00:10, 172.15it/s]\n",
            "1875it [00:10, 171.41it/s]\n",
            "1875it [00:11, 170.43it/s]\n",
            "1875it [00:10, 171.85it/s]\n"
          ]
        }
      ],
      "source": [
        "from tqdm import tqdm\n",
        "\n",
        "for epoch in range(10):\n",
        "  for i, (x, _) in tqdm(enumerate(train_loader)):\n",
        "    x = x.to(device).view(x.shape[0], 784)\n",
        "\n",
        "    x_reconst, mu, sigma = model(x)\n",
        "\n",
        "    reconst_loss = criterion(x_reconst, x)\n",
        "    kl_div = -torch.sum(1 + torch.log(sigma.pow(2)) - mu.pow(2) - sigma.pow(2))\n",
        "\n",
        "    loss = reconst_loss + kl_div\n",
        "    optimizer.zero_grad()\n",
        "    loss.backward()\n",
        "    optimizer.step()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 4. 추론 (이미지 생성)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "Sk7-gPdokOoh"
      },
      "outputs": [],
      "source": [
        "from torchvision.utils import save_image\n",
        "\n",
        "model = model.to(\"cpu\")\n",
        "\n",
        "def inference(digit, num_samples=3):\n",
        "  images = []\n",
        "  idx = 0\n",
        "\n",
        "  for x, y in dataset:\n",
        "    if y == digit:\n",
        "      images.append(x)\n",
        "      idx += 1\n",
        "      if idx >= num_samples:\n",
        "        break\n",
        "\n",
        "  encoding_digit = []\n",
        "  for img in images:\n",
        "    with torch.no_grad():\n",
        "      mu, sigma = model.encoder(img.view(1, 784))\n",
        "    encoding_digit.append((mu, sigma))\n",
        "\n",
        "  mu, sigma = encoding_digit[0]\n",
        "\n",
        "  for example in range(num_samples):\n",
        "    epsilon = torch.randn_like(sigma)\n",
        "    z = mu + sigma * epsilon\n",
        "    out = model.decoder(z)\n",
        "    out = out.view(-1, 1, 28, 28)\n",
        "    save_image(out, f\"digit{digit}_smaple_{example}.png\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "wKK3qzKwljww"
      },
      "outputs": [],
      "source": [
        "inference(7)"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
