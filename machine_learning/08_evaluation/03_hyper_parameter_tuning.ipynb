{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e0ad1f15",
   "metadata": {},
   "source": [
    "# Hyper Parameter Tuning\n",
    "\n",
    "- hyper parameter: 모델 설정과 관련해 직접 지정할 수 있는 매개변수\n",
    "- model parameter: 회귀계수(가중치), 절편 등 모델의 학습 대상이 되는 변수"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69788534",
   "metadata": {},
   "source": [
    "### GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "c8d394af",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "최적의 파라미터: {'n_neighbors': 7}\n",
      "최적화된 모델 객체: KNeighborsClassifier(n_neighbors=7)\n",
      "최적화된 점수: 0.9800000000000001\n"
     ]
    }
   ],
   "source": [
    "from sklearn.datasets import load_iris\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "# 데이터 로드\n",
    "iris_input, iris_target = load_iris(return_X_y=True)\n",
    "\n",
    "# 모델 생성\n",
    "knn = KNeighborsClassifier()\n",
    "\n",
    "# 테스트할 파라미터 값\n",
    "params = {\n",
    "    'n_neighbors': range(1, 13, 2)\n",
    "}\n",
    "\n",
    "# 첫 번째 인자: 모델\n",
    "# 두 번째 인자: 테스트 할 파라미터 (딕셔너리)\n",
    "# scoring: 평가 지표 (accuracy, precision, recall, f1)\n",
    "# cv: 반복 횟수\n",
    "grid = GridSearchCV(knn, params, scoring='accuracy', cv=5)\n",
    "grid.fit(iris_input, iris_target)\n",
    "\n",
    "print(\"최적의 파라미터:\", grid.best_params_)\n",
    "print(\"최적화된 모델 객체:\", grid.best_estimator_)\n",
    "print(\"최적화된 점수:\", grid.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "2f59cae0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9733333333333334"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_knn = grid.best_estimator_\n",
    "# best_knn.predict(iris_input)\n",
    "best_knn.score(iris_input, iris_target)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c453c2d",
   "metadata": {},
   "source": [
    "### RandomSearchCV\n",
    "\n",
    "- 하이퍼 파라미터의 값 목록이나 값의 범위를 제공하는데, 이 범위 중에 랜덤하게 값을 뽑아내 최적의 하이퍼 파라미터 조합을 찾는다.\n",
    "    - 탐색범위가 넓을 때 짧은 시간 내에 좋은 결과를 얻을 수 있다.\n",
    "    - 랜덤하게 값을 추출해 계산하므로, 전역 최적값을 놓칠 수 있다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "50d6c7ce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "최적의 파라미터: {'n_neighbors': 5}\n",
      "최적화된 모델 객체: KNeighborsClassifier()\n",
      "최적화된 점수: 0.9733333333333334\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "\n",
    "# 모델 생성\n",
    "knn = KNeighborsClassifier()\n",
    "\n",
    "# 테스트할 파라미터 값\n",
    "params = {\n",
    "    'n_neighbors': range(1, 100, 2)\n",
    "}\n",
    "\n",
    "# n_iter: 탐색할 최적의 하이퍼 파라미터 조합 수 (기본값: 10)\n",
    "#         값이 크면 시간이 오래 걸림 / 값이 작으면 좋은 조합을 찾을 가능성 저하\n",
    "rd_search = RandomizedSearchCV(knn, params, cv=5, n_iter=10, random_state=0)\n",
    "rd_search.fit(iris_input, iris_target)\n",
    "\n",
    "print(\"최적의 파라미터:\", rd_search.best_params_)\n",
    "print(\"최적화된 모델 객체:\", rd_search.best_estimator_)\n",
    "print(\"최적화된 점수:\", rd_search.best_score_)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "523edcf8",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e818ad2",
   "metadata": {},
   "source": [
    "### HyperOpt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c4d225e",
   "metadata": {},
   "source": [
    "**hyper.hp클래스**\n",
    "<table border=\"1\">\n",
    "  <thead>\n",
    "    <tr>\n",
    "      <th>함수명</th>\n",
    "      <th>설명</th>\n",
    "      <th>사용 방법</th>\n",
    "      <th>예시 코드</th>\n",
    "    </tr>\n",
    "  </thead>\n",
    "  <tbody>\n",
    "    <tr>\n",
    "      <td>hp.uniform</td>\n",
    "      <td>연속적인 실수 값 샘플링</td>\n",
    "      <td>hp.uniform(label, low, high)</td>\n",
    "      <td><code>hp.uniform('learning_rate', 0.01, 0.1)</code></td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "      <td>hp.quniform</td>\n",
    "      <td>연속적이지만 일정 간격(q)을 갖는 값 샘플링</td>\n",
    "      <td>hp.quniform(label, low, high, q)</td>\n",
    "      <td><code>hp.quniform('num_layers', 1, 5, 1)</code></td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "      <td>hp.loguniform</td>\n",
    "      <td>로그 스케일로 분포된 실수 값 샘플링</td>\n",
    "      <td>hp.loguniform(label, low, high)</td>\n",
    "      <td><code>hp.loguniform('reg_param', -3, 0)</code></td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "      <td>hp.randint</td>\n",
    "      <td>정수 값 샘플링</td>\n",
    "      <td>hp.randint(label, upper)</td>\n",
    "      <td><code>hp.randint('num_trees', 1, 100)</code></td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "      <td>hp.choice</td>\n",
    "      <td>주어진 리스트 중 임의의 값 샘플링</td>\n",
    "      <td>hp.choice(label, options)</td>\n",
    "      <td><code>hp.choice('optimizer', ['adam', 'sgd', 'rmsprop'])</code></td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "      <td>hp.normal</td>\n",
    "      <td>정규분포에서 값 샘플링</td>\n",
    "      <td>hp.normal(label, mean, std)</td>\n",
    "      <td><code>hp.normal('dropout_rate', 0.3, 0.05)</code></td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "      <td>hp.lognormal</td>\n",
    "      <td>로그 정규분포에서 값 샘플링</td>\n",
    "      <td>hp.lognormal(label, mean, std)</td>\n",
    "      <td><code>hp.lognormal('scale', 0, 1)</code></td>\n",
    "    </tr>\n",
    "  </tbody>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "965d1576",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install hyperopt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "6d4b4438",
   "metadata": {},
   "outputs": [],
   "source": [
    "from hyperopt import hp\n",
    "\n",
    "# 검색 공간\n",
    "search_space = {\n",
    "    'x': hp.quniform('x', -10, 10, 1),\n",
    "    'y': hp.quniform('y', -15, 15, 1)\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "1121c426",
   "metadata": {},
   "outputs": [],
   "source": [
    "import hyperopt\n",
    "\n",
    "# 목적 함수\n",
    "def objective(search_space):\n",
    "    x = search_space['x']\n",
    "    y = search_space['y']\n",
    "    return {\n",
    "        'loss': x ** 2 + 20 * y,\n",
    "        'status': hyperopt.STATUS_OK\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "21d1ef4e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|██████████| 500/500 [00:05<00:00, 87.62trial/s, best loss: -300.0] \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'x': np.float64(0.0), 'y': np.float64(-15.0)}"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from hyperopt import fmin, tpe, Trials\n",
    "\n",
    "trials = Trials()\n",
    "\n",
    "best_val = fmin(\n",
    "    fn=objective,\n",
    "    space=search_space,\n",
    "    algo=tpe.suggest,\n",
    "    max_evals=500,\n",
    "    trials=trials\n",
    ")\n",
    "best_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "5a35db37",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'loss': 76.0, 'status': 'ok'},\n",
       " {'loss': 141.0, 'status': 'ok'},\n",
       " {'loss': 164.0, 'status': 'ok'},\n",
       " {'loss': -259.0, 'status': 'ok'},\n",
       " {'loss': -79.0, 'status': 'ok'},\n",
       " {'loss': -51.0, 'status': 'ok'},\n",
       " {'loss': 16.0, 'status': 'ok'},\n",
       " {'loss': 309.0, 'status': 'ok'},\n",
       " {'loss': -240.0, 'status': 'ok'},\n",
       " {'loss': -36.0, 'status': 'ok'},\n",
       " {'loss': 29.0, 'status': 'ok'},\n",
       " {'loss': 221.0, 'status': 'ok'},\n",
       " {'loss': 61.0, 'status': 'ok'},\n",
       " {'loss': -104.0, 'status': 'ok'},\n",
       " {'loss': -176.0, 'status': 'ok'},\n",
       " {'loss': 284.0, 'status': 'ok'},\n",
       " {'loss': 329.0, 'status': 'ok'},\n",
       " {'loss': -231.0, 'status': 'ok'},\n",
       " {'loss': -264.0, 'status': 'ok'},\n",
       " {'loss': 185.0, 'status': 'ok'},\n",
       " {'loss': -279.0, 'status': 'ok'},\n",
       " {'loss': -279.0, 'status': 'ok'},\n",
       " {'loss': -175.0, 'status': 'ok'},\n",
       " {'loss': -59.0, 'status': 'ok'},\n",
       " {'loss': -279.0, 'status': 'ok'},\n",
       " {'loss': -264.0, 'status': 'ok'},\n",
       " {'loss': -191.0, 'status': 'ok'},\n",
       " {'loss': -139.0, 'status': 'ok'},\n",
       " {'loss': -11.0, 'status': 'ok'},\n",
       " {'loss': 256.0, 'status': 'ok'},\n",
       " {'loss': -195.0, 'status': 'ok'},\n",
       " {'loss': -299.0, 'status': 'ok'},\n",
       " {'loss': -99.0, 'status': 'ok'},\n",
       " {'loss': 61.0, 'status': 'ok'},\n",
       " {'loss': -151.0, 'status': 'ok'},\n",
       " {'loss': -264.0, 'status': 'ok'},\n",
       " {'loss': 61.0, 'status': 'ok'},\n",
       " {'loss': 200.0, 'status': 'ok'},\n",
       " {'loss': -224.0, 'status': 'ok'},\n",
       " {'loss': -16.0, 'status': 'ok'},\n",
       " {'loss': -160.0, 'status': 'ok'},\n",
       " {'loss': -251.0, 'status': 'ok'},\n",
       " {'loss': 284.0, 'status': 'ok'},\n",
       " {'loss': -51.0, 'status': 'ok'},\n",
       " {'loss': -184.0, 'status': 'ok'},\n",
       " {'loss': -136.0, 'status': 'ok'},\n",
       " {'loss': 104.0, 'status': 'ok'},\n",
       " {'loss': -24.0, 'status': 'ok'},\n",
       " {'loss': -160.0, 'status': 'ok'},\n",
       " {'loss': 36.0, 'status': 'ok'},\n",
       " {'loss': -216.0, 'status': 'ok'},\n",
       " {'loss': 165.0, 'status': 'ok'},\n",
       " {'loss': -300.0, 'status': 'ok'},\n",
       " {'loss': -116.0, 'status': 'ok'},\n",
       " {'loss': -40.0, 'status': 'ok'},\n",
       " {'loss': -116.0, 'status': 'ok'},\n",
       " {'loss': -251.0, 'status': 'ok'},\n",
       " {'loss': -275.0, 'status': 'ok'},\n",
       " {'loss': -216.0, 'status': 'ok'},\n",
       " {'loss': 65.0, 'status': 'ok'},\n",
       " {'loss': -64.0, 'status': 'ok'},\n",
       " {'loss': 201.0, 'status': 'ok'},\n",
       " {'loss': -144.0, 'status': 'ok'},\n",
       " {'loss': -300.0, 'status': 'ok'},\n",
       " {'loss': -231.0, 'status': 'ok'},\n",
       " {'loss': -280.0, 'status': 'ok'},\n",
       " {'loss': -299.0, 'status': 'ok'},\n",
       " {'loss': -239.0, 'status': 'ok'},\n",
       " {'loss': -271.0, 'status': 'ok'},\n",
       " {'loss': -136.0, 'status': 'ok'},\n",
       " {'loss': -191.0, 'status': 'ok'},\n",
       " {'loss': -244.0, 'status': 'ok'},\n",
       " {'loss': -220.0, 'status': 'ok'},\n",
       " {'loss': -159.0, 'status': 'ok'},\n",
       " {'loss': -299.0, 'status': 'ok'},\n",
       " {'loss': -116.0, 'status': 'ok'},\n",
       " {'loss': -131.0, 'status': 'ok'},\n",
       " {'loss': -236.0, 'status': 'ok'},\n",
       " {'loss': -55.0, 'status': 'ok'},\n",
       " {'loss': -279.0, 'status': 'ok'},\n",
       " {'loss': 89.0, 'status': 'ok'},\n",
       " {'loss': -260.0, 'status': 'ok'},\n",
       " {'loss': -164.0, 'status': 'ok'},\n",
       " {'loss': 25.0, 'status': 'ok'},\n",
       " {'loss': 324.0, 'status': 'ok'},\n",
       " {'loss': -299.0, 'status': 'ok'},\n",
       " {'loss': -124.0, 'status': 'ok'},\n",
       " {'loss': -71.0, 'status': 'ok'},\n",
       " {'loss': -144.0, 'status': 'ok'},\n",
       " {'loss': 184.0, 'status': 'ok'},\n",
       " {'loss': 124.0, 'status': 'ok'},\n",
       " {'loss': -211.0, 'status': 'ok'},\n",
       " {'loss': -204.0, 'status': 'ok'},\n",
       " {'loss': -4.0, 'status': 'ok'},\n",
       " {'loss': -79.0, 'status': 'ok'},\n",
       " {'loss': -171.0, 'status': 'ok'},\n",
       " {'loss': 101.0, 'status': 'ok'},\n",
       " {'loss': -99.0, 'status': 'ok'},\n",
       " {'loss': -235.0, 'status': 'ok'},\n",
       " {'loss': -40.0, 'status': 'ok'},\n",
       " {'loss': -276.0, 'status': 'ok'},\n",
       " {'loss': -211.0, 'status': 'ok'},\n",
       " {'loss': 301.0, 'status': 'ok'},\n",
       " {'loss': -299.0, 'status': 'ok'},\n",
       " {'loss': -184.0, 'status': 'ok'},\n",
       " {'loss': 89.0, 'status': 'ok'},\n",
       " {'loss': -224.0, 'status': 'ok'},\n",
       " {'loss': -115.0, 'status': 'ok'},\n",
       " {'loss': -276.0, 'status': 'ok'},\n",
       " {'loss': -260.0, 'status': 'ok'},\n",
       " {'loss': -79.0, 'status': 'ok'},\n",
       " {'loss': -211.0, 'status': 'ok'},\n",
       " {'loss': -200.0, 'status': 'ok'},\n",
       " {'loss': -171.0, 'status': 'ok'},\n",
       " {'loss': 116.0, 'status': 'ok'},\n",
       " {'loss': 244.0, 'status': 'ok'},\n",
       " {'loss': -216.0, 'status': 'ok'},\n",
       " {'loss': -36.0, 'status': 'ok'},\n",
       " {'loss': -239.0, 'status': 'ok'},\n",
       " {'loss': -64.0, 'status': 'ok'},\n",
       " {'loss': -200.0, 'status': 'ok'},\n",
       " {'loss': 176.0, 'status': 'ok'},\n",
       " {'loss': 4.0, 'status': 'ok'},\n",
       " {'loss': -299.0, 'status': 'ok'},\n",
       " {'loss': -135.0, 'status': 'ok'},\n",
       " {'loss': -271.0, 'status': 'ok'},\n",
       " {'loss': -259.0, 'status': 'ok'},\n",
       " {'loss': -151.0, 'status': 'ok'},\n",
       " {'loss': 36.0, 'status': 'ok'},\n",
       " {'loss': -96.0, 'status': 'ok'},\n",
       " {'loss': -176.0, 'status': 'ok'},\n",
       " {'loss': -71.0, 'status': 'ok'},\n",
       " {'loss': -120.0, 'status': 'ok'},\n",
       " {'loss': -139.0, 'status': 'ok'},\n",
       " {'loss': -235.0, 'status': 'ok'},\n",
       " {'loss': -71.0, 'status': 'ok'},\n",
       " {'loss': -284.0, 'status': 'ok'},\n",
       " {'loss': 120.0, 'status': 'ok'},\n",
       " {'loss': 61.0, 'status': 'ok'},\n",
       " {'loss': 316.0, 'status': 'ok'},\n",
       " {'loss': -251.0, 'status': 'ok'},\n",
       " {'loss': -216.0, 'status': 'ok'},\n",
       " {'loss': -16.0, 'status': 'ok'},\n",
       " {'loss': -116.0, 'status': 'ok'},\n",
       " {'loss': -204.0, 'status': 'ok'},\n",
       " {'loss': -299.0, 'status': 'ok'},\n",
       " {'loss': -299.0, 'status': 'ok'},\n",
       " {'loss': -280.0, 'status': 'ok'},\n",
       " {'loss': -231.0, 'status': 'ok'},\n",
       " {'loss': -259.0, 'status': 'ok'},\n",
       " {'loss': -200.0, 'status': 'ok'},\n",
       " {'loss': -276.0, 'status': 'ok'},\n",
       " {'loss': -296.0, 'status': 'ok'},\n",
       " {'loss': -211.0, 'status': 'ok'},\n",
       " {'loss': -279.0, 'status': 'ok'},\n",
       " {'loss': -215.0, 'status': 'ok'},\n",
       " {'loss': -300.0, 'status': 'ok'},\n",
       " {'loss': -196.0, 'status': 'ok'},\n",
       " {'loss': -259.0, 'status': 'ok'},\n",
       " {'loss': -220.0, 'status': 'ok'},\n",
       " {'loss': -135.0, 'status': 'ok'},\n",
       " {'loss': -276.0, 'status': 'ok'},\n",
       " {'loss': -224.0, 'status': 'ok'},\n",
       " {'loss': -291.0, 'status': 'ok'},\n",
       " {'loss': -171.0, 'status': 'ok'},\n",
       " {'loss': -139.0, 'status': 'ok'},\n",
       " {'loss': -260.0, 'status': 'ok'},\n",
       " {'loss': 229.0, 'status': 'ok'},\n",
       " {'loss': -219.0, 'status': 'ok'},\n",
       " {'loss': -144.0, 'status': 'ok'},\n",
       " {'loss': -116.0, 'status': 'ok'},\n",
       " {'loss': -276.0, 'status': 'ok'},\n",
       " {'loss': -199.0, 'status': 'ok'},\n",
       " {'loss': -296.0, 'status': 'ok'},\n",
       " {'loss': -239.0, 'status': 'ok'},\n",
       " {'loss': -155.0, 'status': 'ok'},\n",
       " {'loss': 185.0, 'status': 'ok'},\n",
       " {'loss': -240.0, 'status': 'ok'},\n",
       " {'loss': -291.0, 'status': 'ok'},\n",
       " {'loss': 9.0, 'status': 'ok'},\n",
       " {'loss': -256.0, 'status': 'ok'},\n",
       " {'loss': -259.0, 'status': 'ok'},\n",
       " {'loss': -280.0, 'status': 'ok'},\n",
       " {'loss': -164.0, 'status': 'ok'},\n",
       " {'loss': -264.0, 'status': 'ok'},\n",
       " {'loss': -91.0, 'status': 'ok'},\n",
       " {'loss': -64.0, 'status': 'ok'},\n",
       " {'loss': -219.0, 'status': 'ok'},\n",
       " {'loss': -176.0, 'status': 'ok'},\n",
       " {'loss': 261.0, 'status': 'ok'},\n",
       " {'loss': -119.0, 'status': 'ok'},\n",
       " {'loss': 184.0, 'status': 'ok'},\n",
       " {'loss': 105.0, 'status': 'ok'},\n",
       " {'loss': -291.0, 'status': 'ok'},\n",
       " {'loss': -24.0, 'status': 'ok'},\n",
       " {'loss': 280.0, 'status': 'ok'},\n",
       " {'loss': -231.0, 'status': 'ok'},\n",
       " {'loss': -216.0, 'status': 'ok'},\n",
       " {'loss': -124.0, 'status': 'ok'},\n",
       " {'loss': 124.0, 'status': 'ok'},\n",
       " {'loss': -279.0, 'status': 'ok'},\n",
       " {'loss': -244.0, 'status': 'ok'},\n",
       " {'loss': 21.0, 'status': 'ok'},\n",
       " {'loss': -99.0, 'status': 'ok'},\n",
       " {'loss': -219.0, 'status': 'ok'},\n",
       " {'loss': -239.0, 'status': 'ok'},\n",
       " {'loss': -200.0, 'status': 'ok'},\n",
       " {'loss': -11.0, 'status': 'ok'},\n",
       " {'loss': -155.0, 'status': 'ok'},\n",
       " {'loss': -264.0, 'status': 'ok'},\n",
       " {'loss': 89.0, 'status': 'ok'},\n",
       " {'loss': -256.0, 'status': 'ok'},\n",
       " {'loss': -140.0, 'status': 'ok'},\n",
       " {'loss': -211.0, 'status': 'ok'},\n",
       " {'loss': 85.0, 'status': 'ok'},\n",
       " {'loss': -156.0, 'status': 'ok'},\n",
       " {'loss': -291.0, 'status': 'ok'},\n",
       " {'loss': -199.0, 'status': 'ok'},\n",
       " {'loss': -239.0, 'status': 'ok'},\n",
       " {'loss': -264.0, 'status': 'ok'},\n",
       " {'loss': -196.0, 'status': 'ok'},\n",
       " {'loss': -300.0, 'status': 'ok'},\n",
       " {'loss': -116.0, 'status': 'ok'},\n",
       " {'loss': 156.0, 'status': 'ok'},\n",
       " {'loss': -300.0, 'status': 'ok'},\n",
       " {'loss': -79.0, 'status': 'ok'},\n",
       " {'loss': -175.0, 'status': 'ok'},\n",
       " {'loss': -224.0, 'status': 'ok'},\n",
       " {'loss': -216.0, 'status': 'ok'},\n",
       " {'loss': -280.0, 'status': 'ok'},\n",
       " {'loss': -179.0, 'status': 'ok'},\n",
       " {'loss': -231.0, 'status': 'ok'},\n",
       " {'loss': 204.0, 'status': 'ok'},\n",
       " {'loss': -291.0, 'status': 'ok'},\n",
       " {'loss': -259.0, 'status': 'ok'},\n",
       " {'loss': 24.0, 'status': 'ok'},\n",
       " {'loss': -184.0, 'status': 'ok'},\n",
       " {'loss': -279.0, 'status': 'ok'},\n",
       " {'loss': -140.0, 'status': 'ok'},\n",
       " {'loss': 109.0, 'status': 'ok'},\n",
       " {'loss': -75.0, 'status': 'ok'},\n",
       " {'loss': 256.0, 'status': 'ok'},\n",
       " {'loss': -159.0, 'status': 'ok'},\n",
       " {'loss': -236.0, 'status': 'ok'},\n",
       " {'loss': -291.0, 'status': 'ok'},\n",
       " {'loss': -196.0, 'status': 'ok'},\n",
       " {'loss': -260.0, 'status': 'ok'},\n",
       " {'loss': -276.0, 'status': 'ok'},\n",
       " {'loss': -11.0, 'status': 'ok'},\n",
       " {'loss': -104.0, 'status': 'ok'},\n",
       " {'loss': -179.0, 'status': 'ok'},\n",
       " {'loss': -219.0, 'status': 'ok'},\n",
       " {'loss': -196.0, 'status': 'ok'},\n",
       " {'loss': -251.0, 'status': 'ok'},\n",
       " {'loss': -240.0, 'status': 'ok'},\n",
       " {'loss': 9.0, 'status': 'ok'},\n",
       " {'loss': -299.0, 'status': 'ok'},\n",
       " {'loss': -300.0, 'status': 'ok'},\n",
       " {'loss': -300.0, 'status': 'ok'},\n",
       " {'loss': -279.0, 'status': 'ok'},\n",
       " {'loss': -259.0, 'status': 'ok'},\n",
       " {'loss': -296.0, 'status': 'ok'},\n",
       " {'loss': -239.0, 'status': 'ok'},\n",
       " {'loss': -276.0, 'status': 'ok'},\n",
       " {'loss': -280.0, 'status': 'ok'},\n",
       " {'loss': -239.0, 'status': 'ok'},\n",
       " {'loss': -300.0, 'status': 'ok'},\n",
       " {'loss': -211.0, 'status': 'ok'},\n",
       " {'loss': -276.0, 'status': 'ok'},\n",
       " {'loss': -219.0, 'status': 'ok'},\n",
       " {'loss': -256.0, 'status': 'ok'},\n",
       " {'loss': -231.0, 'status': 'ok'},\n",
       " {'loss': -279.0, 'status': 'ok'},\n",
       " {'loss': -299.0, 'status': 'ok'},\n",
       " {'loss': -300.0, 'status': 'ok'},\n",
       " {'loss': -180.0, 'status': 'ok'},\n",
       " {'loss': -291.0, 'status': 'ok'},\n",
       " {'loss': -256.0, 'status': 'ok'},\n",
       " {'loss': -256.0, 'status': 'ok'},\n",
       " {'loss': -159.0, 'status': 'ok'},\n",
       " {'loss': -204.0, 'status': 'ok'},\n",
       " {'loss': -199.0, 'status': 'ok'},\n",
       " {'loss': -271.0, 'status': 'ok'},\n",
       " {'loss': -239.0, 'status': 'ok'},\n",
       " {'loss': -280.0, 'status': 'ok'},\n",
       " {'loss': -291.0, 'status': 'ok'},\n",
       " {'loss': -196.0, 'status': 'ok'},\n",
       " {'loss': -244.0, 'status': 'ok'},\n",
       " {'loss': -236.0, 'status': 'ok'},\n",
       " {'loss': -180.0, 'status': 'ok'},\n",
       " {'loss': -299.0, 'status': 'ok'},\n",
       " {'loss': -184.0, 'status': 'ok'},\n",
       " {'loss': 149.0, 'status': 'ok'},\n",
       " {'loss': -259.0, 'status': 'ok'},\n",
       " {'loss': -136.0, 'status': 'ok'},\n",
       " {'loss': -180.0, 'status': 'ok'},\n",
       " {'loss': -144.0, 'status': 'ok'},\n",
       " {'loss': -195.0, 'status': 'ok'},\n",
       " {'loss': -236.0, 'status': 'ok'},\n",
       " {'loss': 116.0, 'status': 'ok'},\n",
       " {'loss': -275.0, 'status': 'ok'},\n",
       " {'loss': -199.0, 'status': 'ok'},\n",
       " {'loss': -279.0, 'status': 'ok'},\n",
       " {'loss': -240.0, 'status': 'ok'},\n",
       " {'loss': -39.0, 'status': 'ok'},\n",
       " {'loss': 20.0, 'status': 'ok'},\n",
       " {'loss': 204.0, 'status': 'ok'},\n",
       " {'loss': -256.0, 'status': 'ok'},\n",
       " {'loss': -171.0, 'status': 'ok'},\n",
       " {'loss': -291.0, 'status': 'ok'},\n",
       " {'loss': -299.0, 'status': 'ok'},\n",
       " {'loss': 140.0, 'status': 'ok'},\n",
       " {'loss': -280.0, 'status': 'ok'},\n",
       " {'loss': 196.0, 'status': 'ok'},\n",
       " {'loss': -244.0, 'status': 'ok'},\n",
       " {'loss': -195.0, 'status': 'ok'},\n",
       " {'loss': -139.0, 'status': 'ok'},\n",
       " {'loss': -116.0, 'status': 'ok'},\n",
       " {'loss': -196.0, 'status': 'ok'},\n",
       " {'loss': -299.0, 'status': 'ok'},\n",
       " {'loss': -280.0, 'status': 'ok'},\n",
       " {'loss': -236.0, 'status': 'ok'},\n",
       " {'loss': 281.0, 'status': 'ok'},\n",
       " {'loss': -251.0, 'status': 'ok'},\n",
       " {'loss': -144.0, 'status': 'ok'},\n",
       " {'loss': -211.0, 'status': 'ok'},\n",
       " {'loss': -176.0, 'status': 'ok'},\n",
       " {'loss': -300.0, 'status': 'ok'},\n",
       " {'loss': -24.0, 'status': 'ok'},\n",
       " {'loss': -256.0, 'status': 'ok'},\n",
       " {'loss': -191.0, 'status': 'ok'},\n",
       " {'loss': -279.0, 'status': 'ok'},\n",
       " {'loss': -99.0, 'status': 'ok'},\n",
       " {'loss': -195.0, 'status': 'ok'},\n",
       " {'loss': -16.0, 'status': 'ok'},\n",
       " {'loss': -276.0, 'status': 'ok'},\n",
       " {'loss': 81.0, 'status': 'ok'},\n",
       " {'loss': -231.0, 'status': 'ok'},\n",
       " {'loss': -300.0, 'status': 'ok'},\n",
       " {'loss': -180.0, 'status': 'ok'},\n",
       " {'loss': 241.0, 'status': 'ok'},\n",
       " {'loss': -144.0, 'status': 'ok'},\n",
       " {'loss': -71.0, 'status': 'ok'},\n",
       " {'loss': -256.0, 'status': 'ok'},\n",
       " {'loss': -264.0, 'status': 'ok'},\n",
       " {'loss': -259.0, 'status': 'ok'},\n",
       " {'loss': -164.0, 'status': 'ok'},\n",
       " {'loss': -219.0, 'status': 'ok'},\n",
       " {'loss': -231.0, 'status': 'ok'},\n",
       " {'loss': -296.0, 'status': 'ok'},\n",
       " {'loss': -176.0, 'status': 'ok'},\n",
       " {'loss': -279.0, 'status': 'ok'},\n",
       " {'loss': 120.0, 'status': 'ok'},\n",
       " {'loss': -115.0, 'status': 'ok'},\n",
       " {'loss': -251.0, 'status': 'ok'},\n",
       " {'loss': -239.0, 'status': 'ok'},\n",
       " {'loss': 309.0, 'status': 'ok'},\n",
       " {'loss': -256.0, 'status': 'ok'},\n",
       " {'loss': -31.0, 'status': 'ok'},\n",
       " {'loss': -156.0, 'status': 'ok'},\n",
       " {'loss': -284.0, 'status': 'ok'},\n",
       " {'loss': -200.0, 'status': 'ok'},\n",
       " {'loss': -299.0, 'status': 'ok'},\n",
       " {'loss': -239.0, 'status': 'ok'},\n",
       " {'loss': -260.0, 'status': 'ok'},\n",
       " {'loss': -264.0, 'status': 'ok'},\n",
       " {'loss': -276.0, 'status': 'ok'},\n",
       " {'loss': -156.0, 'status': 'ok'},\n",
       " {'loss': -260.0, 'status': 'ok'},\n",
       " {'loss': -64.0, 'status': 'ok'},\n",
       " {'loss': -179.0, 'status': 'ok'},\n",
       " {'loss': 69.0, 'status': 'ok'},\n",
       " {'loss': -299.0, 'status': 'ok'},\n",
       " {'loss': -191.0, 'status': 'ok'},\n",
       " {'loss': -219.0, 'status': 'ok'},\n",
       " {'loss': -276.0, 'status': 'ok'},\n",
       " {'loss': 4.0, 'status': 'ok'},\n",
       " {'loss': -111.0, 'status': 'ok'},\n",
       " {'loss': -224.0, 'status': 'ok'},\n",
       " {'loss': 161.0, 'status': 'ok'},\n",
       " {'loss': 224.0, 'status': 'ok'},\n",
       " {'loss': -219.0, 'status': 'ok'},\n",
       " {'loss': -155.0, 'status': 'ok'},\n",
       " {'loss': -260.0, 'status': 'ok'},\n",
       " {'loss': -175.0, 'status': 'ok'},\n",
       " {'loss': -279.0, 'status': 'ok'},\n",
       " {'loss': -236.0, 'status': 'ok'},\n",
       " {'loss': -284.0, 'status': 'ok'},\n",
       " {'loss': -159.0, 'status': 'ok'},\n",
       " {'loss': -260.0, 'status': 'ok'},\n",
       " {'loss': -291.0, 'status': 'ok'},\n",
       " {'loss': -76.0, 'status': 'ok'},\n",
       " {'loss': -136.0, 'status': 'ok'},\n",
       " {'loss': -279.0, 'status': 'ok'},\n",
       " {'loss': -204.0, 'status': 'ok'},\n",
       " {'loss': 269.0, 'status': 'ok'},\n",
       " {'loss': -176.0, 'status': 'ok'},\n",
       " {'loss': -215.0, 'status': 'ok'},\n",
       " {'loss': -244.0, 'status': 'ok'},\n",
       " {'loss': -219.0, 'status': 'ok'},\n",
       " {'loss': -271.0, 'status': 'ok'},\n",
       " {'loss': -300.0, 'status': 'ok'},\n",
       " {'loss': -300.0, 'status': 'ok'},\n",
       " {'loss': -300.0, 'status': 'ok'},\n",
       " {'loss': -279.0, 'status': 'ok'},\n",
       " {'loss': -260.0, 'status': 'ok'},\n",
       " {'loss': -299.0, 'status': 'ok'},\n",
       " {'loss': -279.0, 'status': 'ok'},\n",
       " {'loss': -259.0, 'status': 'ok'},\n",
       " {'loss': -239.0, 'status': 'ok'},\n",
       " {'loss': -279.0, 'status': 'ok'},\n",
       " {'loss': -276.0, 'status': 'ok'},\n",
       " {'loss': -260.0, 'status': 'ok'},\n",
       " {'loss': -300.0, 'status': 'ok'},\n",
       " {'loss': -239.0, 'status': 'ok'},\n",
       " {'loss': -216.0, 'status': 'ok'},\n",
       " {'loss': -296.0, 'status': 'ok'},\n",
       " {'loss': -279.0, 'status': 'ok'},\n",
       " {'loss': -256.0, 'status': 'ok'},\n",
       " {'loss': -236.0, 'status': 'ok'},\n",
       " {'loss': -299.0, 'status': 'ok'},\n",
       " {'loss': -199.0, 'status': 'ok'},\n",
       " {'loss': -220.0, 'status': 'ok'},\n",
       " {'loss': -240.0, 'status': 'ok'},\n",
       " {'loss': -291.0, 'status': 'ok'},\n",
       " {'loss': -259.0, 'status': 'ok'},\n",
       " {'loss': -271.0, 'status': 'ok'},\n",
       " {'loss': -216.0, 'status': 'ok'},\n",
       " {'loss': -299.0, 'status': 'ok'},\n",
       " {'loss': -260.0, 'status': 'ok'},\n",
       " {'loss': -276.0, 'status': 'ok'},\n",
       " {'loss': -199.0, 'status': 'ok'},\n",
       " {'loss': -236.0, 'status': 'ok'},\n",
       " {'loss': -300.0, 'status': 'ok'},\n",
       " {'loss': 40.0, 'status': 'ok'},\n",
       " {'loss': -299.0, 'status': 'ok'},\n",
       " {'loss': -276.0, 'status': 'ok'},\n",
       " {'loss': -300.0, 'status': 'ok'},\n",
       " {'loss': -259.0, 'status': 'ok'},\n",
       " {'loss': -211.0, 'status': 'ok'},\n",
       " {'loss': -259.0, 'status': 'ok'},\n",
       " {'loss': -236.0, 'status': 'ok'},\n",
       " {'loss': -276.0, 'status': 'ok'},\n",
       " {'loss': -271.0, 'status': 'ok'},\n",
       " {'loss': -171.0, 'status': 'ok'},\n",
       " {'loss': -239.0, 'status': 'ok'},\n",
       " {'loss': -204.0, 'status': 'ok'},\n",
       " {'loss': -196.0, 'status': 'ok'},\n",
       " {'loss': 141.0, 'status': 'ok'},\n",
       " {'loss': 101.0, 'status': 'ok'},\n",
       " {'loss': -256.0, 'status': 'ok'},\n",
       " {'loss': -271.0, 'status': 'ok'},\n",
       " {'loss': 21.0, 'status': 'ok'},\n",
       " {'loss': -300.0, 'status': 'ok'},\n",
       " {'loss': -300.0, 'status': 'ok'},\n",
       " {'loss': -260.0, 'status': 'ok'},\n",
       " {'loss': -296.0, 'status': 'ok'},\n",
       " {'loss': 81.0, 'status': 'ok'},\n",
       " {'loss': -144.0, 'status': 'ok'},\n",
       " {'loss': -211.0, 'status': 'ok'},\n",
       " {'loss': -239.0, 'status': 'ok'},\n",
       " {'loss': 204.0, 'status': 'ok'},\n",
       " {'loss': -276.0, 'status': 'ok'},\n",
       " {'loss': -191.0, 'status': 'ok'},\n",
       " {'loss': -259.0, 'status': 'ok'},\n",
       " {'loss': -300.0, 'status': 'ok'},\n",
       " {'loss': -180.0, 'status': 'ok'},\n",
       " {'loss': -256.0, 'status': 'ok'},\n",
       " {'loss': -19.0, 'status': 'ok'},\n",
       " {'loss': -191.0, 'status': 'ok'},\n",
       " {'loss': -224.0, 'status': 'ok'},\n",
       " {'loss': -279.0, 'status': 'ok'},\n",
       " {'loss': -239.0, 'status': 'ok'},\n",
       " {'loss': -296.0, 'status': 'ok'},\n",
       " {'loss': -219.0, 'status': 'ok'},\n",
       " {'loss': -264.0, 'status': 'ok'},\n",
       " {'loss': 184.0, 'status': 'ok'},\n",
       " {'loss': -271.0, 'status': 'ok'},\n",
       " {'loss': -115.0, 'status': 'ok'},\n",
       " {'loss': -259.0, 'status': 'ok'},\n",
       " {'loss': -224.0, 'status': 'ok'},\n",
       " {'loss': -300.0, 'status': 'ok'},\n",
       " {'loss': -300.0, 'status': 'ok'},\n",
       " {'loss': -179.0, 'status': 'ok'},\n",
       " {'loss': -139.0, 'status': 'ok'},\n",
       " {'loss': -256.0, 'status': 'ok'},\n",
       " {'loss': -196.0, 'status': 'ok'},\n",
       " {'loss': -111.0, 'status': 'ok'},\n",
       " {'loss': -279.0, 'status': 'ok'},\n",
       " {'loss': -300.0, 'status': 'ok'},\n",
       " {'loss': -220.0, 'status': 'ok'},\n",
       " {'loss': -59.0, 'status': 'ok'},\n",
       " {'loss': 289.0, 'status': 'ok'},\n",
       " {'loss': -156.0, 'status': 'ok'},\n",
       " {'loss': -239.0, 'status': 'ok'},\n",
       " {'loss': -224.0, 'status': 'ok'},\n",
       " {'loss': -256.0, 'status': 'ok'},\n",
       " {'loss': -279.0, 'status': 'ok'},\n",
       " {'loss': -164.0, 'status': 'ok'},\n",
       " {'loss': -271.0, 'status': 'ok'}]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trials.results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "c2b091c3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'x': [np.float64(6.0),\n",
       "  np.float64(-9.0),\n",
       "  np.float64(-8.0),\n",
       "  np.float64(-1.0),\n",
       "  np.float64(9.0),\n",
       "  np.float64(-3.0),\n",
       "  np.float64(-4.0),\n",
       "  np.float64(7.0),\n",
       "  np.float64(0.0),\n",
       "  np.float64(-8.0),\n",
       "  np.float64(3.0),\n",
       "  np.float64(9.0),\n",
       "  np.float64(-1.0),\n",
       "  np.float64(4.0),\n",
       "  np.float64(-2.0),\n",
       "  np.float64(2.0),\n",
       "  np.float64(7.0),\n",
       "  np.float64(-3.0),\n",
       "  np.float64(4.0),\n",
       "  np.float64(5.0),\n",
       "  np.float64(1.0),\n",
       "  np.float64(1.0),\n",
       "  np.float64(-5.0),\n",
       "  np.float64(1.0),\n",
       "  np.float64(1.0),\n",
       "  np.float64(-6.0),\n",
       "  np.float64(3.0),\n",
       "  np.float64(1.0),\n",
       "  np.float64(7.0),\n",
       "  np.float64(-6.0),\n",
       "  np.float64(5.0),\n",
       "  np.float64(-1.0),\n",
       "  np.float64(-1.0),\n",
       "  np.float64(-9.0),\n",
       "  np.float64(-3.0),\n",
       "  np.float64(-6.0),\n",
       "  np.float64(-1.0),\n",
       "  np.float64(10.0),\n",
       "  np.float64(-4.0),\n",
       "  np.float64(-2.0),\n",
       "  np.float64(0.0),\n",
       "  np.float64(3.0),\n",
       "  np.float64(8.0),\n",
       "  np.float64(-7.0),\n",
       "  np.float64(-4.0),\n",
       "  np.float64(2.0),\n",
       "  np.float64(-2.0),\n",
       "  np.float64(6.0),\n",
       "  np.float64(-10.0),\n",
       "  np.float64(4.0),\n",
       "  np.float64(2.0),\n",
       "  np.float64(-5.0),\n",
       "  np.float64(0.0),\n",
       "  np.float64(-8.0),\n",
       "  np.float64(0.0),\n",
       "  np.float64(-2.0),\n",
       "  np.float64(-3.0),\n",
       "  np.float64(5.0),\n",
       "  np.float64(2.0),\n",
       "  np.float64(-5.0),\n",
       "  np.float64(-4.0),\n",
       "  np.float64(-1.0),\n",
       "  np.float64(6.0),\n",
       "  np.float64(-0.0),\n",
       "  np.float64(3.0),\n",
       "  np.float64(0.0),\n",
       "  np.float64(-1.0),\n",
       "  np.float64(1.0),\n",
       "  np.float64(-3.0),\n",
       "  np.float64(-2.0),\n",
       "  np.float64(3.0),\n",
       "  np.float64(4.0),\n",
       "  np.float64(-0.0),\n",
       "  np.float64(-1.0),\n",
       "  np.float64(1.0),\n",
       "  np.float64(2.0),\n",
       "  np.float64(-7.0),\n",
       "  np.float64(-2.0),\n",
       "  np.float64(-5.0),\n",
       "  np.float64(1.0),\n",
       "  np.float64(-3.0),\n",
       "  np.float64(-0.0),\n",
       "  np.float64(6.0),\n",
       "  np.float64(5.0),\n",
       "  np.float64(8.0),\n",
       "  np.float64(-1.0),\n",
       "  np.float64(4.0),\n",
       "  np.float64(-7.0),\n",
       "  np.float64(-4.0),\n",
       "  np.float64(2.0),\n",
       "  np.float64(-2.0),\n",
       "  np.float64(3.0),\n",
       "  np.float64(-6.0),\n",
       "  np.float64(-4.0),\n",
       "  np.float64(1.0),\n",
       "  np.float64(-3.0),\n",
       "  np.float64(-9.0),\n",
       "  np.float64(-1.0),\n",
       "  np.float64(-5.0),\n",
       "  np.float64(0.0),\n",
       "  np.float64(2.0),\n",
       "  np.float64(3.0),\n",
       "  np.float64(-1.0),\n",
       "  np.float64(1.0),\n",
       "  np.float64(4.0),\n",
       "  np.float64(7.0),\n",
       "  np.float64(-4.0),\n",
       "  np.float64(5.0),\n",
       "  np.float64(-2.0),\n",
       "  np.float64(0.0),\n",
       "  np.float64(9.0),\n",
       "  np.float64(-3.0),\n",
       "  np.float64(-10.0),\n",
       "  np.float64(3.0),\n",
       "  np.float64(-6.0),\n",
       "  np.float64(-2.0),\n",
       "  np.float64(-8.0),\n",
       "  np.float64(2.0),\n",
       "  np.float64(-1.0),\n",
       "  np.float64(6.0),\n",
       "  np.float64(0.0),\n",
       "  np.float64(4.0),\n",
       "  np.float64(8.0),\n",
       "  np.float64(1.0),\n",
       "  np.float64(-5.0),\n",
       "  np.float64(-3.0),\n",
       "  np.float64(1.0),\n",
       "  np.float64(7.0),\n",
       "  np.float64(-4.0),\n",
       "  np.float64(2.0),\n",
       "  np.float64(-2.0),\n",
       "  np.float64(-7.0),\n",
       "  np.float64(10.0),\n",
       "  np.float64(-1.0),\n",
       "  np.float64(5.0),\n",
       "  np.float64(-3.0),\n",
       "  np.float64(4.0),\n",
       "  np.float64(-0.0),\n",
       "  np.float64(-1.0),\n",
       "  np.float64(-4.0),\n",
       "  np.float64(3.0),\n",
       "  np.float64(2.0),\n",
       "  np.float64(-2.0),\n",
       "  np.float64(-8.0),\n",
       "  np.float64(-6.0),\n",
       "  np.float64(1.0),\n",
       "  np.float64(1.0),\n",
       "  np.float64(-0.0),\n",
       "  np.float64(3.0),\n",
       "  np.float64(1.0),\n",
       "  np.float64(0.0),\n",
       "  np.float64(-2.0),\n",
       "  np.float64(2.0),\n",
       "  np.float64(-3.0),\n",
       "  np.float64(-1.0),\n",
       "  np.float64(5.0),\n",
       "  np.float64(-0.0),\n",
       "  np.float64(-2.0),\n",
       "  np.float64(-1.0),\n",
       "  np.float64(-0.0),\n",
       "  np.float64(-5.0),\n",
       "  np.float64(2.0),\n",
       "  np.float64(-4.0),\n",
       "  np.float64(-3.0),\n",
       "  np.float64(3.0),\n",
       "  np.float64(-1.0),\n",
       "  np.float64(0.0),\n",
       "  np.float64(-3.0),\n",
       "  np.float64(1.0),\n",
       "  np.float64(4.0),\n",
       "  np.float64(2.0),\n",
       "  np.float64(-2.0),\n",
       "  np.float64(-1.0),\n",
       "  np.float64(2.0),\n",
       "  np.float64(1.0),\n",
       "  np.float64(5.0),\n",
       "  np.float64(-5.0),\n",
       "  np.float64(-0.0),\n",
       "  np.float64(-3.0),\n",
       "  np.float64(3.0),\n",
       "  np.float64(-2.0),\n",
       "  np.float64(1.0),\n",
       "  np.float64(0.0),\n",
       "  np.float64(6.0),\n",
       "  np.float64(4.0),\n",
       "  np.float64(7.0),\n",
       "  np.float64(-4.0),\n",
       "  np.float64(-1.0),\n",
       "  np.float64(-2.0),\n",
       "  np.float64(-1.0),\n",
       "  np.float64(1.0),\n",
       "  np.float64(2.0),\n",
       "  np.float64(-5.0),\n",
       "  np.float64(3.0),\n",
       "  np.float64(-4.0),\n",
       "  np.float64(0.0),\n",
       "  np.float64(-3.0),\n",
       "  np.float64(-2.0),\n",
       "  np.float64(-6.0),\n",
       "  np.float64(2.0),\n",
       "  np.float64(-1.0),\n",
       "  np.float64(4.0),\n",
       "  np.float64(9.0),\n",
       "  np.float64(1.0),\n",
       "  np.float64(-9.0),\n",
       "  np.float64(-1.0),\n",
       "  np.float64(-0.0),\n",
       "  np.float64(3.0),\n",
       "  np.float64(5.0),\n",
       "  np.float64(-4.0),\n",
       "  np.float64(-7.0),\n",
       "  np.float64(-2.0),\n",
       "  np.float64(-0.0),\n",
       "  np.float64(-3.0),\n",
       "  np.float64(-5.0),\n",
       "  np.float64(2.0),\n",
       "  np.float64(3.0),\n",
       "  np.float64(-1.0),\n",
       "  np.float64(1.0),\n",
       "  np.float64(4.0),\n",
       "  np.float64(8.0),\n",
       "  np.float64(-0.0),\n",
       "  np.float64(2.0),\n",
       "  np.float64(4.0),\n",
       "  np.float64(0.0),\n",
       "  np.float64(1.0),\n",
       "  np.float64(5.0),\n",
       "  np.float64(6.0),\n",
       "  np.float64(-2.0),\n",
       "  np.float64(-0.0),\n",
       "  np.float64(1.0),\n",
       "  np.float64(-3.0),\n",
       "  np.float64(-2.0),\n",
       "  np.float64(3.0),\n",
       "  np.float64(1.0),\n",
       "  np.float64(2.0),\n",
       "  np.float64(-6.0),\n",
       "  np.float64(-1.0),\n",
       "  np.float64(-0.0),\n",
       "  np.float64(-3.0),\n",
       "  np.float64(-5.0),\n",
       "  np.float64(-4.0),\n",
       "  np.float64(-1.0),\n",
       "  np.float64(2.0),\n",
       "  np.float64(3.0),\n",
       "  np.float64(-2.0),\n",
       "  np.float64(0.0),\n",
       "  np.float64(2.0),\n",
       "  np.float64(7.0),\n",
       "  np.float64(4.0),\n",
       "  np.float64(1.0),\n",
       "  np.float64(-1.0),\n",
       "  np.float64(-2.0),\n",
       "  np.float64(3.0),\n",
       "  np.float64(-0.0),\n",
       "  np.float64(-3.0),\n",
       "  np.float64(1.0),\n",
       "  np.float64(0.0),\n",
       "  np.float64(-0.0),\n",
       "  np.float64(-1.0),\n",
       "  np.float64(1.0),\n",
       "  np.float64(2.0),\n",
       "  np.float64(-1.0),\n",
       "  np.float64(-2.0),\n",
       "  np.float64(0.0),\n",
       "  np.float64(1.0),\n",
       "  np.float64(0.0),\n",
       "  np.float64(-3.0),\n",
       "  np.float64(2.0),\n",
       "  np.float64(1.0),\n",
       "  np.float64(-2.0),\n",
       "  np.float64(3.0),\n",
       "  np.float64(-1.0),\n",
       "  np.float64(-1.0),\n",
       "  np.float64(-0.0),\n",
       "  np.float64(0.0),\n",
       "  np.float64(3.0),\n",
       "  np.float64(2.0),\n",
       "  np.float64(-2.0),\n",
       "  np.float64(1.0),\n",
       "  np.float64(-4.0),\n",
       "  np.float64(-1.0),\n",
       "  np.float64(-3.0),\n",
       "  np.float64(1.0),\n",
       "  np.float64(0.0),\n",
       "  np.float64(-3.0),\n",
       "  np.float64(2.0),\n",
       "  np.float64(4.0),\n",
       "  np.float64(-2.0),\n",
       "  np.float64(-0.0),\n",
       "  np.float64(-1.0),\n",
       "  np.float64(6.0),\n",
       "  np.float64(3.0),\n",
       "  np.float64(1.0),\n",
       "  np.float64(2.0),\n",
       "  np.float64(10.0),\n",
       "  np.float64(-4.0),\n",
       "  np.float64(-5.0),\n",
       "  np.float64(-2.0),\n",
       "  np.float64(4.0),\n",
       "  np.float64(5.0),\n",
       "  np.float64(-1.0),\n",
       "  np.float64(-1.0),\n",
       "  np.float64(-0.0),\n",
       "  np.float64(1.0),\n",
       "  np.float64(-0.0),\n",
       "  np.float64(-2.0),\n",
       "  np.float64(2.0),\n",
       "  np.float64(-3.0),\n",
       "  np.float64(3.0),\n",
       "  np.float64(1.0),\n",
       "  np.float64(-10.0),\n",
       "  np.float64(0.0),\n",
       "  np.float64(-4.0),\n",
       "  np.float64(4.0),\n",
       "  np.float64(5.0),\n",
       "  np.float64(-1.0),\n",
       "  np.float64(2.0),\n",
       "  np.float64(-2.0),\n",
       "  np.float64(1.0),\n",
       "  np.float64(-0.0),\n",
       "  np.float64(2.0),\n",
       "  np.float64(-1.0),\n",
       "  np.float64(3.0),\n",
       "  np.float64(-4.0),\n",
       "  np.float64(-3.0),\n",
       "  np.float64(-8.0),\n",
       "  np.float64(-0.0),\n",
       "  np.float64(-6.0),\n",
       "  np.float64(-2.0),\n",
       "  np.float64(3.0),\n",
       "  np.float64(1.0),\n",
       "  np.float64(-1.0),\n",
       "  np.float64(-5.0),\n",
       "  np.float64(2.0),\n",
       "  np.float64(-2.0),\n",
       "  np.float64(-1.0),\n",
       "  np.float64(-3.0),\n",
       "  np.float64(0.0),\n",
       "  np.float64(0.0),\n",
       "  np.float64(1.0),\n",
       "  np.float64(-4.0),\n",
       "  np.float64(-3.0),\n",
       "  np.float64(2.0),\n",
       "  np.float64(4.0),\n",
       "  np.float64(1.0),\n",
       "  np.float64(6.0),\n",
       "  np.float64(-1.0),\n",
       "  np.float64(3.0),\n",
       "  np.float64(-2.0),\n",
       "  np.float64(2.0),\n",
       "  np.float64(1.0),\n",
       "  np.float64(0.0),\n",
       "  np.float64(5.0),\n",
       "  np.float64(-7.0),\n",
       "  np.float64(-1.0),\n",
       "  np.float64(-3.0),\n",
       "  np.float64(-2.0),\n",
       "  np.float64(3.0),\n",
       "  np.float64(8.0),\n",
       "  np.float64(4.0),\n",
       "  np.float64(-0.0),\n",
       "  np.float64(1.0),\n",
       "  np.float64(-1.0),\n",
       "  np.float64(-0.0),\n",
       "  np.float64(-4.0),\n",
       "  np.float64(2.0),\n",
       "  np.float64(-2.0),\n",
       "  np.float64(0.0),\n",
       "  np.float64(-6.0),\n",
       "  np.float64(1.0),\n",
       "  np.float64(-3.0),\n",
       "  np.float64(-1.0),\n",
       "  np.float64(3.0),\n",
       "  np.float64(1.0),\n",
       "  np.float64(-2.0),\n",
       "  np.float64(2.0),\n",
       "  np.float64(3.0),\n",
       "  np.float64(4.0),\n",
       "  np.float64(1.0),\n",
       "  np.float64(2.0),\n",
       "  np.float64(-1.0),\n",
       "  np.float64(-5.0),\n",
       "  np.float64(-0.0),\n",
       "  np.float64(5.0),\n",
       "  np.float64(-1.0),\n",
       "  np.float64(-2.0),\n",
       "  np.float64(-4.0),\n",
       "  np.float64(1.0),\n",
       "  np.float64(-0.0),\n",
       "  np.float64(-3.0),\n",
       "  np.float64(2.0),\n",
       "  np.float64(-2.0),\n",
       "  np.float64(-1.0),\n",
       "  np.float64(4.0),\n",
       "  np.float64(-3.0),\n",
       "  np.float64(2.0),\n",
       "  np.float64(5.0),\n",
       "  np.float64(-4.0),\n",
       "  np.float64(-9.0),\n",
       "  np.float64(3.0),\n",
       "  np.float64(-0.0),\n",
       "  np.float64(-0.0),\n",
       "  np.float64(0.0),\n",
       "  np.float64(-1.0),\n",
       "  np.float64(-0.0),\n",
       "  np.float64(1.0),\n",
       "  np.float64(1.0),\n",
       "  np.float64(-1.0),\n",
       "  np.float64(1.0),\n",
       "  np.float64(-1.0),\n",
       "  np.float64(-2.0),\n",
       "  np.float64(0.0),\n",
       "  np.float64(0.0),\n",
       "  np.float64(1.0),\n",
       "  np.float64(2.0),\n",
       "  np.float64(-2.0),\n",
       "  np.float64(-1.0),\n",
       "  np.float64(2.0),\n",
       "  np.float64(-2.0),\n",
       "  np.float64(1.0),\n",
       "  np.float64(-1.0),\n",
       "  np.float64(0.0),\n",
       "  np.float64(0.0),\n",
       "  np.float64(3.0),\n",
       "  np.float64(-1.0),\n",
       "  np.float64(-3.0),\n",
       "  np.float64(2.0),\n",
       "  np.float64(1.0),\n",
       "  np.float64(0.0),\n",
       "  np.float64(-2.0),\n",
       "  np.float64(1.0),\n",
       "  np.float64(-2.0),\n",
       "  np.float64(-0.0),\n",
       "  np.float64(-0.0),\n",
       "  np.float64(-1.0),\n",
       "  np.float64(2.0),\n",
       "  np.float64(0.0),\n",
       "  np.float64(-1.0),\n",
       "  np.float64(-3.0),\n",
       "  np.float64(1.0),\n",
       "  np.float64(-2.0),\n",
       "  np.float64(2.0),\n",
       "  np.float64(3.0),\n",
       "  np.float64(3.0),\n",
       "  np.float64(-1.0),\n",
       "  np.float64(4.0),\n",
       "  np.float64(2.0),\n",
       "  np.float64(1.0),\n",
       "  np.float64(1.0),\n",
       "  np.float64(-2.0),\n",
       "  np.float64(-3.0),\n",
       "  np.float64(-1.0),\n",
       "  np.float64(-0.0),\n",
       "  np.float64(-0.0),\n",
       "  np.float64(0.0),\n",
       "  np.float64(2.0),\n",
       "  np.float64(1.0),\n",
       "  np.float64(-4.0),\n",
       "  np.float64(-3.0),\n",
       "  np.float64(-1.0),\n",
       "  np.float64(-2.0),\n",
       "  np.float64(2.0),\n",
       "  np.float64(3.0),\n",
       "  np.float64(1.0),\n",
       "  np.float64(0.0),\n",
       "  np.float64(-0.0),\n",
       "  np.float64(-2.0),\n",
       "  np.float64(-1.0),\n",
       "  np.float64(3.0),\n",
       "  np.float64(-4.0),\n",
       "  np.float64(1.0),\n",
       "  np.float64(-1.0),\n",
       "  np.float64(2.0),\n",
       "  np.float64(1.0),\n",
       "  np.float64(4.0),\n",
       "  np.float64(-2.0),\n",
       "  np.float64(-3.0),\n",
       "  np.float64(-5.0),\n",
       "  np.float64(-1.0),\n",
       "  np.float64(4.0),\n",
       "  np.float64(0.0),\n",
       "  np.float64(0.0),\n",
       "  np.float64(-1.0),\n",
       "  np.float64(9.0),\n",
       "  np.float64(-2.0),\n",
       "  np.float64(2.0),\n",
       "  np.float64(3.0),\n",
       "  np.float64(1.0),\n",
       "  np.float64(-0.0),\n",
       "  np.float64(-0.0),\n",
       "  np.float64(1.0),\n",
       "  np.float64(-3.0),\n",
       "  np.float64(-2.0),\n",
       "  np.float64(-1.0),\n",
       "  np.float64(6.0),\n",
       "  np.float64(2.0),\n",
       "  np.float64(1.0),\n",
       "  np.float64(-4.0),\n",
       "  np.float64(-3.0)],\n",
       " 'y': [np.float64(2.0),\n",
       "  np.float64(3.0),\n",
       "  np.float64(5.0),\n",
       "  np.float64(-13.0),\n",
       "  np.float64(-8.0),\n",
       "  np.float64(-3.0),\n",
       "  np.float64(-0.0),\n",
       "  np.float64(13.0),\n",
       "  np.float64(-12.0),\n",
       "  np.float64(-5.0),\n",
       "  np.float64(1.0),\n",
       "  np.float64(7.0),\n",
       "  np.float64(3.0),\n",
       "  np.float64(-6.0),\n",
       "  np.float64(-9.0),\n",
       "  np.float64(14.0),\n",
       "  np.float64(14.0),\n",
       "  np.float64(-12.0),\n",
       "  np.float64(-14.0),\n",
       "  np.float64(8.0),\n",
       "  np.float64(-14.0),\n",
       "  np.float64(-14.0),\n",
       "  np.float64(-10.0),\n",
       "  np.float64(-3.0),\n",
       "  np.float64(-14.0),\n",
       "  np.float64(-15.0),\n",
       "  np.float64(-10.0),\n",
       "  np.float64(-7.0),\n",
       "  np.float64(-3.0),\n",
       "  np.float64(11.0),\n",
       "  np.float64(-11.0),\n",
       "  np.float64(-15.0),\n",
       "  np.float64(-5.0),\n",
       "  np.float64(-1.0),\n",
       "  np.float64(-8.0),\n",
       "  np.float64(-15.0),\n",
       "  np.float64(3.0),\n",
       "  np.float64(5.0),\n",
       "  np.float64(-12.0),\n",
       "  np.float64(-1.0),\n",
       "  np.float64(-8.0),\n",
       "  np.float64(-13.0),\n",
       "  np.float64(11.0),\n",
       "  np.float64(-5.0),\n",
       "  np.float64(-10.0),\n",
       "  np.float64(-7.0),\n",
       "  np.float64(5.0),\n",
       "  np.float64(-3.0),\n",
       "  np.float64(-13.0),\n",
       "  np.float64(1.0),\n",
       "  np.float64(-11.0),\n",
       "  np.float64(7.0),\n",
       "  np.float64(-15.0),\n",
       "  np.float64(-9.0),\n",
       "  np.float64(-2.0),\n",
       "  np.float64(-6.0),\n",
       "  np.float64(-13.0),\n",
       "  np.float64(-15.0),\n",
       "  np.float64(-11.0),\n",
       "  np.float64(2.0),\n",
       "  np.float64(-4.0),\n",
       "  np.float64(10.0),\n",
       "  np.float64(-9.0),\n",
       "  np.float64(-15.0),\n",
       "  np.float64(-12.0),\n",
       "  np.float64(-14.0),\n",
       "  np.float64(-15.0),\n",
       "  np.float64(-12.0),\n",
       "  np.float64(-14.0),\n",
       "  np.float64(-7.0),\n",
       "  np.float64(-10.0),\n",
       "  np.float64(-13.0),\n",
       "  np.float64(-11.0),\n",
       "  np.float64(-8.0),\n",
       "  np.float64(-15.0),\n",
       "  np.float64(-6.0),\n",
       "  np.float64(-9.0),\n",
       "  np.float64(-12.0),\n",
       "  np.float64(-4.0),\n",
       "  np.float64(-14.0),\n",
       "  np.float64(4.0),\n",
       "  np.float64(-13.0),\n",
       "  np.float64(-10.0),\n",
       "  np.float64(-0.0),\n",
       "  np.float64(13.0),\n",
       "  np.float64(-15.0),\n",
       "  np.float64(-7.0),\n",
       "  np.float64(-6.0),\n",
       "  np.float64(-8.0),\n",
       "  np.float64(9.0),\n",
       "  np.float64(6.0),\n",
       "  np.float64(-11.0),\n",
       "  np.float64(-12.0),\n",
       "  np.float64(-1.0),\n",
       "  np.float64(-4.0),\n",
       "  np.float64(-9.0),\n",
       "  np.float64(1.0),\n",
       "  np.float64(-5.0),\n",
       "  np.float64(-13.0),\n",
       "  np.float64(-2.0),\n",
       "  np.float64(-14.0),\n",
       "  np.float64(-11.0),\n",
       "  np.float64(15.0),\n",
       "  np.float64(-15.0),\n",
       "  np.float64(-10.0),\n",
       "  np.float64(2.0),\n",
       "  np.float64(-12.0),\n",
       "  np.float64(-7.0),\n",
       "  np.float64(-14.0),\n",
       "  np.float64(-13.0),\n",
       "  np.float64(-8.0),\n",
       "  np.float64(-11.0),\n",
       "  np.float64(-15.0),\n",
       "  np.float64(-9.0),\n",
       "  np.float64(4.0),\n",
       "  np.float64(12.0),\n",
       "  np.float64(-14.0),\n",
       "  np.float64(-2.0),\n",
       "  np.float64(-12.0),\n",
       "  np.float64(-5.0),\n",
       "  np.float64(-10.0),\n",
       "  np.float64(8.0),\n",
       "  np.float64(-3.0),\n",
       "  np.float64(-15.0),\n",
       "  np.float64(-8.0),\n",
       "  np.float64(-14.0),\n",
       "  np.float64(-13.0),\n",
       "  np.float64(-10.0),\n",
       "  np.float64(1.0),\n",
       "  np.float64(-5.0),\n",
       "  np.float64(-9.0),\n",
       "  np.float64(-6.0),\n",
       "  np.float64(-11.0),\n",
       "  np.float64(-7.0),\n",
       "  np.float64(-13.0),\n",
       "  np.float64(-4.0),\n",
       "  np.float64(-15.0),\n",
       "  np.float64(6.0),\n",
       "  np.float64(3.0),\n",
       "  np.float64(15.0),\n",
       "  np.float64(-13.0),\n",
       "  np.float64(-11.0),\n",
       "  np.float64(-1.0),\n",
       "  np.float64(-9.0),\n",
       "  np.float64(-12.0),\n",
       "  np.float64(-15.0),\n",
       "  np.float64(-15.0),\n",
       "  np.float64(-14.0),\n",
       "  np.float64(-12.0),\n",
       "  np.float64(-13.0),\n",
       "  np.float64(-10.0),\n",
       "  np.float64(-14.0),\n",
       "  np.float64(-15.0),\n",
       "  np.float64(-11.0),\n",
       "  np.float64(-14.0),\n",
       "  np.float64(-12.0),\n",
       "  np.float64(-15.0),\n",
       "  np.float64(-10.0),\n",
       "  np.float64(-13.0),\n",
       "  np.float64(-11.0),\n",
       "  np.float64(-8.0),\n",
       "  np.float64(-14.0),\n",
       "  np.float64(-12.0),\n",
       "  np.float64(-15.0),\n",
       "  np.float64(-9.0),\n",
       "  np.float64(-7.0),\n",
       "  np.float64(-13.0),\n",
       "  np.float64(11.0),\n",
       "  np.float64(-11.0),\n",
       "  np.float64(-8.0),\n",
       "  np.float64(-6.0),\n",
       "  np.float64(-14.0),\n",
       "  np.float64(-10.0),\n",
       "  np.float64(-15.0),\n",
       "  np.float64(-12.0),\n",
       "  np.float64(-9.0),\n",
       "  np.float64(8.0),\n",
       "  np.float64(-12.0),\n",
       "  np.float64(-15.0),\n",
       "  np.float64(-0.0),\n",
       "  np.float64(-13.0),\n",
       "  np.float64(-13.0),\n",
       "  np.float64(-14.0),\n",
       "  np.float64(-10.0),\n",
       "  np.float64(-14.0),\n",
       "  np.float64(-7.0),\n",
       "  np.float64(-4.0),\n",
       "  np.float64(-11.0),\n",
       "  np.float64(-9.0),\n",
       "  np.float64(13.0),\n",
       "  np.float64(-6.0),\n",
       "  np.float64(9.0),\n",
       "  np.float64(4.0),\n",
       "  np.float64(-15.0),\n",
       "  np.float64(-2.0),\n",
       "  np.float64(14.0),\n",
       "  np.float64(-12.0),\n",
       "  np.float64(-11.0),\n",
       "  np.float64(-8.0),\n",
       "  np.float64(6.0),\n",
       "  np.float64(-14.0),\n",
       "  np.float64(-13.0),\n",
       "  np.float64(-3.0),\n",
       "  np.float64(-5.0),\n",
       "  np.float64(-15.0),\n",
       "  np.float64(-12.0),\n",
       "  np.float64(-10.0),\n",
       "  np.float64(-1.0),\n",
       "  np.float64(-9.0),\n",
       "  np.float64(-14.0),\n",
       "  np.float64(2.0),\n",
       "  np.float64(-13.0),\n",
       "  np.float64(-7.0),\n",
       "  np.float64(-11.0),\n",
       "  np.float64(3.0),\n",
       "  np.float64(-8.0),\n",
       "  np.float64(-15.0),\n",
       "  np.float64(-10.0),\n",
       "  np.float64(-12.0),\n",
       "  np.float64(-14.0),\n",
       "  np.float64(-13.0),\n",
       "  np.float64(-15.0),\n",
       "  np.float64(-6.0),\n",
       "  np.float64(7.0),\n",
       "  np.float64(-15.0),\n",
       "  np.float64(-4.0),\n",
       "  np.float64(-10.0),\n",
       "  np.float64(-13.0),\n",
       "  np.float64(-11.0),\n",
       "  np.float64(-14.0),\n",
       "  np.float64(-9.0),\n",
       "  np.float64(-12.0),\n",
       "  np.float64(10.0),\n",
       "  np.float64(-15.0),\n",
       "  np.float64(-13.0),\n",
       "  np.float64(1.0),\n",
       "  np.float64(-11.0),\n",
       "  np.float64(-14.0),\n",
       "  np.float64(-7.0),\n",
       "  np.float64(5.0),\n",
       "  np.float64(-5.0),\n",
       "  np.float64(12.0),\n",
       "  np.float64(-8.0),\n",
       "  np.float64(-12.0),\n",
       "  np.float64(-15.0),\n",
       "  np.float64(-10.0),\n",
       "  np.float64(-13.0),\n",
       "  np.float64(-14.0),\n",
       "  np.float64(-3.0),\n",
       "  np.float64(-6.0),\n",
       "  np.float64(-9.0),\n",
       "  np.float64(-11.0),\n",
       "  np.float64(-10.0),\n",
       "  np.float64(-13.0),\n",
       "  np.float64(-12.0),\n",
       "  np.float64(-0.0),\n",
       "  np.float64(-15.0),\n",
       "  np.float64(-15.0),\n",
       "  np.float64(-15.0),\n",
       "  np.float64(-14.0),\n",
       "  np.float64(-13.0),\n",
       "  np.float64(-15.0),\n",
       "  np.float64(-12.0),\n",
       "  np.float64(-14.0),\n",
       "  np.float64(-14.0),\n",
       "  np.float64(-12.0),\n",
       "  np.float64(-15.0),\n",
       "  np.float64(-11.0),\n",
       "  np.float64(-14.0),\n",
       "  np.float64(-11.0),\n",
       "  np.float64(-13.0),\n",
       "  np.float64(-12.0),\n",
       "  np.float64(-14.0),\n",
       "  np.float64(-15.0),\n",
       "  np.float64(-15.0),\n",
       "  np.float64(-9.0),\n",
       "  np.float64(-15.0),\n",
       "  np.float64(-13.0),\n",
       "  np.float64(-13.0),\n",
       "  np.float64(-8.0),\n",
       "  np.float64(-11.0),\n",
       "  np.float64(-10.0),\n",
       "  np.float64(-14.0),\n",
       "  np.float64(-12.0),\n",
       "  np.float64(-14.0),\n",
       "  np.float64(-15.0),\n",
       "  np.float64(-10.0),\n",
       "  np.float64(-13.0),\n",
       "  np.float64(-12.0),\n",
       "  np.float64(-9.0),\n",
       "  np.float64(-15.0),\n",
       "  np.float64(-11.0),\n",
       "  np.float64(7.0),\n",
       "  np.float64(-13.0),\n",
       "  np.float64(-7.0),\n",
       "  np.float64(-14.0),\n",
       "  np.float64(-8.0),\n",
       "  np.float64(-11.0),\n",
       "  np.float64(-12.0),\n",
       "  np.float64(5.0),\n",
       "  np.float64(-15.0),\n",
       "  np.float64(-10.0),\n",
       "  np.float64(-14.0),\n",
       "  np.float64(-12.0),\n",
       "  np.float64(-2.0),\n",
       "  np.float64(1.0),\n",
       "  np.float64(10.0),\n",
       "  np.float64(-13.0),\n",
       "  np.float64(-9.0),\n",
       "  np.float64(-15.0),\n",
       "  np.float64(-15.0),\n",
       "  np.float64(2.0),\n",
       "  np.float64(-14.0),\n",
       "  np.float64(9.0),\n",
       "  np.float64(-13.0),\n",
       "  np.float64(-11.0),\n",
       "  np.float64(-7.0),\n",
       "  np.float64(-6.0),\n",
       "  np.float64(-10.0),\n",
       "  np.float64(-15.0),\n",
       "  np.float64(-14.0),\n",
       "  np.float64(-12.0),\n",
       "  np.float64(14.0),\n",
       "  np.float64(-13.0),\n",
       "  np.float64(-8.0),\n",
       "  np.float64(-11.0),\n",
       "  np.float64(-12.0),\n",
       "  np.float64(-15.0),\n",
       "  np.float64(-3.0),\n",
       "  np.float64(-13.0),\n",
       "  np.float64(-10.0),\n",
       "  np.float64(-14.0),\n",
       "  np.float64(-5.0),\n",
       "  np.float64(-11.0),\n",
       "  np.float64(-1.0),\n",
       "  np.float64(-14.0),\n",
       "  np.float64(4.0),\n",
       "  np.float64(-12.0),\n",
       "  np.float64(-15.0),\n",
       "  np.float64(-9.0),\n",
       "  np.float64(12.0),\n",
       "  np.float64(-8.0),\n",
       "  np.float64(-4.0),\n",
       "  np.float64(-13.0),\n",
       "  np.float64(-14.0),\n",
       "  np.float64(-13.0),\n",
       "  np.float64(-10.0),\n",
       "  np.float64(-11.0),\n",
       "  np.float64(-12.0),\n",
       "  np.float64(-15.0),\n",
       "  np.float64(-9.0),\n",
       "  np.float64(-14.0),\n",
       "  np.float64(6.0),\n",
       "  np.float64(-7.0),\n",
       "  np.float64(-15.0),\n",
       "  np.float64(-12.0),\n",
       "  np.float64(15.0),\n",
       "  np.float64(-13.0),\n",
       "  np.float64(-2.0),\n",
       "  np.float64(-11.0),\n",
       "  np.float64(-15.0),\n",
       "  np.float64(-10.0),\n",
       "  np.float64(-15.0),\n",
       "  np.float64(-12.0),\n",
       "  np.float64(-13.0),\n",
       "  np.float64(-14.0),\n",
       "  np.float64(-14.0),\n",
       "  np.float64(-8.0),\n",
       "  np.float64(-13.0),\n",
       "  np.float64(-5.0),\n",
       "  np.float64(-9.0),\n",
       "  np.float64(3.0),\n",
       "  np.float64(-15.0),\n",
       "  np.float64(-10.0),\n",
       "  np.float64(-11.0),\n",
       "  np.float64(-14.0),\n",
       "  np.float64(0.0),\n",
       "  np.float64(-6.0),\n",
       "  np.float64(-12.0),\n",
       "  np.float64(8.0),\n",
       "  np.float64(11.0),\n",
       "  np.float64(-11.0),\n",
       "  np.float64(-9.0),\n",
       "  np.float64(-13.0),\n",
       "  np.float64(-10.0),\n",
       "  np.float64(-14.0),\n",
       "  np.float64(-12.0),\n",
       "  np.float64(-15.0),\n",
       "  np.float64(-8.0),\n",
       "  np.float64(-13.0),\n",
       "  np.float64(-15.0),\n",
       "  np.float64(-4.0),\n",
       "  np.float64(-7.0),\n",
       "  np.float64(-14.0),\n",
       "  np.float64(-11.0),\n",
       "  np.float64(13.0),\n",
       "  np.float64(-9.0),\n",
       "  np.float64(-12.0),\n",
       "  np.float64(-13.0),\n",
       "  np.float64(-15.0),\n",
       "  np.float64(-14.0),\n",
       "  np.float64(-15.0),\n",
       "  np.float64(-15.0),\n",
       "  np.float64(-15.0),\n",
       "  np.float64(-14.0),\n",
       "  np.float64(-13.0),\n",
       "  np.float64(-15.0),\n",
       "  np.float64(-14.0),\n",
       "  np.float64(-13.0),\n",
       "  np.float64(-12.0),\n",
       "  np.float64(-14.0),\n",
       "  np.float64(-14.0),\n",
       "  np.float64(-13.0),\n",
       "  np.float64(-15.0),\n",
       "  np.float64(-12.0),\n",
       "  np.float64(-11.0),\n",
       "  np.float64(-15.0),\n",
       "  np.float64(-14.0),\n",
       "  np.float64(-13.0),\n",
       "  np.float64(-12.0),\n",
       "  np.float64(-15.0),\n",
       "  np.float64(-10.0),\n",
       "  np.float64(-11.0),\n",
       "  np.float64(-12.0),\n",
       "  np.float64(-15.0),\n",
       "  np.float64(-13.0),\n",
       "  np.float64(-14.0),\n",
       "  np.float64(-11.0),\n",
       "  np.float64(-15.0),\n",
       "  np.float64(-13.0),\n",
       "  np.float64(-14.0),\n",
       "  np.float64(-10.0),\n",
       "  np.float64(-12.0),\n",
       "  np.float64(-15.0),\n",
       "  np.float64(2.0),\n",
       "  np.float64(-15.0),\n",
       "  np.float64(-14.0),\n",
       "  np.float64(-15.0),\n",
       "  np.float64(-13.0),\n",
       "  np.float64(-11.0),\n",
       "  np.float64(-13.0),\n",
       "  np.float64(-12.0),\n",
       "  np.float64(-14.0),\n",
       "  np.float64(-14.0),\n",
       "  np.float64(-9.0),\n",
       "  np.float64(-12.0),\n",
       "  np.float64(-11.0),\n",
       "  np.float64(-10.0),\n",
       "  np.float64(7.0),\n",
       "  np.float64(5.0),\n",
       "  np.float64(-13.0),\n",
       "  np.float64(-14.0),\n",
       "  np.float64(1.0),\n",
       "  np.float64(-15.0),\n",
       "  np.float64(-15.0),\n",
       "  np.float64(-13.0),\n",
       "  np.float64(-15.0),\n",
       "  np.float64(4.0),\n",
       "  np.float64(-8.0),\n",
       "  np.float64(-11.0),\n",
       "  np.float64(-12.0),\n",
       "  np.float64(10.0),\n",
       "  np.float64(-14.0),\n",
       "  np.float64(-10.0),\n",
       "  np.float64(-13.0),\n",
       "  np.float64(-15.0),\n",
       "  np.float64(-9.0),\n",
       "  np.float64(-13.0),\n",
       "  np.float64(-1.0),\n",
       "  np.float64(-10.0),\n",
       "  np.float64(-12.0),\n",
       "  np.float64(-14.0),\n",
       "  np.float64(-12.0),\n",
       "  np.float64(-15.0),\n",
       "  np.float64(-11.0),\n",
       "  np.float64(-14.0),\n",
       "  np.float64(9.0),\n",
       "  np.float64(-14.0),\n",
       "  np.float64(-7.0),\n",
       "  np.float64(-13.0),\n",
       "  np.float64(-12.0),\n",
       "  np.float64(-15.0),\n",
       "  np.float64(-15.0),\n",
       "  np.float64(-9.0),\n",
       "  np.float64(-11.0),\n",
       "  np.float64(-13.0),\n",
       "  np.float64(-10.0),\n",
       "  np.float64(-6.0),\n",
       "  np.float64(-14.0),\n",
       "  np.float64(-15.0),\n",
       "  np.float64(-11.0),\n",
       "  np.float64(-3.0),\n",
       "  np.float64(14.0),\n",
       "  np.float64(-8.0),\n",
       "  np.float64(-12.0),\n",
       "  np.float64(-13.0),\n",
       "  np.float64(-13.0),\n",
       "  np.float64(-14.0),\n",
       "  np.float64(-9.0),\n",
       "  np.float64(-14.0)]}"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trials.vals"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1adcfa23",
   "metadata": {},
   "source": [
    "- hyperopt를 활용한 XGBoost 하이퍼 파라미터 튜닝"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "8b9b8dd8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|██████████| 50/50 [00:11<00:00,  4.21trial/s, best loss: -0.9741784037558686]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'colsample_bytree': np.float64(0.5010247093957608),\n",
       " 'learning_rate': np.float64(0.16532913013986236),\n",
       " 'max_dapth': np.float64(6.0),\n",
       " 'n_estimators': np.float64(500.0)}"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from xgboost import XGBClassifier\n",
    "from sklearn.datasets import load_breast_cancer\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "from hyperopt import fmin, tpe, Trials, hp\n",
    "import hyperopt\n",
    "\n",
    "# 0. 데이터 로드 및 분리\n",
    "data = load_breast_cancer()\n",
    "X_train, X_test, y_train, y_test = train_test_split(data.data, data.target, random_state=42)\n",
    "\n",
    "# 1. 검색 공간\n",
    "search_space = {\n",
    "    'n_estimators': hp.quniform('n_estimators', 100, 500, 100),\n",
    "    'max_depth': hp.quniform('max_dapth', 3, 10, 1),\n",
    "    'learning_rate': hp.uniform('learning_rate', 0.01, 0.2),\n",
    "    'colsample_bytree': hp.uniform('colsample_bytree', 0.5, 1)\n",
    "}\n",
    "\n",
    "# 2. 목적 함수\n",
    "def xgb_objective(ss):\n",
    "    xgb_clf = XGBClassifier(\n",
    "        n_estimators=int(ss['n_estimators']),\n",
    "        max_depth=int(ss['max_depth']),\n",
    "        learning_rate=ss['learning_rate'],\n",
    "        colsample_bytree=ss['colsample_bytree']\n",
    "    )\n",
    "    mean_acc = cross_val_score(xgb_clf, X_train, y_train, scoring='accuracy', cv=3).mean()\n",
    "    return {\n",
    "        'loss': -1 * mean_acc,\n",
    "        'status': hyperopt.STATUS_OK\n",
    "    }\n",
    "\n",
    "# 3. Trials() + fmin()\n",
    "trials = Trials()\n",
    "best = fmin(\n",
    "    fn=xgb_objective,\n",
    "    space=search_space,\n",
    "    algo=tpe.suggest,\n",
    "    max_evals=50,\n",
    "    trials=trials\n",
    ")\n",
    "\n",
    "best"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff5664b3",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9a66293",
   "metadata": {},
   "source": [
    "### Optuna"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7fe9558",
   "metadata": {},
   "source": [
    "<table border=\"1\">\n",
    "    <thead>\n",
    "        <tr>\n",
    "            <th>함수명</th>\n",
    "            <th>설명</th>\n",
    "            <th>사용 방법</th>\n",
    "            <th>예시 코드</th>\n",
    "        </tr>\n",
    "    </thead>\n",
    "    <tbody>\n",
    "        <tr>\n",
    "            <td>suggest_uniform</td>\n",
    "            <td>연속적인 실수 값 샘플링</td>\n",
    "            <td>trial.suggest_uniform(name, low, high)</td>\n",
    "            <td><code>trial.suggest_uniform('learning_rate', 0.01, 0.1)</code></td>\n",
    "        </tr>\n",
    "        <tr>\n",
    "            <td>suggest_discrete_uniform</td>\n",
    "            <td>연속적이지만 일정 간격(step)을 갖는 값 샘플링</td>\n",
    "            <td>trial.suggest_discrete_uniform(name, low, high, step)</td>\n",
    "            <td><code>trial.suggest_discrete_uniform('num_layers', 1, 5, 1)</code></td>\n",
    "        </tr>\n",
    "        <tr>\n",
    "            <td>suggest_loguniform</td>\n",
    "            <td>로그 스케일로 분포된 실수 값 샘플링</td>\n",
    "            <td>trial.suggest_loguniform(name, low, high)</td>\n",
    "            <td><code>trial.suggest_loguniform('reg_param', 1e-3, 1)</code></td>\n",
    "        </tr>\n",
    "        <tr>\n",
    "            <td>suggest_int</td>\n",
    "            <td>정수 값 샘플링</td>\n",
    "            <td>trial.suggest_int(name, low, high, step)</td>\n",
    "            <td><code>trial.suggest_int('num_trees', 1, 100)</code></td>\n",
    "        </tr>\n",
    "        <tr>\n",
    "            <td>suggest_categorical</td>\n",
    "            <td>주어진 리스트 중 임의의 값 샘플링</td>\n",
    "            <td>trial.suggest_categorical(name, choices)</td>\n",
    "            <td><code>trial.suggest_categorical('optimizer', ['adam', 'sgd', 'rmsprop'])</code></td>\n",
    "        </tr>\n",
    "        <tr>\n",
    "            <td>suggest_float</td>\n",
    "            <td>연속적인 실수 값 샘플링 (<code>step</code> 사용 가능)</td>\n",
    "            <td>trial.suggest_float(name, low, high, step=None, log=False)</td>\n",
    "            <td><code>trial.suggest_float('alpha', 0.1, 1.0, step=0.1)</code></td>\n",
    "        </tr>\n",
    "    </tbody>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "738b9de7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install optuna"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "7378b027",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-11 10:26:12,336] A new study created in memory with name: no-name-955652d4-4ae6-425b-b854-6ea4efb1c509\n",
      "C:\\Users\\Playdata\\AppData\\Local\\Temp\\ipykernel_9840\\2037294840.py:5: FutureWarning:\n",
      "\n",
      "suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
      "\n",
      "C:\\Users\\Playdata\\AppData\\Local\\Temp\\ipykernel_9840\\2037294840.py:6: FutureWarning:\n",
      "\n",
      "suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
      "\n",
      "[I 2025-08-11 10:26:12,339] Trial 0 finished with value: 169.68452849813104 and parameters: {'x': -8.110586402710407, 'y': 1.7999557561823636}. Best is trial 0 with value: 169.68452849813104.\n",
      "[I 2025-08-11 10:26:12,340] Trial 1 finished with value: 218.09856034625034 and parameters: {'x': -8.926865548109252, 'y': -13.709100903283584}. Best is trial 0 with value: 169.68452849813104.\n",
      "[I 2025-08-11 10:26:12,341] Trial 2 finished with value: 28.79093183574342 and parameters: {'x': 5.836177193435702, 'y': -0.4451091381704213}. Best is trial 2 with value: 28.79093183574342.\n",
      "[I 2025-08-11 10:26:12,342] Trial 3 finished with value: 198.7464772705225 and parameters: {'x': 9.968971831498635, 'y': 7.25479126229007}. Best is trial 2 with value: 28.79093183574342.\n",
      "[I 2025-08-11 10:26:12,343] Trial 4 finished with value: 47.867473878610646 and parameters: {'x': -3.7233065711089353, 'y': -6.632367185866604}. Best is trial 2 with value: 28.79093183574342.\n",
      "[I 2025-08-11 10:26:12,344] Trial 5 finished with value: 80.29378765063848 and parameters: {'x': 9.572561845113498, 'y': 1.090584408970681}. Best is trial 2 with value: 28.79093183574342.\n",
      "[I 2025-08-11 10:26:12,345] Trial 6 finished with value: 111.59862009039892 and parameters: {'x': -6.492533934185047, 'y': -9.635776051401132}. Best is trial 2 with value: 28.79093183574342.\n",
      "[I 2025-08-11 10:26:12,346] Trial 7 finished with value: 45.311983574566334 and parameters: {'x': 1.1781784366870802, 'y': -11.480196738218247}. Best is trial 2 with value: 28.79093183574342.\n",
      "[I 2025-08-11 10:26:12,347] Trial 8 finished with value: 68.64753861608453 and parameters: {'x': -3.215284564479715, 'y': 0.4788480904862418}. Best is trial 2 with value: 28.79093183574342.\n",
      "[I 2025-08-11 10:26:12,348] Trial 9 finished with value: 216.50510672658362 and parameters: {'x': -9.859214547652499, 'y': -12.151622749000815}. Best is trial 2 with value: 28.79093183574342.\n",
      "[I 2025-08-11 10:26:12,356] Trial 10 finished with value: 374.7464023183077 and parameters: {'x': 3.904018841940897, 'y': 14.33724779413357}. Best is trial 2 with value: 28.79093183574342.\n",
      "[I 2025-08-11 10:26:12,364] Trial 11 finished with value: 0.13945106485291422 and parameters: {'x': 3.348854106582806, 'y': -4.866763829335925}. Best is trial 11 with value: 0.13945106485291422.\n",
      "[I 2025-08-11 10:26:12,371] Trial 12 finished with value: 6.342224515479275 and parameters: {'x': 5.158855882983362, 'y': -3.703247983619303}. Best is trial 11 with value: 0.13945106485291422.\n",
      "[I 2025-08-11 10:26:12,380] Trial 13 finished with value: 4.253606722159322 and parameters: {'x': 5.021972513644087, 'y': -4.593510299974115}. Best is trial 11 with value: 0.13945106485291422.\n",
      "[I 2025-08-11 10:26:12,388] Trial 14 finished with value: 2.1798324588656524 and parameters: {'x': 1.7400667786088748, 'y': -5.769675734644554}. Best is trial 11 with value: 0.13945106485291422.\n",
      "[I 2025-08-11 10:26:12,395] Trial 15 finished with value: 117.94523572421785 and parameters: {'x': 0.6698174653052624, 'y': 5.60733166631559}. Best is trial 11 with value: 0.13945106485291422.\n",
      "[I 2025-08-11 10:26:12,404] Trial 16 finished with value: 33.0489762854837 and parameters: {'x': -2.2627372342729783, 'y': -7.313562855960585}. Best is trial 11 with value: 0.13945106485291422.\n",
      "[I 2025-08-11 10:26:12,411] Trial 17 finished with value: 7.349294362444711 and parameters: {'x': 1.2739049735591785, 'y': -2.909571737145479}. Best is trial 11 with value: 0.13945106485291422.\n",
      "[I 2025-08-11 10:26:12,414] Trial 18 finished with value: 11.376432914769293 and parameters: {'x': 3.2152230077988437, 'y': -8.366023168619508}. Best is trial 11 with value: 0.13945106485291422.\n",
      "[I 2025-08-11 10:26:12,419] Trial 19 finished with value: 104.50497831687464 and parameters: {'x': 7.360619434342492, 'y': 4.246078977907835}. Best is trial 11 with value: 0.13945106485291422.\n",
      "[I 2025-08-11 10:26:12,429] Trial 20 finished with value: 231.16791452913225 and parameters: {'x': -1.5938962042748055, 'y': 9.493585898371796}. Best is trial 11 with value: 0.13945106485291422.\n",
      "[I 2025-08-11 10:26:12,429] Trial 21 finished with value: 0.16159845004157633 and parameters: {'x': 2.898094470118064, 'y': -4.611137925452921}. Best is trial 11 with value: 0.13945106485291422.\n",
      "[I 2025-08-11 10:26:12,439] Trial 22 finished with value: 0.16151304154714283 and parameters: {'x': 2.6046754067439113, 'y': -5.072329160883083}. Best is trial 11 with value: 0.13945106485291422.\n",
      "[I 2025-08-11 10:26:12,439] Trial 23 finished with value: 5.531997231388986 and parameters: {'x': 2.725413381621747, 'y': -2.6640634810858876}. Best is trial 11 with value: 0.13945106485291422.\n",
      "[I 2025-08-11 10:26:12,449] Trial 24 finished with value: 35.781097499597976 and parameters: {'x': -0.8395786234197526, 'y': -9.58679991869888}. Best is trial 11 with value: 0.13945106485291422.\n",
      "[I 2025-08-11 10:26:12,449] Trial 25 finished with value: 30.650605057805073 and parameters: {'x': 7.152684662674476, 'y': -1.3386047536228425}. Best is trial 11 with value: 0.13945106485291422.\n",
      "[I 2025-08-11 10:26:12,459] Trial 26 finished with value: 0.9016158171935257 and parameters: {'x': 3.855463156044816, 'y': -5.412066263898621}. Best is trial 11 with value: 0.13945106485291422.\n",
      "[I 2025-08-11 10:26:12,459] Trial 27 finished with value: 80.14228841267426 and parameters: {'x': -0.495817810685244, 'y': 3.2414529208853757}. Best is trial 11 with value: 0.13945106485291422.\n",
      "[I 2025-08-11 10:26:12,474] Trial 28 finished with value: 21.27841596829137 and parameters: {'x': 6.967505300520887, 'y': -2.646849418624037}. Best is trial 11 with value: 0.13945106485291422.\n",
      "[I 2025-08-11 10:26:12,474] Trial 29 finished with value: 93.87267401544248 and parameters: {'x': -5.3931409029401145, 'y': -9.84023344466319}. Best is trial 11 with value: 0.13945106485291422.\n",
      "[I 2025-08-11 10:26:12,484] Trial 30 finished with value: 51.132446686284325 and parameters: {'x': 2.5176682521852065, 'y': 2.1344097703548153}. Best is trial 11 with value: 0.13945106485291422.\n",
      "[I 2025-08-11 10:26:12,484] Trial 31 finished with value: 2.76152918503606 and parameters: {'x': 4.643619873885426, 'y': -5.245036518104782}. Best is trial 11 with value: 0.13945106485291422.\n",
      "[I 2025-08-11 10:26:12,494] Trial 32 finished with value: 6.290456483345596 and parameters: {'x': 3.2958376205489666, 'y': -7.4905695303712205}. Best is trial 11 with value: 0.13945106485291422.\n",
      "[I 2025-08-11 10:26:12,494] Trial 33 finished with value: 20.472449731214603 and parameters: {'x': 6.069835141941528, 'y': -1.676062285102887}. Best is trial 11 with value: 0.13945106485291422.\n",
      "[I 2025-08-11 10:26:12,504] Trial 34 finished with value: 106.21307291975768 and parameters: {'x': 8.4255690955417, 'y': -13.762207079797903}. Best is trial 11 with value: 0.13945106485291422.\n",
      "[I 2025-08-11 10:26:12,517] Trial 35 finished with value: 1.0292473807444293 and parameters: {'x': 4.007515933717282, 'y': -4.881008302599622}. Best is trial 11 with value: 0.13945106485291422.\n",
      "[I 2025-08-11 10:26:12,530] Trial 36 finished with value: 27.91711467650979 and parameters: {'x': 0.38043130770357747, 'y': -0.4114300111200002}. Best is trial 11 with value: 0.13945106485291422.\n",
      "[I 2025-08-11 10:26:12,538] Trial 37 finished with value: 2.9866376822838046 and parameters: {'x': 2.24713729525687, 'y': -6.555582022938895}. Best is trial 11 with value: 0.13945106485291422.\n",
      "[I 2025-08-11 10:26:12,545] Trial 38 finished with value: 56.735028740355 and parameters: {'x': 6.257952248336002, 'y': -11.791227863053734}. Best is trial 11 with value: 0.13945106485291422.\n",
      "[I 2025-08-11 10:26:12,549] Trial 39 finished with value: 128.8133281444933 and parameters: {'x': 8.606602899080986, 'y': -14.868096679527921}. Best is trial 11 with value: 0.13945106485291422.\n",
      "[I 2025-08-11 10:26:12,558] Trial 40 finished with value: 16.580491357456374 and parameters: {'x': 4.430500981271713, 'y': -8.8123691190698}. Best is trial 11 with value: 0.13945106485291422.\n",
      "[I 2025-08-11 10:26:12,564] Trial 41 finished with value: 1.1820565716299125 and parameters: {'x': 3.6595045602505074, 'y': -4.1356445715802455}. Best is trial 11 with value: 0.13945106485291422.\n",
      "[I 2025-08-11 10:26:12,568] Trial 42 finished with value: 2.0590773262977558 and parameters: {'x': 1.900706013789754, 'y': -5.9222960794559105}. Best is trial 11 with value: 0.13945106485291422.\n",
      "[I 2025-08-11 10:26:12,571] Trial 43 finished with value: 5.513521089024907 and parameters: {'x': 5.334791257812639, 'y': -4.7504586778375515}. Best is trial 11 with value: 0.13945106485291422.\n",
      "[I 2025-08-11 10:26:12,578] Trial 44 finished with value: 12.204345884370692 and parameters: {'x': 4.0083733840401425, 'y': -1.6552236244062408}. Best is trial 11 with value: 0.13945106485291422.\n",
      "[I 2025-08-11 10:26:12,578] Trial 45 finished with value: 14.329372750179612 and parameters: {'x': 0.10692439637576578, 'y': -7.441205911408106}. Best is trial 11 with value: 0.13945106485291422.\n",
      "[I 2025-08-11 10:26:12,592] Trial 46 finished with value: 33.494541624078394 and parameters: {'x': 1.1056345372771275, 'y': -10.468630643746307}. Best is trial 11 with value: 0.13945106485291422.\n",
      "[I 2025-08-11 10:26:12,592] Trial 47 finished with value: 41.01208975630721 and parameters: {'x': 2.903799947046795, 'y': 1.40334563381667}. Best is trial 11 with value: 0.13945106485291422.\n",
      "[I 2025-08-11 10:26:12,598] Trial 48 finished with value: 31.849713085511176 and parameters: {'x': 5.624376941289036, 'y': -0.003765542376781699}. Best is trial 11 with value: 0.13945106485291422.\n",
      "[I 2025-08-11 10:26:12,608] Trial 49 finished with value: 3.0818796430950557 and parameters: {'x': 4.472760360601843, 'y': -4.0445647257218384}. Best is trial 11 with value: 0.13945106485291422.\n",
      "[I 2025-08-11 10:26:12,608] Trial 50 finished with value: 4.444771610935387 and parameters: {'x': 1.8614511942606178, 'y': -3.225604827586365}. Best is trial 11 with value: 0.13945106485291422.\n",
      "[I 2025-08-11 10:26:12,619] Trial 51 finished with value: 1.3576927768085991 and parameters: {'x': 4.096966876180424, 'y': -4.607117766536128}. Best is trial 11 with value: 0.13945106485291422.\n",
      "[I 2025-08-11 10:26:12,619] Trial 52 finished with value: 2.0078172582812988 and parameters: {'x': 3.5841325744840606, 'y': -6.290971104908209}. Best is trial 11 with value: 0.13945106485291422.\n",
      "[I 2025-08-11 10:26:12,629] Trial 53 finished with value: 1.9174345227104432 and parameters: {'x': 3.6656204460864954, 'y': -3.78575787239033}. Best is trial 11 with value: 0.13945106485291422.\n",
      "[I 2025-08-11 10:26:12,633] Trial 54 finished with value: 13.785171582049635 and parameters: {'x': 1.130010025630595, 'y': -8.207539411730984}. Best is trial 11 with value: 0.13945106485291422.\n",
      "[I 2025-08-11 10:26:12,641] Trial 55 finished with value: 0.6526585151122586 and parameters: {'x': 2.7195476203818005, 'y': -5.757631162161871}. Best is trial 11 with value: 0.13945106485291422.\n",
      "[I 2025-08-11 10:26:12,643] Trial 56 finished with value: 0.5715226017612687 and parameters: {'x': 2.476600713096297, 'y': -5.545505076264157}. Best is trial 11 with value: 0.13945106485291422.\n",
      "[I 2025-08-11 10:26:12,643] Trial 57 finished with value: 19.71530601799366 and parameters: {'x': -0.8941252584371862, 'y': -7.13332943766198}. Best is trial 11 with value: 0.13945106485291422.\n",
      "[I 2025-08-11 10:26:12,658] Trial 58 finished with value: 7.614863537253336 and parameters: {'x': 2.5114762279221456, 'y': -2.284082464181182}. Best is trial 11 with value: 0.13945106485291422.\n",
      "[I 2025-08-11 10:26:12,658] Trial 59 finished with value: 2.896557565126603 and parameters: {'x': 1.55029336091275, 'y': -5.891576259056371}. Best is trial 11 with value: 0.13945106485291422.\n",
      "[I 2025-08-11 10:26:12,667] Trial 60 finished with value: 69.52724950199725 and parameters: {'x': -3.0001558635854755, 'y': -10.79011045789958}. Best is trial 11 with value: 0.13945106485291422.\n",
      "[I 2025-08-11 10:26:12,674] Trial 61 finished with value: 0.11673220944970891 and parameters: {'x': 2.973647230704504, 'y': -5.34064312850866}. Best is trial 61 with value: 0.11673220944970891.\n",
      "[I 2025-08-11 10:26:12,679] Trial 62 finished with value: 19.032232391011597 and parameters: {'x': 5.123849349700472, 'y': -8.810708114089621}. Best is trial 61 with value: 0.11673220944970891.\n",
      "[I 2025-08-11 10:26:12,684] Trial 63 finished with value: 0.1105309959386112 and parameters: {'x': 2.9621790695743204, 'y': -5.330303758925549}. Best is trial 63 with value: 0.1105309959386112.\n",
      "[I 2025-08-11 10:26:12,684] Trial 64 finished with value: 330.02526259983284 and parameters: {'x': 3.1159598042696923, 'y': 13.166227344267897}. Best is trial 63 with value: 0.1105309959386112.\n",
      "[I 2025-08-11 10:26:12,695] Trial 65 finished with value: 13.70034408175564 and parameters: {'x': 2.2157028474334917, 'y': -1.3826498568383365}. Best is trial 63 with value: 0.1105309959386112.\n",
      "[I 2025-08-11 10:26:12,701] Trial 66 finished with value: 7.134135598048483 and parameters: {'x': 0.8801533314835208, 'y': -3.375073632428821}. Best is trial 63 with value: 0.1105309959386112.\n",
      "[I 2025-08-11 10:26:12,706] Trial 67 finished with value: 19.486716472308526 and parameters: {'x': -0.3430490693593391, 'y': -7.882835304377304}. Best is trial 63 with value: 0.1105309959386112.\n",
      "[I 2025-08-11 10:26:12,709] Trial 68 finished with value: 23.588103894270645 and parameters: {'x': -1.541135014039524, 'y': -6.722264984993569}. Best is trial 63 with value: 0.1105309959386112.\n",
      "[I 2025-08-11 10:26:12,709] Trial 69 finished with value: 0.049758510577362525 and parameters: {'x': 2.8308756536630293, 'y': -5.14544918718733}. Best is trial 69 with value: 0.049758510577362525.\n",
      "[I 2025-08-11 10:26:12,720] Trial 70 finished with value: 12.745789635284227 and parameters: {'x': 0.6938479267451059, 'y': -2.2746647453374877}. Best is trial 69 with value: 0.049758510577362525.\n",
      "[I 2025-08-11 10:26:12,720] Trial 71 finished with value: 0.08982390182431449 and parameters: {'x': 2.764476914558115, 'y': -5.185345024341764}. Best is trial 69 with value: 0.049758510577362525.\n",
      "[I 2025-08-11 10:26:12,730] Trial 72 finished with value: 129.59132027345967 and parameters: {'x': -8.372837241434645, 'y': -5.499893341920913}. Best is trial 69 with value: 0.049758510577362525.\n",
      "[I 2025-08-11 10:26:12,730] Trial 73 finished with value: 19.3017621222766 and parameters: {'x': 1.8666038424396667, 'y': -9.244664329756132}. Best is trial 69 with value: 0.049758510577362525.\n",
      "[I 2025-08-11 10:26:12,740] Trial 74 finished with value: 0.6054347458000364 and parameters: {'x': 3.202546550000295, 'y': -4.248727984759838}. Best is trial 69 with value: 0.049758510577362525.\n",
      "[I 2025-08-11 10:26:12,740] Trial 75 finished with value: 3.0408555253179808 and parameters: {'x': 2.4138167214152926, 'y': -6.642329044139957}. Best is trial 69 with value: 0.049758510577362525.\n",
      "[I 2025-08-11 10:26:12,750] Trial 76 finished with value: 21.26387537793923 and parameters: {'x': 4.420412174801866, 'y': -0.6129389528280029}. Best is trial 69 with value: 0.049758510577362525.\n",
      "[I 2025-08-11 10:26:12,760] Trial 77 finished with value: 7.070847096675649 and parameters: {'x': 4.929846506509724, 'y': -3.170645043194771}. Best is trial 69 with value: 0.049758510577362525.\n",
      "[I 2025-08-11 10:26:12,760] Trial 78 finished with value: 13.66831978543052 and parameters: {'x': 6.6950023767848945, 'y': -4.8763989442419735}. Best is trial 69 with value: 0.049758510577362525.\n",
      "[I 2025-08-11 10:26:12,760] Trial 79 finished with value: 10.414110077883944 and parameters: {'x': 1.442766277291786, 'y': -7.826505476864367}. Best is trial 69 with value: 0.049758510577362525.\n",
      "[I 2025-08-11 10:26:12,776] Trial 80 finished with value: 59.09236879136305 and parameters: {'x': 3.07254497900527, 'y': -12.68681377538081}. Best is trial 69 with value: 0.049758510577362525.\n",
      "[I 2025-08-11 10:26:12,776] Trial 81 finished with value: 0.5569889402593455 and parameters: {'x': 3.3287026338975636, 'y': -4.329967524124278}. Best is trial 69 with value: 0.049758510577362525.\n",
      "[I 2025-08-11 10:26:12,784] Trial 82 finished with value: 1.3106982464643973 and parameters: {'x': 2.775317071380151, 'y': -3.877406650629354}. Best is trial 69 with value: 0.049758510577362525.\n",
      "[I 2025-08-11 10:26:12,792] Trial 83 finished with value: 0.1760980597950048 and parameters: {'x': 3.336198183500721, 'y': -5.251135105482727}. Best is trial 69 with value: 0.049758510577362525.\n",
      "[I 2025-08-11 10:26:12,794] Trial 84 finished with value: 14.729829668129852 and parameters: {'x': 5.899945045076166, 'y': -2.4860094662731824}. Best is trial 69 with value: 0.049758510577362525.\n",
      "[I 2025-08-11 10:26:12,794] Trial 85 finished with value: 3.835775172983286 and parameters: {'x': 3.4984929255196526, 'y': -6.894011609307119}. Best is trial 69 with value: 0.049758510577362525.\n",
      "[I 2025-08-11 10:26:12,804] Trial 86 finished with value: 2.986931959981259 and parameters: {'x': 4.728224228639188, 'y': -5.013152016033457}. Best is trial 69 with value: 0.049758510577362525.\n",
      "[I 2025-08-11 10:26:12,804] Trial 87 finished with value: 86.67066226557024 and parameters: {'x': -6.176392926715913, 'y': -3.430135317905261}. Best is trial 69 with value: 0.049758510577362525.\n",
      "[I 2025-08-11 10:26:12,814] Trial 88 finished with value: 22.58868213941567 and parameters: {'x': 0.3919929612484143, 'y': -1.0267165435577272}. Best is trial 69 with value: 0.049758510577362525.\n",
      "[I 2025-08-11 10:26:12,824] Trial 89 finished with value: 2.521602767404871 and parameters: {'x': 4.145902119482092, 'y': -6.099323018939984}. Best is trial 69 with value: 0.049758510577362525.\n",
      "[I 2025-08-11 10:26:12,824] Trial 90 finished with value: 0.9757069047026693 and parameters: {'x': 2.1366509586145566, 'y': -4.520067361558411}. Best is trial 69 with value: 0.049758510577362525.\n",
      "[I 2025-08-11 10:26:12,834] Trial 91 finished with value: 2.1988320101170893 and parameters: {'x': 1.5566259769805153, 'y': -5.339857970025182}. Best is trial 69 with value: 0.049758510577362525.\n",
      "[I 2025-08-11 10:26:12,834] Trial 92 finished with value: 5.496859286140379 and parameters: {'x': 3.391420205365137, 'y': -7.311633515281411}. Best is trial 69 with value: 0.049758510577362525.\n",
      "[I 2025-08-11 10:26:12,846] Trial 93 finished with value: 1.485505814905443 and parameters: {'x': 3.880722337002757, 'y': -5.842516456818409}. Best is trial 69 with value: 0.049758510577362525.\n",
      "[I 2025-08-11 10:26:12,854] Trial 94 finished with value: 31.47700190395583 and parameters: {'x': 2.666453484119285, 'y': 0.600513246631925}. Best is trial 69 with value: 0.049758510577362525.\n",
      "[I 2025-08-11 10:26:12,857] Trial 95 finished with value: 12.289684939335682 and parameters: {'x': 2.1966738888388955, 'y': -8.412382173564746}. Best is trial 69 with value: 0.049758510577362525.\n",
      "[I 2025-08-11 10:26:12,857] Trial 96 finished with value: 8.554816122357622 and parameters: {'x': 3.1234910833671825, 'y': -2.0777464047953638}. Best is trial 69 with value: 0.049758510577362525.\n",
      "[I 2025-08-11 10:26:12,871] Trial 97 finished with value: 6.380116115079267 and parameters: {'x': 5.340103148677372, 'y': -4.0491933063816195}. Best is trial 69 with value: 0.049758510577362525.\n",
      "[I 2025-08-11 10:26:12,877] Trial 98 finished with value: 5.934832328266354 and parameters: {'x': 4.277893272663703, 'y': -2.925916802067187}. Best is trial 69 with value: 0.049758510577362525.\n",
      "[I 2025-08-11 10:26:12,883] Trial 99 finished with value: 3.2835396180949874 and parameters: {'x': 1.191468869584427, 'y': -5.112937010819118}. Best is trial 69 with value: 0.049758510577362525.\n",
      "[I 2025-08-11 10:26:12,888] Trial 100 finished with value: 1.9025552055237038 and parameters: {'x': 3.6227295871372167, 'y': -6.230757111223663}. Best is trial 69 with value: 0.049758510577362525.\n",
      "[I 2025-08-11 10:26:12,888] Trial 101 finished with value: 0.26074170675481967 and parameters: {'x': 2.9445300380362704, 'y': -4.492393075229896}. Best is trial 69 with value: 0.049758510577362525.\n",
      "[I 2025-08-11 10:26:12,898] Trial 102 finished with value: 0.37872712880705267 and parameters: {'x': 2.7428754756567106, 'y': -4.4408809538315746}. Best is trial 69 with value: 0.049758510577362525.\n",
      "[I 2025-08-11 10:26:12,907] Trial 103 finished with value: 1.8209427334087285 and parameters: {'x': 1.8060482703293899, 'y': -4.371174109450568}. Best is trial 69 with value: 0.049758510577362525.\n",
      "[I 2025-08-11 10:26:12,907] Trial 104 finished with value: 2.432684272055606 and parameters: {'x': 2.8291234263102747, 'y': -6.550317860511084}. Best is trial 69 with value: 0.049758510577362525.\n",
      "[I 2025-08-11 10:26:12,917] Trial 105 finished with value: 4.784268631407924 and parameters: {'x': 4.696280909278922, 'y': -3.6190946056214433}. Best is trial 69 with value: 0.049758510577362525.\n",
      "[I 2025-08-11 10:26:12,923] Trial 106 finished with value: 179.64720808749394 and parameters: {'x': 3.7825323674035474, 'y': 8.380390546671638}. Best is trial 69 with value: 0.049758510577362525.\n",
      "[I 2025-08-11 10:26:12,923] Trial 107 finished with value: 5.000579983005084 and parameters: {'x': 2.078940836883446, 'y': -2.962297862531396}. Best is trial 69 with value: 0.049758510577362525.\n",
      "[I 2025-08-11 10:26:12,934] Trial 108 finished with value: 0.21078330305895554 and parameters: {'x': 3.401397535288085, 'y': -5.222852690635778}. Best is trial 69 with value: 0.049758510577362525.\n",
      "[I 2025-08-11 10:26:12,934] Trial 109 finished with value: 0.03782481730133801 and parameters: {'x': 2.91916713483893, 'y': -5.176892241806107}. Best is trial 109 with value: 0.03782481730133801.\n",
      "[I 2025-08-11 10:26:12,944] Trial 110 finished with value: 7.819751676586001 and parameters: {'x': 3.9673275024180104, 'y': -7.623743352474044}. Best is trial 109 with value: 0.03782481730133801.\n",
      "[I 2025-08-11 10:26:12,944] Trial 111 finished with value: 0.09094733650951657 and parameters: {'x': 2.7807181123173037, 'y': -5.2070333070880865}. Best is trial 109 with value: 0.03782481730133801.\n",
      "[I 2025-08-11 10:26:12,957] Trial 112 finished with value: 0.03142981240916103 and parameters: {'x': 3.0664459133643236, 'y': -5.164361653089587}. Best is trial 112 with value: 0.03142981240916103.\n",
      "[I 2025-08-11 10:26:12,957] Trial 113 finished with value: 0.8405798034440775 and parameters: {'x': 2.2614164809105697, 'y': -5.5432073165685}. Best is trial 112 with value: 0.03142981240916103.\n",
      "[I 2025-08-11 10:26:12,967] Trial 114 finished with value: 3.5398970131960272 and parameters: {'x': 1.6364920466637847, 'y': -6.296434755159284}. Best is trial 112 with value: 0.03142981240916103.\n",
      "[I 2025-08-11 10:26:12,973] Trial 115 finished with value: 3.6178177286384616 and parameters: {'x': 3.3316976925139534, 'y': -6.872910667762715}. Best is trial 112 with value: 0.03142981240916103.\n",
      "[I 2025-08-11 10:26:12,973] Trial 116 finished with value: 4.248904895854643 and parameters: {'x': 0.9938573674764761, 'y': -5.4735996556441195}. Best is trial 112 with value: 0.03142981240916103.\n",
      "[I 2025-08-11 10:26:12,984] Trial 117 finished with value: 3.5672270197864018 and parameters: {'x': 4.352697743943905, 'y': -3.681881707389101}. Best is trial 112 with value: 0.03142981240916103.\n",
      "[I 2025-08-11 10:26:12,994] Trial 118 finished with value: 0.291245319828709 and parameters: {'x': 2.460578205662978, 'y': -4.983585140179194}. Best is trial 112 with value: 0.03142981240916103.\n",
      "[I 2025-08-11 10:26:12,994] Trial 119 finished with value: 11.529530075165017 and parameters: {'x': 3.7020497784163866, 'y': -8.32214632185136}. Best is trial 112 with value: 0.03142981240916103.\n",
      "[I 2025-08-11 10:26:13,007] Trial 120 finished with value: 9.960751688776028 and parameters: {'x': 5.446262585723756, 'y': -6.994129145884026}. Best is trial 112 with value: 0.03142981240916103.\n",
      "[I 2025-08-11 10:26:13,019] Trial 121 finished with value: 0.0807271777129555 and parameters: {'x': 3.01474503905156, 'y': -4.716257578891835}. Best is trial 112 with value: 0.03142981240916103.\n",
      "[I 2025-08-11 10:26:13,031] Trial 122 finished with value: 0.011279016250261325 and parameters: {'x': 2.893842295845239, 'y': -4.996908382486204}. Best is trial 122 with value: 0.011279016250261325.\n",
      "[I 2025-08-11 10:26:13,038] Trial 123 finished with value: 1.2095924716802693 and parameters: {'x': 2.999270259862228, 'y': -6.09981450215916}. Best is trial 122 with value: 0.011279016250261325.\n",
      "[I 2025-08-11 10:26:13,041] Trial 124 finished with value: 10.942485666671677 and parameters: {'x': 1.9257239828633466, 'y': -1.8713554523281672}. Best is trial 122 with value: 0.011279016250261325.\n",
      "[I 2025-08-11 10:26:13,051] Trial 125 finished with value: 1.7466898496670744 and parameters: {'x': 2.5804285409191365, 'y': -3.746744383458893}. Best is trial 122 with value: 0.011279016250261325.\n",
      "[I 2025-08-11 10:26:13,051] Trial 126 finished with value: 6.838799566651692 and parameters: {'x': 4.166670181174756, 'y': -2.6595555432761593}. Best is trial 122 with value: 0.011279016250261325.\n",
      "[I 2025-08-11 10:26:13,061] Trial 127 finished with value: 3.160185738285767 and parameters: {'x': 1.4046514092706262, 'y': -5.784250350553679}. Best is trial 122 with value: 0.011279016250261325.\n",
      "[I 2025-08-11 10:26:13,061] Trial 128 finished with value: 3.1702888523874866 and parameters: {'x': 4.777180718284247, 'y': -4.890832482183685}. Best is trial 122 with value: 0.011279016250261325.\n",
      "[I 2025-08-11 10:26:13,076] Trial 129 finished with value: 59.074200346470306 and parameters: {'x': 0.5897035036133262, 'y': 2.29826494079082}. Best is trial 122 with value: 0.011279016250261325.\n",
      "[I 2025-08-11 10:26:13,083] Trial 130 finished with value: 1.9125052069232873 and parameters: {'x': 3.093742158061932, 'y': -6.379752736806555}. Best is trial 122 with value: 0.011279016250261325.\n",
      "[I 2025-08-11 10:26:13,086] Trial 131 finished with value: 0.2875858502437086 and parameters: {'x': 3.4607279739632633, 'y': -4.725563150704183}. Best is trial 122 with value: 0.011279016250261325.\n",
      "[I 2025-08-11 10:26:13,086] Trial 132 finished with value: 0.3870668600957358 and parameters: {'x': 2.429470857806961, 'y': -5.248119644535072}. Best is trial 122 with value: 0.011279016250261325.\n",
      "[I 2025-08-11 10:26:13,096] Trial 133 finished with value: 3.2647199272889584 and parameters: {'x': 3.3296117232301317, 'y': -3.2234651595878505}. Best is trial 122 with value: 0.011279016250261325.\n",
      "[I 2025-08-11 10:26:13,096] Trial 134 finished with value: 0.13627653474864138 and parameters: {'x': 2.798215008935308, 'y': -5.3091267573822485}. Best is trial 122 with value: 0.011279016250261325.\n",
      "[I 2025-08-11 10:26:13,106] Trial 135 finished with value: 0.8846549044289321 and parameters: {'x': 2.783355790093815, 'y': -4.084729443965853}. Best is trial 122 with value: 0.011279016250261325.\n",
      "[I 2025-08-11 10:26:13,117] Trial 136 finished with value: 6.013766485401282 and parameters: {'x': 2.069687136817139, 'y': -7.268983133916555}. Best is trial 122 with value: 0.011279016250261325.\n",
      "[I 2025-08-11 10:26:13,126] Trial 137 finished with value: 1.4399308672599327 and parameters: {'x': 3.9366901931216507, 'y': -5.750028232381727}. Best is trial 122 with value: 0.011279016250261325.\n",
      "[I 2025-08-11 10:26:13,126] Trial 138 finished with value: 3.9258833958469577 and parameters: {'x': 1.7488693724886053, 'y': -6.536409954650744}. Best is trial 122 with value: 0.011279016250261325.\n",
      "[I 2025-08-11 10:26:13,136] Trial 139 finished with value: 0.3983397620896014 and parameters: {'x': 2.429998667107293, 'y': -4.729005087519823}. Best is trial 122 with value: 0.011279016250261325.\n",
      "[I 2025-08-11 10:26:13,140] Trial 140 finished with value: 1.100401894465359 and parameters: {'x': 2.824626224263441, 'y': -3.96576311550532}. Best is trial 122 with value: 0.011279016250261325.\n",
      "[I 2025-08-11 10:26:13,140] Trial 141 finished with value: 0.37665388655504467 and parameters: {'x': 3.5532003681533753, 'y': -5.265750332511579}. Best is trial 122 with value: 0.011279016250261325.\n",
      "[I 2025-08-11 10:26:13,157] Trial 142 finished with value: 0.08479651752327201 and parameters: {'x': 3.0969723889592378, 'y': -5.274577627098076}. Best is trial 122 with value: 0.011279016250261325.\n",
      "[I 2025-08-11 10:26:13,157] Trial 143 finished with value: 116.82467185560388 and parameters: {'x': 2.9950365989254286, 'y': 5.808545101920687}. Best is trial 122 with value: 0.011279016250261325.\n",
      "[I 2025-08-11 10:26:13,167] Trial 144 finished with value: 1.6281002836296725 and parameters: {'x': 2.1979401690051876, 'y': -5.992371055167494}. Best is trial 122 with value: 0.011279016250261325.\n",
      "[I 2025-08-11 10:26:13,173] Trial 145 finished with value: 3.4893070354061964 and parameters: {'x': 3.8978853113763847, 'y': -3.3619801579282598}. Best is trial 122 with value: 0.011279016250261325.\n",
      "[I 2025-08-11 10:26:13,180] Trial 146 finished with value: 1.9890315113208628 and parameters: {'x': 4.310258605417044, 'y': -4.478220450523934}. Best is trial 122 with value: 0.011279016250261325.\n",
      "[I 2025-08-11 10:26:13,183] Trial 147 finished with value: 8.19170812046244 and parameters: {'x': 3.062021513573218, 'y': -7.861443945338879}. Best is trial 122 with value: 0.011279016250261325.\n",
      "[I 2025-08-11 10:26:13,190] Trial 148 finished with value: 3.0660986319973733 and parameters: {'x': 1.383607365885311, 'y': -5.673330145157003}. Best is trial 122 with value: 0.011279016250261325.\n",
      "[I 2025-08-11 10:26:13,190] Trial 149 finished with value: 3.05105668383397 and parameters: {'x': 2.5490880132271303, 'y': -6.687523352140205}. Best is trial 122 with value: 0.011279016250261325.\n",
      "[I 2025-08-11 10:26:13,200] Trial 150 finished with value: 261.0350258323148 and parameters: {'x': 3.409297172886935, 'y': 11.151393180050489}. Best is trial 122 with value: 0.011279016250261325.\n",
      "[I 2025-08-11 10:26:13,207] Trial 151 finished with value: 0.5070556593718536 and parameters: {'x': 3.7037617346155716, 'y': -5.1085130419015865}. Best is trial 122 with value: 0.011279016250261325.\n",
      "[I 2025-08-11 10:26:13,207] Trial 152 finished with value: 0.05105905940082875 and parameters: {'x': 3.14213740139812, 'y': -5.175658812829355}. Best is trial 122 with value: 0.011279016250261325.\n",
      "[I 2025-08-11 10:26:13,217] Trial 153 finished with value: 1.2866661183882802 and parameters: {'x': 2.711915240318622, 'y': -3.9028795464363983}. Best is trial 122 with value: 0.011279016250261325.\n",
      "[I 2025-08-11 10:26:13,226] Trial 154 finished with value: 1.3379281250022008 and parameters: {'x': 1.990452441217272, 'y': -4.435427726895807}. Best is trial 122 with value: 0.011279016250261325.\n",
      "[I 2025-08-11 10:26:13,226] Trial 155 finished with value: 0.9767516177264917 and parameters: {'x': 3.1340713180583286, 'y': -5.979171333016135}. Best is trial 122 with value: 0.011279016250261325.\n",
      "[I 2025-08-11 10:26:13,234] Trial 156 finished with value: 5.158268089097001 and parameters: {'x': 2.358666745316633, 'y': -7.178751877918695}. Best is trial 122 with value: 0.011279016250261325.\n",
      "[I 2025-08-11 10:26:13,240] Trial 157 finished with value: 3.705355637980072 and parameters: {'x': 4.924669276585475, 'y': -5.031683019868936}. Best is trial 122 with value: 0.011279016250261325.\n",
      "[I 2025-08-11 10:26:13,250] Trial 158 finished with value: 2.514565052646192 and parameters: {'x': 4.506118349570778, 'y': -5.496157807287547}. Best is trial 122 with value: 0.011279016250261325.\n",
      "[I 2025-08-11 10:26:13,257] Trial 159 finished with value: 4.7120927994312884 and parameters: {'x': 4.050273111144013, 'y': -3.100258125049836}. Best is trial 122 with value: 0.011279016250261325.\n",
      "[I 2025-08-11 10:26:13,257] Trial 160 finished with value: 2.1140847222873105 and parameters: {'x': 3.1442455075145883, 'y': -6.446816490039137}. Best is trial 122 with value: 0.011279016250261325.\n",
      "[I 2025-08-11 10:26:13,272] Trial 161 finished with value: 0.24403673177077917 and parameters: {'x': 3.4924970834198175, 'y': -5.038514342701811}. Best is trial 122 with value: 0.011279016250261325.\n",
      "[I 2025-08-11 10:26:13,277] Trial 162 finished with value: 0.6082237130360045 and parameters: {'x': 2.89001362160708, 'y': -4.2279075770323775}. Best is trial 122 with value: 0.011279016250261325.\n",
      "[I 2025-08-11 10:26:13,277] Trial 163 finished with value: 0.6964628175268608 and parameters: {'x': 3.4875782741942007, 'y': -5.677296274949645}. Best is trial 122 with value: 0.011279016250261325.\n",
      "[I 2025-08-11 10:26:13,290] Trial 164 finished with value: 0.19379734902128723 and parameters: {'x': 2.5790582225092016, 'y': -4.871138178717766}. Best is trial 122 with value: 0.011279016250261325.\n",
      "[I 2025-08-11 10:26:13,290] Trial 165 finished with value: 1.7107621230464745 and parameters: {'x': 2.5692219627396042, 'y': -3.7650131961593454}. Best is trial 122 with value: 0.011279016250261325.\n",
      "[I 2025-08-11 10:26:13,300] Trial 166 finished with value: 56.4296253022859 and parameters: {'x': -4.505292127352616, 'y': -4.6834318629666924}. Best is trial 122 with value: 0.011279016250261325.\n",
      "[I 2025-08-11 10:26:13,306] Trial 167 finished with value: 169.86002538065839 and parameters: {'x': -9.97144176808475, 'y': -6.265592287367758}. Best is trial 122 with value: 0.011279016250261325.\n",
      "[I 2025-08-11 10:26:13,311] Trial 168 finished with value: 1.7731520450840927 and parameters: {'x': 1.7423766428829217, 'y': -5.437647731306427}. Best is trial 122 with value: 0.011279016250261325.\n",
      "[I 2025-08-11 10:26:13,311] Trial 169 finished with value: 0.85913359555198 and parameters: {'x': 2.1562706823326065, 'y': -4.616262545403117}. Best is trial 122 with value: 0.011279016250261325.\n",
      "[I 2025-08-11 10:26:13,325] Trial 170 finished with value: 5.908050806699115 and parameters: {'x': 3.8029922475073916, 'y': -2.7058216596911775}. Best is trial 122 with value: 0.011279016250261325.\n",
      "[I 2025-08-11 10:26:13,331] Trial 171 finished with value: 0.07482785631642895 and parameters: {'x': 3.110231653152023, 'y': -5.250353428096763}. Best is trial 122 with value: 0.011279016250261325.\n",
      "[I 2025-08-11 10:26:13,333] Trial 172 finished with value: 1.1323769184025314 and parameters: {'x': 2.873248333156125, 'y': -6.056556166682506}. Best is trial 122 with value: 0.011279016250261325.\n",
      "[I 2025-08-11 10:26:13,343] Trial 173 finished with value: 0.045830069221147046 and parameters: {'x': 3.1996649469223817, 'y': -5.077226797108449}. Best is trial 122 with value: 0.011279016250261325.\n",
      "[I 2025-08-11 10:26:13,343] Trial 174 finished with value: 1.1968040331482084 and parameters: {'x': 3.2061140184007644, 'y': -3.9256066620799914}. Best is trial 122 with value: 0.011279016250261325.\n",
      "[I 2025-08-11 10:26:13,353] Trial 175 finished with value: 3.566379344113704 and parameters: {'x': 3.6688271566352855, 'y': -6.766083117710167}. Best is trial 122 with value: 0.011279016250261325.\n",
      "[I 2025-08-11 10:26:13,357] Trial 176 finished with value: 0.15068374425483483 and parameters: {'x': 3.0064663440927895, 'y': -5.388126178772971}. Best is trial 122 with value: 0.011279016250261325.\n",
      "[I 2025-08-11 10:26:13,367] Trial 177 finished with value: 0.8899896453413052 and parameters: {'x': 2.319918949922504, 'y': -5.653819096284894}. Best is trial 122 with value: 0.011279016250261325.\n",
      "[I 2025-08-11 10:26:13,373] Trial 178 finished with value: 0.35465621607121633 and parameters: {'x': 2.9342642554565135, 'y': -4.408108939110811}. Best is trial 122 with value: 0.011279016250261325.\n",
      "[I 2025-08-11 10:26:13,380] Trial 179 finished with value: 2.988070773114175 and parameters: {'x': 4.029616760271601, 'y': -3.611489971198628}. Best is trial 122 with value: 0.011279016250261325.\n",
      "[I 2025-08-11 10:26:13,384] Trial 180 finished with value: 2.4370845326766153 and parameters: {'x': 1.910286822565773, 'y': -6.117859438213417}. Best is trial 122 with value: 0.011279016250261325.\n",
      "[I 2025-08-11 10:26:13,391] Trial 181 finished with value: 0.10473430876697808 and parameters: {'x': 3.2131327577562967, 'y': -5.243533850497572}. Best is trial 122 with value: 0.011279016250261325.\n",
      "[I 2025-08-11 10:26:13,391] Trial 182 finished with value: 0.05178834284188221 and parameters: {'x': 3.1926671205731707, 'y': -5.121110377308988}. Best is trial 122 with value: 0.011279016250261325.\n",
      "[I 2025-08-11 10:26:13,401] Trial 183 finished with value: 0.13068999424954958 and parameters: {'x': 3.2544983351670442, 'y': -5.256750056760953}. Best is trial 122 with value: 0.011279016250261325.\n",
      "[I 2025-08-11 10:26:13,408] Trial 184 finished with value: 0.017289902395266798 and parameters: {'x': 3.128563012422248, 'y': -4.9724055398280065}. Best is trial 122 with value: 0.011279016250261325.\n",
      "[I 2025-08-11 10:26:13,418] Trial 185 finished with value: 0.08373802841750382 and parameters: {'x': 3.2847043927908364, 'y': -4.948217405017661}. Best is trial 122 with value: 0.011279016250261325.\n",
      "[I 2025-08-11 10:26:13,423] Trial 186 finished with value: 0.10146878651377632 and parameters: {'x': 3.3168097736175204, 'y': -4.966828417972732}. Best is trial 122 with value: 0.011279016250261325.\n",
      "[I 2025-08-11 10:26:13,423] Trial 187 finished with value: 0.9911819502562875 and parameters: {'x': 3.723776115827158, 'y': -4.316384549315597}. Best is trial 122 with value: 0.011279016250261325.\n",
      "[I 2025-08-11 10:26:13,433] Trial 188 finished with value: 0.1357065505844749 and parameters: {'x': 3.3471442101722855, 'y': -4.876722070392406}. Best is trial 122 with value: 0.011279016250261325.\n",
      "[I 2025-08-11 10:26:13,440] Trial 189 finished with value: 6.100845572193614 and parameters: {'x': 4.433111287554425, 'y': -7.011725033317852}. Best is trial 122 with value: 0.011279016250261325.\n",
      "[I 2025-08-11 10:26:13,440] Trial 190 finished with value: 2.518757234488948 and parameters: {'x': 4.200026318421957, 'y': -6.038601978422722}. Best is trial 122 with value: 0.011279016250261325.\n",
      "[I 2025-08-11 10:26:13,450] Trial 191 finished with value: 0.1222848782970853 and parameters: {'x': 3.3263473794021943, 'y': -4.874372509957392}. Best is trial 122 with value: 0.011279016250261325.\n",
      "[I 2025-08-11 10:26:13,459] Trial 192 finished with value: 0.06958290416714935 and parameters: {'x': 3.2380102531621753, 'y': -5.113727848642391}. Best is trial 122 with value: 0.011279016250261325.\n",
      "[I 2025-08-11 10:26:13,459] Trial 193 finished with value: 1.0143042348142821 and parameters: {'x': 2.62443377843622, 'y': -4.065519262887357}. Best is trial 122 with value: 0.011279016250261325.\n",
      "[I 2025-08-11 10:26:13,467] Trial 194 finished with value: 0.7874115209168707 and parameters: {'x': 3.747176669195456, 'y': -4.521315818177731}. Best is trial 122 with value: 0.011279016250261325.\n",
      "[I 2025-08-11 10:26:13,472] Trial 195 finished with value: 0.7436450452422267 and parameters: {'x': 3.3465141844225053, 'y': -5.789666363242245}. Best is trial 122 with value: 0.011279016250261325.\n",
      "[I 2025-08-11 10:26:13,477] Trial 196 finished with value: 0.017722254851223588 and parameters: {'x': 3.0233037273925194, 'y': -4.868930586554915}. Best is trial 122 with value: 0.011279016250261325.\n",
      "[I 2025-08-11 10:26:13,487] Trial 197 finished with value: 3.0382163590142133 and parameters: {'x': 2.3713460961598356, 'y': -3.374266126267668}. Best is trial 122 with value: 0.011279016250261325.\n",
      "[I 2025-08-11 10:26:13,487] Trial 198 finished with value: 2.04484382726396 and parameters: {'x': 2.855740358779287, 'y': -6.422685131425373}. Best is trial 122 with value: 0.011279016250261325.\n",
      "[I 2025-08-11 10:26:13,497] Trial 199 finished with value: 0.8947150691067616 and parameters: {'x': 3.8987409647245905, 'y': -5.294923290759943}. Best is trial 122 with value: 0.011279016250261325.\n",
      "[I 2025-08-11 10:26:13,505] Trial 200 finished with value: 0.9308902282374885 and parameters: {'x': 2.9650290502182863, 'y': -4.03580745651667}. Best is trial 122 with value: 0.011279016250261325.\n",
      "[I 2025-08-11 10:26:13,508] Trial 201 finished with value: 0.1997283248551017 and parameters: {'x': 3.443941592477961, 'y': -4.948578337996194}. Best is trial 122 with value: 0.011279016250261325.\n",
      "[I 2025-08-11 10:26:13,518] Trial 202 finished with value: 0.06224509740630875 and parameters: {'x': 3.2171616124444684, 'y': -4.877175200033433}. Best is trial 122 with value: 0.011279016250261325.\n",
      "[I 2025-08-11 10:26:13,523] Trial 203 finished with value: 1.1393113561388255 and parameters: {'x': 2.5793745750687, 'y': -5.981012542244078}. Best is trial 122 with value: 0.011279016250261325.\n",
      "[I 2025-08-11 10:26:13,523] Trial 204 finished with value: 0.17418686468637157 and parameters: {'x': 3.1598198311803496, 'y': -4.614455597566433}. Best is trial 122 with value: 0.011279016250261325.\n",
      "[I 2025-08-11 10:26:13,533] Trial 205 finished with value: 0.9749384755258161 and parameters: {'x': 2.198668828240567, 'y': -5.576894122601773}. Best is trial 122 with value: 0.011279016250261325.\n",
      "[I 2025-08-11 10:26:13,544] Trial 206 finished with value: 1.001187857882979 and parameters: {'x': 3.7313775205046174, 'y': -4.317156840567692}. Best is trial 122 with value: 0.011279016250261325.\n",
      "[I 2025-08-11 10:26:13,550] Trial 207 finished with value: 0.11488607743576063 and parameters: {'x': 2.702923385988117, 'y': -5.163191797719724}. Best is trial 122 with value: 0.011279016250261325.\n",
      "[I 2025-08-11 10:26:13,553] Trial 208 finished with value: 2.0569986727766874 and parameters: {'x': 2.6679910984359982, 'y': -3.60473344408355}. Best is trial 122 with value: 0.011279016250261325.\n",
      "[I 2025-08-11 10:26:13,562] Trial 209 finished with value: 2.1853744597648688 and parameters: {'x': 3.039911393216099, 'y': -6.477762342346163}. Best is trial 122 with value: 0.011279016250261325.\n",
      "[I 2025-08-11 10:26:13,570] Trial 210 finished with value: 1.3466272113328386 and parameters: {'x': 4.159780728471972, 'y': -4.960809781860005}. Best is trial 122 with value: 0.011279016250261325.\n",
      "[I 2025-08-11 10:26:13,580] Trial 211 finished with value: 0.43097791080795017 and parameters: {'x': 2.69489205109092, 'y': -5.581280526355773}. Best is trial 122 with value: 0.011279016250261325.\n",
      "[I 2025-08-11 10:26:13,584] Trial 212 finished with value: 0.39075635474069553 and parameters: {'x': 3.5941925810642408, 'y': -5.1941430692785895}. Best is trial 122 with value: 0.011279016250261325.\n",
      "[I 2025-08-11 10:26:13,598] Trial 213 finished with value: 0.2478496013505844 and parameters: {'x': 3.1263065911257897, 'y': -4.518443932248002}. Best is trial 122 with value: 0.011279016250261325.\n",
      "[I 2025-08-11 10:26:13,606] Trial 214 finished with value: 1.0503969066883156 and parameters: {'x': 2.4000144285470753, 'y': -5.830911680467078}. Best is trial 122 with value: 0.011279016250261325.\n",
      "[I 2025-08-11 10:26:13,606] Trial 215 finished with value: 21.899725215071687 and parameters: {'x': 7.666803315718244, 'y': -5.347378795370253}. Best is trial 122 with value: 0.011279016250261325.\n",
      "[I 2025-08-11 10:26:13,617] Trial 216 finished with value: 0.9259167877099967 and parameters: {'x': 3.3872696613526214, 'y': -4.119126003842875}. Best is trial 122 with value: 0.011279016250261325.\n",
      "[I 2025-08-11 10:26:13,625] Trial 217 finished with value: 0.07409589201808632 and parameters: {'x': 2.8710097518514233, 'y': -4.760297250953071}. Best is trial 122 with value: 0.011279016250261325.\n",
      "[I 2025-08-11 10:26:13,625] Trial 218 finished with value: 0.6662303908714694 and parameters: {'x': 2.2080590739558565, 'y': -4.802364070756823}. Best is trial 122 with value: 0.011279016250261325.\n",
      "[I 2025-08-11 10:26:13,635] Trial 219 finished with value: 2.116057712540142 and parameters: {'x': 2.825707086964447, 'y': -3.5558117529194044}. Best is trial 122 with value: 0.011279016250261325.\n",
      "[I 2025-08-11 10:26:13,635] Trial 220 finished with value: 2.982892058695401 and parameters: {'x': 1.906834975196223, 'y': -6.337117155391089}. Best is trial 122 with value: 0.011279016250261325.\n",
      "[I 2025-08-11 10:26:13,645] Trial 221 finished with value: 0.018678656179442116 and parameters: {'x': 3.094644266863168, 'y': -4.901404265156268}. Best is trial 122 with value: 0.011279016250261325.\n",
      "[I 2025-08-11 10:26:13,655] Trial 222 finished with value: 0.05564492336326254 and parameters: {'x': 3.1212722250847884, 'y': -4.797668660889503}. Best is trial 122 with value: 0.011279016250261325.\n",
      "[I 2025-08-11 10:26:13,655] Trial 223 finished with value: 0.7116917299543213 and parameters: {'x': 3.6467058973840167, 'y': -4.458277550545434}. Best is trial 122 with value: 0.011279016250261325.\n",
      "[I 2025-08-11 10:26:13,666] Trial 224 finished with value: 0.034031283314572176 and parameters: {'x': 3.1558164413196454, 'y': -4.901245152376941}. Best is trial 122 with value: 0.011279016250261325.\n",
      "[I 2025-08-11 10:26:13,673] Trial 225 finished with value: 0.80949370395913 and parameters: {'x': 3.2080864288594233, 'y': -4.124675064856677}. Best is trial 122 with value: 0.011279016250261325.\n",
      "[I 2025-08-11 10:26:13,673] Trial 226 finished with value: 0.31697014410062524 and parameters: {'x': 3.548594134150652, 'y': -4.873451115863783}. Best is trial 122 with value: 0.011279016250261325.\n",
      "[I 2025-08-11 10:26:13,683] Trial 227 finished with value: 0.48424282472328245 and parameters: {'x': 3.022129597758062, 'y': -5.695523619747273}. Best is trial 122 with value: 0.011279016250261325.\n",
      "[I 2025-08-11 10:26:13,694] Trial 228 finished with value: 1.0108709982319615 and parameters: {'x': 3.9700524028495674, 'y': -4.735671919846298}. Best is trial 122 with value: 0.011279016250261325.\n",
      "[I 2025-08-11 10:26:13,694] Trial 229 finished with value: 3.915380342661038 and parameters: {'x': 2.4966569216134835, 'y': -3.086357899684107}. Best is trial 122 with value: 0.011279016250261325.\n",
      "[I 2025-08-11 10:26:13,706] Trial 230 finished with value: 0.6051609635105327 and parameters: {'x': 3.2379165962521026, 'y': -5.740646107623841}. Best is trial 122 with value: 0.011279016250261325.\n",
      "[I 2025-08-11 10:26:13,706] Trial 231 finished with value: 0.05509349056962093 and parameters: {'x': 2.8702376610204787, 'y': -5.195589432107629}. Best is trial 122 with value: 0.011279016250261325.\n",
      "[I 2025-08-11 10:26:13,717] Trial 232 finished with value: 0.023121004798637112 and parameters: {'x': 2.8494125068604053, 'y': -5.02108107465405}. Best is trial 122 with value: 0.011279016250261325.\n",
      "[I 2025-08-11 10:26:13,723] Trial 233 finished with value: 0.5241009170932889 and parameters: {'x': 2.9008677036365795, 'y': -4.282871207584716}. Best is trial 122 with value: 0.011279016250261325.\n",
      "[I 2025-08-11 10:26:13,723] Trial 234 finished with value: 0.28880925346467373 and parameters: {'x': 2.47686901533274, 'y': -4.876942182914953}. Best is trial 122 with value: 0.011279016250261325.\n",
      "[I 2025-08-11 10:26:13,733] Trial 235 finished with value: 1.8169775306702098 and parameters: {'x': 3.5546115173852306, 'y': -3.7714302643098105}. Best is trial 122 with value: 0.011279016250261325.\n",
      "[I 2025-08-11 10:26:13,733] Trial 236 finished with value: 1.009537336516867 and parameters: {'x': 2.6754473012494913, 'y': -5.950895831440347}. Best is trial 122 with value: 0.011279016250261325.\n",
      "[I 2025-08-11 10:26:13,743] Trial 237 finished with value: 0.19992477435889094 and parameters: {'x': 3.135730718054114, 'y': -4.573969547408398}. Best is trial 122 with value: 0.011279016250261325.\n",
      "[I 2025-08-11 10:26:13,753] Trial 238 finished with value: 0.718051998524948 and parameters: {'x': 3.7768082159737935, 'y': -5.338557224292379}. Best is trial 122 with value: 0.011279016250261325.\n",
      "[I 2025-08-11 10:26:13,753] Trial 239 finished with value: 1.6196983731969663 and parameters: {'x': 2.1545352144371464, 'y': -4.048744161873303}. Best is trial 122 with value: 0.011279016250261325.\n",
      "[I 2025-08-11 10:26:13,763] Trial 240 finished with value: 0.9822733545358919 and parameters: {'x': 2.857021566780159, 'y': -5.980729586669991}. Best is trial 122 with value: 0.011279016250261325.\n",
      "[I 2025-08-11 10:26:13,772] Trial 241 finished with value: 0.08218009958484118 and parameters: {'x': 3.179370448942897, 'y': -5.2236209776180775}. Best is trial 122 with value: 0.011279016250261325.\n",
      "[I 2025-08-11 10:26:13,773] Trial 242 finished with value: 0.14518377577937303 and parameters: {'x': 3.3800813335679525, 'y': -5.026869232452377}. Best is trial 122 with value: 0.011279016250261325.\n",
      "[I 2025-08-11 10:26:13,783] Trial 243 finished with value: 0.06132653750544571 and parameters: {'x': 2.95654221219226, 'y': -5.243799011860801}. Best is trial 122 with value: 0.011279016250261325.\n",
      "[I 2025-08-11 10:26:13,790] Trial 244 finished with value: 0.30656261507083105 and parameters: {'x': 2.8144682250088975, 'y': -5.521670945653946}. Best is trial 122 with value: 0.011279016250261325.\n",
      "[I 2025-08-11 10:26:13,793] Trial 245 finished with value: 0.4691667186740495 and parameters: {'x': 2.441765523695466, 'y': -4.603085666498359}. Best is trial 122 with value: 0.011279016250261325.\n",
      "[I 2025-08-11 10:26:13,793] Trial 246 finished with value: 1.7727032541962027 and parameters: {'x': 3.0263930082422172, 'y': -6.3311674061935745}. Best is trial 122 with value: 0.011279016250261325.\n",
      "[I 2025-08-11 10:26:13,806] Trial 247 finished with value: 0.6173794224262155 and parameters: {'x': 3.5905673889733363, 'y': -5.5182755845179585}. Best is trial 122 with value: 0.011279016250261325.\n",
      "[I 2025-08-11 10:26:13,806] Trial 248 finished with value: 0.7558854941695041 and parameters: {'x': 2.6490096100537954, 'y': -4.204581091289052}. Best is trial 122 with value: 0.011279016250261325.\n",
      "[I 2025-08-11 10:26:13,817] Trial 249 finished with value: 0.004556208545386644 and parameters: {'x': 3.066422930433542, 'y': -4.987991550557733}. Best is trial 249 with value: 0.004556208545386644.\n",
      "[I 2025-08-11 10:26:13,823] Trial 250 finished with value: 1.1656113059941746 and parameters: {'x': 4.033677931151175, 'y': -4.688357190608861}. Best is trial 249 with value: 0.004556208545386644.\n",
      "[I 2025-08-11 10:26:13,833] Trial 251 finished with value: 0.6794582740317435 and parameters: {'x': 3.248533418183825, 'y': -5.7859321943256985}. Best is trial 249 with value: 0.004556208545386644.\n",
      "[I 2025-08-11 10:26:13,840] Trial 252 finished with value: 3.4523931876863037 and parameters: {'x': 2.175776501112258, 'y': -6.6652473724848065}. Best is trial 249 with value: 0.004556208545386644.\n",
      "[I 2025-08-11 10:26:13,840] Trial 253 finished with value: 1.659738419414913 and parameters: {'x': 3.1120183855393866, 'y': -3.7165708820834467}. Best is trial 249 with value: 0.004556208545386644.\n",
      "[I 2025-08-11 10:26:13,850] Trial 254 finished with value: 0.4102583427225936 and parameters: {'x': 3.625385549157796, 'y': -5.1383880689481405}. Best is trial 249 with value: 0.004556208545386644.\n",
      "[I 2025-08-11 10:26:13,858] Trial 255 finished with value: 0.6281668138825364 and parameters: {'x': 2.5133981525570137, 'y': -4.374391931040201}. Best is trial 249 with value: 0.004556208545386644.\n",
      "[I 2025-08-11 10:26:13,858] Trial 256 finished with value: 0.44614842406944033 and parameters: {'x': 2.8622384638801646, 'y': -5.653582575682173}. Best is trial 249 with value: 0.004556208545386644.\n",
      "[I 2025-08-11 10:26:13,868] Trial 257 finished with value: 42.56439815549288 and parameters: {'x': 9.522823690043033, 'y': -4.868968461406148}. Best is trial 249 with value: 0.004556208545386644.\n",
      "[I 2025-08-11 10:26:13,874] Trial 258 finished with value: 1.6160373249229896 and parameters: {'x': 3.389355239253331, 'y': -6.210140414410233}. Best is trial 249 with value: 0.004556208545386644.\n",
      "[I 2025-08-11 10:26:13,884] Trial 259 finished with value: 1.9893864038590328 and parameters: {'x': 3.9570282877640968, 'y': -3.9639096273594885}. Best is trial 249 with value: 0.004556208545386644.\n",
      "[I 2025-08-11 10:26:13,890] Trial 260 finished with value: 115.07508359062307 and parameters: {'x': -7.721871193767718, 'y': -5.34141132798585}. Best is trial 249 with value: 0.004556208545386644.\n",
      "[I 2025-08-11 10:26:13,890] Trial 261 finished with value: 5.4337525446661035 and parameters: {'x': 1.7989654722317152, 'y': -6.997815959435332}. Best is trial 249 with value: 0.004556208545386644.\n",
      "[I 2025-08-11 10:26:13,900] Trial 262 finished with value: 0.1721834901344072 and parameters: {'x': 3.0550970070300063, 'y': -4.588724168044434}. Best is trial 249 with value: 0.004556208545386644.\n",
      "[I 2025-08-11 10:26:13,908] Trial 263 finished with value: 1.4829621434591886 and parameters: {'x': 2.2629650908399936, 'y': -5.9694027471276785}. Best is trial 249 with value: 0.004556208545386644.\n",
      "[I 2025-08-11 10:26:13,908] Trial 264 finished with value: 0.35930178446331773 and parameters: {'x': 3.5419057118439343, 'y': -5.25620301312482}. Best is trial 249 with value: 0.004556208545386644.\n",
      "[I 2025-08-11 10:26:13,917] Trial 265 finished with value: 2.116520062313344 and parameters: {'x': 2.7083266315532897, 'y': -3.574711710406525}. Best is trial 249 with value: 0.004556208545386644.\n",
      "[I 2025-08-11 10:26:13,927] Trial 266 finished with value: 0.4216942644556364 and parameters: {'x': 3.1307157051510037, 'y': -4.363912216056217}. Best is trial 249 with value: 0.004556208545386644.\n",
      "[I 2025-08-11 10:26:13,927] Trial 267 finished with value: 1.0220732735472597 and parameters: {'x': 4.009202647388187, 'y': -4.940139411530333}. Best is trial 249 with value: 0.004556208545386644.\n",
      "[I 2025-08-11 10:26:13,937] Trial 268 finished with value: 2.5832952493599377 and parameters: {'x': 4.5086446469623604, 'y': -5.55433435627945}. Best is trial 249 with value: 0.004556208545386644.\n",
      "[I 2025-08-11 10:26:13,937] Trial 269 finished with value: 1.4809882433532595 and parameters: {'x': 3.5085287776685186, 'y': -6.105615993750191}. Best is trial 249 with value: 0.004556208545386644.\n",
      "[I 2025-08-11 10:26:13,947] Trial 270 finished with value: 3.630076923094361 and parameters: {'x': 2.442110098255908, 'y': -3.178232786378477}. Best is trial 249 with value: 0.004556208545386644.\n",
      "[I 2025-08-11 10:26:13,956] Trial 271 finished with value: 0.049350886454438116 and parameters: {'x': 2.9303141933109043, 'y': -4.7890621541768095}. Best is trial 249 with value: 0.004556208545386644.\n",
      "[I 2025-08-11 10:26:13,956] Trial 272 finished with value: 0.8939093780093351 and parameters: {'x': 2.999655003036082, 'y': -4.054532253862444}. Best is trial 249 with value: 0.004556208545386644.\n",
      "[I 2025-08-11 10:26:13,967] Trial 273 finished with value: 0.4115053195633227 and parameters: {'x': 3.6319050934379433, 'y': -4.889540629865516}. Best is trial 249 with value: 0.004556208545386644.\n",
      "[I 2025-08-11 10:26:13,977] Trial 274 finished with value: 0.42836309440207143 and parameters: {'x': 3.2483255104872595, 'y': -4.394444440828661}. Best is trial 249 with value: 0.004556208545386644.\n",
      "[I 2025-08-11 10:26:13,977] Trial 275 finished with value: 0.1644284310484891 and parameters: {'x': 2.752907762679424, 'y': -5.321518051288573}. Best is trial 249 with value: 0.004556208545386644.\n",
      "[I 2025-08-11 10:26:13,987] Trial 276 finished with value: 93.0168912316616 and parameters: {'x': 2.2421723055626495, 'y': 4.614706881502179}. Best is trial 249 with value: 0.004556208545386644.\n",
      "[I 2025-08-11 10:26:13,987] Trial 277 finished with value: 2.785350944612435 and parameters: {'x': 3.8820487978469123, 'y': -6.416806572129468}. Best is trial 249 with value: 0.004556208545386644.\n",
      "[I 2025-08-11 10:26:13,998] Trial 278 finished with value: 2.106025092562045 and parameters: {'x': 3.3100158919540448, 'y': -3.5822852052341476}. Best is trial 249 with value: 0.004556208545386644.\n",
      "[I 2025-08-11 10:26:14,008] Trial 279 finished with value: 0.12850878183644804 and parameters: {'x': 2.806677416436725, 'y': -4.698113994161921}. Best is trial 249 with value: 0.004556208545386644.\n",
      "[I 2025-08-11 10:26:14,008] Trial 280 finished with value: 7.376650353263173 and parameters: {'x': 4.278838940784378, 'y': -2.6039154195236214}. Best is trial 249 with value: 0.004556208545386644.\n",
      "[I 2025-08-11 10:26:14,018] Trial 281 finished with value: 1.6753404238364258 and parameters: {'x': 1.9384783001891552, 'y': -5.740616030522646}. Best is trial 249 with value: 0.004556208545386644.\n",
      "[I 2025-08-11 10:26:14,023] Trial 282 finished with value: 0.6658904171982563 and parameters: {'x': 2.510467726603162, 'y': -4.347122851907666}. Best is trial 249 with value: 0.004556208545386644.\n",
      "[I 2025-08-11 10:26:14,033] Trial 283 finished with value: 0.18530137720208995 and parameters: {'x': 3.1666453018741563, 'y': -5.396901399046868}. Best is trial 249 with value: 0.004556208545386644.\n",
      "[I 2025-08-11 10:26:14,039] Trial 284 finished with value: 3.766881042667568 and parameters: {'x': 3.7118469429461682, 'y': -6.805589923677512}. Best is trial 249 with value: 0.004556208545386644.\n",
      "[I 2025-08-11 10:26:14,039] Trial 285 finished with value: 0.016681883819957218 and parameters: {'x': 2.923094857822235, 'y': -4.8962335173258005}. Best is trial 249 with value: 0.004556208545386644.\n",
      "[I 2025-08-11 10:26:14,050] Trial 286 finished with value: 59.80540805624196 and parameters: {'x': 2.70235878779653, 'y': -12.727665738438743}. Best is trial 249 with value: 0.004556208545386644.\n",
      "[I 2025-08-11 10:26:14,062] Trial 287 finished with value: 378.5417430144145 and parameters: {'x': 1.5178597810698522, 'y': 14.399613485475534}. Best is trial 249 with value: 0.004556208545386644.\n",
      "[I 2025-08-11 10:26:14,071] Trial 288 finished with value: 2.5408620920272877 and parameters: {'x': 2.1702118966101422, 'y': -3.6390026467696748}. Best is trial 249 with value: 0.004556208545386644.\n",
      "[I 2025-08-11 10:26:14,078] Trial 289 finished with value: 33.073234170529716 and parameters: {'x': -2.7418374379160726, 'y': -4.676678167957826}. Best is trial 249 with value: 0.004556208545386644.\n",
      "[I 2025-08-11 10:26:14,090] Trial 290 finished with value: 1.1149468632834971 and parameters: {'x': 3.4731486248421417, 'y': -4.056031122285545}. Best is trial 249 with value: 0.004556208545386644.\n",
      "[I 2025-08-11 10:26:14,098] Trial 291 finished with value: 1.1017492001123705 and parameters: {'x': 3.004108784056923, 'y': -6.049634373487237}. Best is trial 249 with value: 0.004556208545386644.\n",
      "[I 2025-08-11 10:26:14,106] Trial 292 finished with value: 0.19427316924314803 and parameters: {'x': 2.5611435952357526, 'y': -5.040966147494573}. Best is trial 249 with value: 0.004556208545386644.\n",
      "[I 2025-08-11 10:26:14,107] Trial 293 finished with value: 0.7169374753782847 and parameters: {'x': 3.820623034771541, 'y': -4.791396763734043}. Best is trial 249 with value: 0.004556208545386644.\n",
      "[I 2025-08-11 10:26:14,117] Trial 294 finished with value: 25.787041929172766 and parameters: {'x': 3.2929731429411766, 'y': -10.069635950113966}. Best is trial 249 with value: 0.004556208545386644.\n",
      "[I 2025-08-11 10:26:14,117] Trial 295 finished with value: 3.5409940644001567 and parameters: {'x': 2.8847148795385333, 'y': -3.121781853617546}. Best is trial 249 with value: 0.004556208545386644.\n",
      "[I 2025-08-11 10:26:14,127] Trial 296 finished with value: 0.8765844869591555 and parameters: {'x': 2.417948622517781, 'y': -5.733348948952821}. Best is trial 249 with value: 0.004556208545386644.\n",
      "[I 2025-08-11 10:26:14,137] Trial 297 finished with value: 18.350430847043036 and parameters: {'x': -1.171792495899684, 'y': -4.027077486025674}. Best is trial 249 with value: 0.004556208545386644.\n",
      "[I 2025-08-11 10:26:14,137] Trial 298 finished with value: 6.836568500371695 and parameters: {'x': 1.9523687600733224, 'y': -7.39562878708313}. Best is trial 249 with value: 0.004556208545386644.\n",
      "[I 2025-08-11 10:26:14,147] Trial 299 finished with value: 1.4914138882711279 and parameters: {'x': 4.195031575783016, 'y': -5.251621583240964}. Best is trial 249 with value: 0.004556208545386644.\n",
      "[I 2025-08-11 10:26:14,147] Trial 300 finished with value: 2.2585803491848133 and parameters: {'x': 3.468804254586854, 'y': -6.4278665624161375}. Best is trial 249 with value: 0.004556208545386644.\n",
      "[I 2025-08-11 10:26:14,158] Trial 301 finished with value: 0.2128585034356926 and parameters: {'x': 2.9636966178950677, 'y': -4.540064604663399}. Best is trial 249 with value: 0.004556208545386644.\n",
      "[I 2025-08-11 10:26:14,172] Trial 302 finished with value: 1.0351002785535766 and parameters: {'x': 3.7660922716803924, 'y': -5.669479581335497}. Best is trial 249 with value: 0.004556208545386644.\n",
      "[I 2025-08-11 10:26:14,178] Trial 303 finished with value: 0.05003268347980553 and parameters: {'x': 3.2218608519571736, 'y': -4.9715316693738005}. Best is trial 249 with value: 0.004556208545386644.\n",
      "[I 2025-08-11 10:26:14,178] Trial 304 finished with value: 0.961462250583047 and parameters: {'x': 2.680256068330742, 'y': -4.073055520139565}. Best is trial 249 with value: 0.004556208545386644.\n",
      "[I 2025-08-11 10:26:14,194] Trial 305 finished with value: 0.49039993599325954 and parameters: {'x': 2.300526528266193, 'y': -5.033716440113316}. Best is trial 249 with value: 0.004556208545386644.\n",
      "[I 2025-08-11 10:26:14,197] Trial 306 finished with value: 1.0912723539305031 and parameters: {'x': 3.046027842977529, 'y': -6.043625311882257}. Best is trial 249 with value: 0.004556208545386644.\n",
      "[I 2025-08-11 10:26:14,206] Trial 307 finished with value: 0.7919987317406686 and parameters: {'x': 3.4794348278321627, 'y': -4.250239386469112}. Best is trial 249 with value: 0.004556208545386644.\n",
      "[I 2025-08-11 10:26:14,206] Trial 308 finished with value: 0.43813225807163575 and parameters: {'x': 2.5817929934386066, 'y': -5.513064477170847}. Best is trial 249 with value: 0.004556208545386644.\n",
      "[I 2025-08-11 10:26:14,218] Trial 309 finished with value: 11.137316817277757 and parameters: {'x': 0.004344367186470088, 'y': -3.5291620936111525}. Best is trial 249 with value: 0.004556208545386644.\n",
      "[I 2025-08-11 10:26:14,227] Trial 310 finished with value: 0.07361711911735642 and parameters: {'x': 3.0581483048350484, 'y': -4.734979446528827}. Best is trial 249 with value: 0.004556208545386644.\n",
      "[I 2025-08-11 10:26:14,227] Trial 311 finished with value: 0.2909061119523927 and parameters: {'x': 2.872643236476951, 'y': -4.4758946988082196}. Best is trial 249 with value: 0.004556208545386644.\n",
      "[I 2025-08-11 10:26:14,237] Trial 312 finished with value: 1.1740568238727105 and parameters: {'x': 1.9422980687482057, 'y': -4.764790628377748}. Best is trial 249 with value: 0.004556208545386644.\n",
      "[I 2025-08-11 10:26:14,237] Trial 313 finished with value: 5.130270117340402 and parameters: {'x': 3.9269400986191476, 'y': -2.9333475931080413}. Best is trial 249 with value: 0.004556208545386644.\n",
      "[I 2025-08-11 10:26:14,247] Trial 314 finished with value: 5.5501981009672345 and parameters: {'x': 4.646180866711949, 'y': -6.68531500172482}. Best is trial 249 with value: 0.004556208545386644.\n",
      "[I 2025-08-11 10:26:14,258] Trial 315 finished with value: 13.72442076584482 and parameters: {'x': 6.5107522345727675, 'y': -3.8171899927346145}. Best is trial 249 with value: 0.004556208545386644.\n",
      "[I 2025-08-11 10:26:14,263] Trial 316 finished with value: 1.4885318377250234 and parameters: {'x': 2.3691418119502967, 'y': -6.044293916622935}. Best is trial 249 with value: 0.004556208545386644.\n",
      "[I 2025-08-11 10:26:14,268] Trial 317 finished with value: 0.12265671218075783 and parameters: {'x': 3.343606993005556, 'y': -5.067756523954802}. Best is trial 249 with value: 0.004556208545386644.\n",
      "[I 2025-08-11 10:26:14,273] Trial 318 finished with value: 0.4902733316733953 and parameters: {'x': 2.8971477887609054, 'y': -4.307400004102928}. Best is trial 249 with value: 0.004556208545386644.\n",
      "[I 2025-08-11 10:26:14,278] Trial 319 finished with value: 0.9399854554613553 and parameters: {'x': 3.5675450378753086, 'y': -5.786052215469475}. Best is trial 249 with value: 0.004556208545386644.\n",
      "[I 2025-08-11 10:26:14,289] Trial 320 finished with value: 2.2365063139579764 and parameters: {'x': 1.5169718935117669, 'y': -4.807298289255383}. Best is trial 249 with value: 0.004556208545386644.\n",
      "[I 2025-08-11 10:26:14,289] Trial 321 finished with value: 2.2864070848652456 and parameters: {'x': 2.6339459309634585, 'y': -3.532890084756075}. Best is trial 249 with value: 0.004556208545386644.\n",
      "[I 2025-08-11 10:26:14,299] Trial 322 finished with value: 0.2665818684400262 and parameters: {'x': 3.086221467707085, 'y': -5.509065542878775}. Best is trial 249 with value: 0.004556208545386644.\n",
      "[I 2025-08-11 10:26:14,299] Trial 323 finished with value: 2.127060032534213 and parameters: {'x': 4.315124324129379, 'y': -4.369517609589724}. Best is trial 249 with value: 0.004556208545386644.\n",
      "[I 2025-08-11 10:26:14,314] Trial 324 finished with value: 0.8369987793771977 and parameters: {'x': 2.166554335729982, 'y': -5.377315655766768}. Best is trial 249 with value: 0.004556208545386644.\n",
      "[I 2025-08-11 10:26:14,319] Trial 325 finished with value: 298.7965463155458 and parameters: {'x': 3.7141046156225266, 'y': 12.270975679257164}. Best is trial 249 with value: 0.004556208545386644.\n",
      "[I 2025-08-11 10:26:14,326] Trial 326 finished with value: 1.929007866207286 and parameters: {'x': 3.246404465518592, 'y': -6.366855041904511}. Best is trial 249 with value: 0.004556208545386644.\n",
      "[I 2025-08-11 10:26:14,329] Trial 327 finished with value: 0.15657177749922774 and parameters: {'x': 2.617750025893067, 'y': -4.897741822847869}. Best is trial 249 with value: 0.004556208545386644.\n",
      "[I 2025-08-11 10:26:14,340] Trial 328 finished with value: 1.7793966077467283 and parameters: {'x': 4.052247220315858, 'y': -4.180138795231609}. Best is trial 249 with value: 0.004556208545386644.\n",
      "[I 2025-08-11 10:26:14,346] Trial 329 finished with value: 0.5123893121890628 and parameters: {'x': 2.8964613873138343, 'y': -5.708286007113007}. Best is trial 249 with value: 0.004556208545386644.\n",
      "[I 2025-08-11 10:26:14,353] Trial 330 finished with value: 0.25318429804751125 and parameters: {'x': 3.4978769455938554, 'y': -4.927179363545459}. Best is trial 249 with value: 0.004556208545386644.\n",
      "[I 2025-08-11 10:26:14,360] Trial 331 finished with value: 2.0458958468775603 and parameters: {'x': 2.2423712360629087, 'y': -3.7867834064221197}. Best is trial 249 with value: 0.004556208545386644.\n",
      "[I 2025-08-11 10:26:14,365] Trial 332 finished with value: 3.491276834582039 and parameters: {'x': 3.1087262055494858, 'y': -6.865329849331975}. Best is trial 249 with value: 0.004556208545386644.\n",
      "[I 2025-08-11 10:26:14,373] Trial 333 finished with value: 61.906148024990294 and parameters: {'x': 1.7350004697707304, 'y': 2.765688907850354}. Best is trial 249 with value: 0.004556208545386644.\n",
      "[I 2025-08-11 10:26:14,373] Trial 334 finished with value: 0.25676396980832494 and parameters: {'x': 2.7193012036166917, 'y': -5.421867462027219}. Best is trial 249 with value: 0.004556208545386644.\n",
      "[I 2025-08-11 10:26:14,383] Trial 335 finished with value: 0.6783210303057743 and parameters: {'x': 3.642734094018836, 'y': -4.485010762547837}. Best is trial 249 with value: 0.004556208545386644.\n",
      "[I 2025-08-11 10:26:14,383] Trial 336 finished with value: 1.030929152589071 and parameters: {'x': 3.2898625955305056, 'y': -5.973092404811275}. Best is trial 249 with value: 0.004556208545386644.\n",
      "[I 2025-08-11 10:26:14,393] Trial 337 finished with value: 0.32879267216340846 and parameters: {'x': 2.4271137089391086, 'y': -5.024371493140636}. Best is trial 249 with value: 0.004556208545386644.\n",
      "[I 2025-08-11 10:26:14,403] Trial 338 finished with value: 2.1173462873162348 and parameters: {'x': 2.9452488847915093, 'y': -3.5459200150268}. Best is trial 249 with value: 0.004556208545386644.\n",
      "[I 2025-08-11 10:26:14,403] Trial 339 finished with value: 6.635135779502612 and parameters: {'x': 4.091255527978479, 'y': -2.6666982295127313}. Best is trial 249 with value: 0.004556208545386644.\n",
      "[I 2025-08-11 10:26:14,413] Trial 340 finished with value: 0.2939378221873528 and parameters: {'x': 3.3093892808703895, 'y': -4.554785338213288}. Best is trial 249 with value: 0.004556208545386644.\n",
      "[I 2025-08-11 10:26:14,422] Trial 341 finished with value: 2.7236296506393436 and parameters: {'x': 3.8095213157814727, 'y': -6.4381602448735595}. Best is trial 249 with value: 0.004556208545386644.\n",
      "[I 2025-08-11 10:26:14,432] Trial 342 finished with value: 0.27007894977343017 and parameters: {'x': 2.6080912075145473, 'y': -5.341301110672123}. Best is trial 249 with value: 0.004556208545386644.\n",
      "[I 2025-08-11 10:26:14,439] Trial 343 finished with value: 2.223380914116727 and parameters: {'x': 1.985359700249567, 'y': -3.9073491059633554}. Best is trial 249 with value: 0.004556208545386644.\n",
      "[I 2025-08-11 10:26:14,450] Trial 344 finished with value: 1.0367304791813705 and parameters: {'x': 3.020461720332135, 'y': -6.017994006457022}. Best is trial 249 with value: 0.004556208545386644.\n",
      "[I 2025-08-11 10:26:14,463] Trial 345 finished with value: 5.900541571891986 and parameters: {'x': 3.4696062065480886, 'y': -7.38327748755018}. Best is trial 249 with value: 0.004556208545386644.\n",
      "[I 2025-08-11 10:26:14,466] Trial 346 finished with value: 9.751466395463181 and parameters: {'x': 2.473301398794626, 'y': -1.9220047142739993}. Best is trial 249 with value: 0.004556208545386644.\n",
      "[I 2025-08-11 10:26:14,481] Trial 347 finished with value: 0.09513635092969558 and parameters: {'x': 2.882917738537275, 'y': -4.714643915466185}. Best is trial 249 with value: 0.004556208545386644.\n",
      "[I 2025-08-11 10:26:14,487] Trial 348 finished with value: 0.20071611546093943 and parameters: {'x': 3.28812145662628, 'y': -5.343077457278222}. Best is trial 249 with value: 0.004556208545386644.\n",
      "[I 2025-08-11 10:26:14,489] Trial 349 finished with value: 3.527460683327013 and parameters: {'x': 3.7788350852704973, 'y': -3.2909427764762498}. Best is trial 249 with value: 0.004556208545386644.\n",
      "[I 2025-08-11 10:26:14,499] Trial 350 finished with value: 1.537536676801524 and parameters: {'x': 2.0792439641053524, 'y': -4.169491120357465}. Best is trial 249 with value: 0.004556208545386644.\n",
      "[I 2025-08-11 10:26:14,508] Trial 351 finished with value: 0.04109722516603268 and parameters: {'x': 2.8011409691034515, 'y': -4.960600621871428}. Best is trial 249 with value: 0.004556208545386644.\n",
      "[I 2025-08-11 10:26:14,514] Trial 352 finished with value: 4.653800776634386 and parameters: {'x': 1.01840341278143, 'y': -5.852687364840187}. Best is trial 249 with value: 0.004556208545386644.\n",
      "[I 2025-08-11 10:26:14,520] Trial 353 finished with value: 0.11243326594121997 and parameters: {'x': 2.6901685148990326, 'y': -5.128209659469749}. Best is trial 249 with value: 0.004556208545386644.\n",
      "[I 2025-08-11 10:26:14,528] Trial 354 finished with value: 2.558763818540041 and parameters: {'x': 2.3214697795291026, 'y': -6.448571903098965}. Best is trial 249 with value: 0.004556208545386644.\n",
      "[I 2025-08-11 10:26:14,534] Trial 355 finished with value: 48.03756800434769 and parameters: {'x': -3.917778977363634, 'y': -4.573500264134374}. Best is trial 249 with value: 0.004556208545386644.\n",
      "[I 2025-08-11 10:26:14,536] Trial 356 finished with value: 0.3401410912643791 and parameters: {'x': 3.042694826927113, 'y': -5.58165130707155}. Best is trial 249 with value: 0.004556208545386644.\n",
      "[I 2025-08-11 10:26:14,546] Trial 357 finished with value: 2.7953105409313483 and parameters: {'x': 4.442976238239912, 'y': -4.155529682696697}. Best is trial 249 with value: 0.004556208545386644.\n",
      "[I 2025-08-11 10:26:14,546] Trial 358 finished with value: 38.574209195780305 and parameters: {'x': 3.507635813223212, 'y': -11.190033527931291}. Best is trial 249 with value: 0.004556208545386644.\n",
      "[I 2025-08-11 10:26:14,556] Trial 359 finished with value: 68.5792815310728 and parameters: {'x': -2.060939659696692, 'y': 1.5548586019823443}. Best is trial 249 with value: 0.004556208545386644.\n",
      "[I 2025-08-11 10:26:14,567] Trial 360 finished with value: 162.49085401415905 and parameters: {'x': 2.7669278865809703, 'y': 7.7450590977094125}. Best is trial 249 with value: 0.004556208545386644.\n",
      "[I 2025-08-11 10:26:14,573] Trial 361 finished with value: 1.8549997253998363 and parameters: {'x': 1.6380190200562397, 'y': -5.002745117715233}. Best is trial 249 with value: 0.004556208545386644.\n",
      "[I 2025-08-11 10:26:14,574] Trial 362 finished with value: 1.9362478163489674 and parameters: {'x': 4.013494659257906, 'y': -5.953454976390951}. Best is trial 249 with value: 0.004556208545386644.\n",
      "[I 2025-08-11 10:26:14,583] Trial 363 finished with value: 0.20941457776660627 and parameters: {'x': 3.274028784686518, 'y': -5.366500754337336}. Best is trial 249 with value: 0.004556208545386644.\n",
      "[I 2025-08-11 10:26:14,593] Trial 364 finished with value: 4.143487025130611 and parameters: {'x': 2.385161770358965, 'y': -6.940479573843149}. Best is trial 249 with value: 0.004556208545386644.\n",
      "[I 2025-08-11 10:26:14,594] Trial 365 finished with value: 1.2589173052383202 and parameters: {'x': 2.9274844625706247, 'y': -3.880330940826867}. Best is trial 249 with value: 0.004556208545386644.\n",
      "[I 2025-08-11 10:26:14,603] Trial 366 finished with value: 3.77401553656659 and parameters: {'x': 4.918495326196702, 'y': -4.694400229175477}. Best is trial 249 with value: 0.004556208545386644.\n",
      "[I 2025-08-11 10:26:14,612] Trial 367 finished with value: 3.9254884819024194 and parameters: {'x': 3.490407260503041, 'y': -3.0803674307961115}. Best is trial 249 with value: 0.004556208545386644.\n",
      "[I 2025-08-11 10:26:14,619] Trial 368 finished with value: 0.6624119244347197 and parameters: {'x': 3.7987234334851503, 'y': -5.156373914820895}. Best is trial 249 with value: 0.004556208545386644.\n",
      "[I 2025-08-11 10:26:14,627] Trial 369 finished with value: 1.8185047418012474 and parameters: {'x': 2.58427345059106, 'y': -6.282839108352167}. Best is trial 249 with value: 0.004556208545386644.\n",
      "[I 2025-08-11 10:26:14,634] Trial 370 finished with value: 1.3686966950797952 and parameters: {'x': 1.9962595935876308, 'y': -4.398999258224312}. Best is trial 249 with value: 0.004556208545386644.\n",
      "[I 2025-08-11 10:26:14,642] Trial 371 finished with value: 221.072117554469 and parameters: {'x': 3.1459630691491487, 'y': 9.86777765292828}. Best is trial 249 with value: 0.004556208545386644.\n",
      "[I 2025-08-11 10:26:14,642] Trial 372 finished with value: 0.44241212107609307 and parameters: {'x': 2.7590611033356853, 'y': -5.619968200112131}. Best is trial 249 with value: 0.004556208545386644.\n",
      "[I 2025-08-11 10:26:14,650] Trial 373 finished with value: 87.5399104708697 and parameters: {'x': 3.2598327332414465, 'y': -14.352667930681918}. Best is trial 249 with value: 0.004556208545386644.\n",
      "[I 2025-08-11 10:26:14,656] Trial 374 finished with value: 1.587495865235867 and parameters: {'x': 4.231920050246995, 'y': -4.735672825772095}. Best is trial 249 with value: 0.004556208545386644.\n",
      "[I 2025-08-11 10:26:14,671] Trial 375 finished with value: 1.821171166872543 and parameters: {'x': 2.3309261483028854, 'y': -3.8280309953553675}. Best is trial 249 with value: 0.004556208545386644.\n",
      "[I 2025-08-11 10:26:14,679] Trial 376 finished with value: 1.0448835997975425 and parameters: {'x': 3.7458964028584663, 'y': -5.698943600013866}. Best is trial 249 with value: 0.004556208545386644.\n",
      "[I 2025-08-11 10:26:14,679] Trial 377 finished with value: 0.010065118312072602 and parameters: {'x': 2.925856914220952, 'y': -5.067586397619886}. Best is trial 249 with value: 0.004556208545386644.\n",
      "[I 2025-08-11 10:26:14,689] Trial 378 finished with value: 0.3568494783688127 and parameters: {'x': 2.848385640954409, 'y': -4.4221915849522375}. Best is trial 249 with value: 0.004556208545386644.\n",
      "[I 2025-08-11 10:26:14,699] Trial 379 finished with value: 0.6614695457246093 and parameters: {'x': 2.1867618135129394, 'y': -4.989360556224779}. Best is trial 249 with value: 0.004556208545386644.\n",
      "[I 2025-08-11 10:26:14,706] Trial 380 finished with value: 1.3203135640953856 and parameters: {'x': 3.47845689191905, 'y': -3.9553026435036087}. Best is trial 249 with value: 0.004556208545386644.\n",
      "[I 2025-08-11 10:26:14,706] Trial 381 finished with value: 145.9001848655649 and parameters: {'x': -9.018039762083198, 'y': -6.211158595127878}. Best is trial 249 with value: 0.004556208545386644.\n",
      "[I 2025-08-11 10:26:14,719] Trial 382 finished with value: 8.983027938411174 and parameters: {'x': 2.632215050197016, 'y': -7.974518813036756}. Best is trial 249 with value: 0.004556208545386644.\n",
      "[I 2025-08-11 10:26:14,726] Trial 383 finished with value: 0.016313673251775 and parameters: {'x': 3.1216422262831527, 'y': -5.038946656296186}. Best is trial 249 with value: 0.004556208545386644.\n",
      "[I 2025-08-11 10:26:14,726] Trial 384 finished with value: 0.32210940840769664 and parameters: {'x': 3.2121338980530085, 'y': -5.5264110729311575}. Best is trial 249 with value: 0.004556208545386644.\n",
      "[I 2025-08-11 10:26:14,742] Trial 385 finished with value: 17.094112958248395 and parameters: {'x': 3.7016702220028304, 'y': -0.9254728056125465}. Best is trial 249 with value: 0.004556208545386644.\n",
      "[I 2025-08-11 10:26:14,750] Trial 386 finished with value: 71.49079770012737 and parameters: {'x': -5.454657291028906, 'y': -5.097815087686657}. Best is trial 249 with value: 0.004556208545386644.\n",
      "[I 2025-08-11 10:26:14,756] Trial 387 finished with value: 17.394934714164883 and parameters: {'x': 3.1199732228546995, 'y': -9.168997618128696}. Best is trial 249 with value: 0.004556208545386644.\n",
      "[I 2025-08-11 10:26:14,756] Trial 388 finished with value: 4.903726647621583 and parameters: {'x': 1.732566743909186, 'y': -6.815857810781621}. Best is trial 249 with value: 0.004556208545386644.\n",
      "[I 2025-08-11 10:26:14,768] Trial 389 finished with value: 4.363597373858236 and parameters: {'x': 4.091165535896063, 'y': -3.218720923849692}. Best is trial 249 with value: 0.004556208545386644.\n",
      "[I 2025-08-11 10:26:14,773] Trial 390 finished with value: 1.555925613754114 and parameters: {'x': 2.5274683076119717, 'y': -6.154400023147531}. Best is trial 249 with value: 0.004556208545386644.\n",
      "[I 2025-08-11 10:26:14,782] Trial 391 finished with value: 0.7353600075979605 and parameters: {'x': 3.4649373643862384, 'y': -4.279449339188743}. Best is trial 249 with value: 0.004556208545386644.\n",
      "[I 2025-08-11 10:26:14,789] Trial 392 finished with value: 0.4596782636834647 and parameters: {'x': 2.9083788235242287, 'y': -5.671776617414346}. Best is trial 249 with value: 0.004556208545386644.\n",
      "[I 2025-08-11 10:26:14,789] Trial 393 finished with value: 0.5160434150966323 and parameters: {'x': 2.2913525204328087, 'y': -4.882262305102828}. Best is trial 249 with value: 0.004556208545386644.\n",
      "[I 2025-08-11 10:26:14,799] Trial 394 finished with value: 2.3453111178195014 and parameters: {'x': 3.667515853310003, 'y': -3.6216917241054816}. Best is trial 249 with value: 0.004556208545386644.\n",
      "[I 2025-08-11 10:26:14,811] Trial 395 finished with value: 0.07740646690659249 and parameters: {'x': 3.146571856461838, 'y': -5.236480776808439}. Best is trial 249 with value: 0.004556208545386644.\n",
      "[I 2025-08-11 10:26:14,818] Trial 396 finished with value: 0.5808246669763284 and parameters: {'x': 2.5841258230505666, 'y': -4.361350380941976}. Best is trial 249 with value: 0.004556208545386644.\n",
      "[I 2025-08-11 10:26:14,825] Trial 397 finished with value: 3.2149149399589048 and parameters: {'x': 4.547835158175805, 'y': -5.905053182456029}. Best is trial 249 with value: 0.004556208545386644.\n",
      "[I 2025-08-11 10:26:14,826] Trial 398 finished with value: 30.107520936100535 and parameters: {'x': 7.750554381123594, 'y': -2.254138749301422}. Best is trial 249 with value: 0.004556208545386644.\n",
      "[I 2025-08-11 10:26:14,837] Trial 399 finished with value: 29.091983421491207 and parameters: {'x': 3.9195846272285726, 'y': 0.31472930024249646}. Best is trial 249 with value: 0.004556208545386644.\n",
      "[I 2025-08-11 10:26:14,837] Trial 400 finished with value: 2.5155522759165683 and parameters: {'x': 3.2942595832040613, 'y': -6.558513257437722}. Best is trial 249 with value: 0.004556208545386644.\n",
      "[I 2025-08-11 10:26:14,851] Trial 401 finished with value: 0.13642634293055755 and parameters: {'x': 2.86047771022171, 'y': -4.658006032822828}. Best is trial 249 with value: 0.004556208545386644.\n",
      "[I 2025-08-11 10:26:14,857] Trial 402 finished with value: 2.700746981131613 and parameters: {'x': 1.3793868975126091, 'y': -5.272690581388148}. Best is trial 249 with value: 0.004556208545386644.\n",
      "[I 2025-08-11 10:26:14,857] Trial 403 finished with value: 6.066420745045941 and parameters: {'x': 2.1814728757636686, 'y': -7.323022619764031}. Best is trial 249 with value: 0.004556208545386644.\n",
      "[I 2025-08-11 10:26:14,872] Trial 404 finished with value: 1.2336431359200173 and parameters: {'x': 3.4256601317819535, 'y': -3.9741069314341835}. Best is trial 249 with value: 0.004556208545386644.\n",
      "[I 2025-08-11 10:26:14,873] Trial 405 finished with value: 0.40084303343182315 and parameters: {'x': 2.8841048925611776, 'y': -5.622423776460674}. Best is trial 249 with value: 0.004556208545386644.\n",
      "[I 2025-08-11 10:26:14,882] Trial 406 finished with value: 1.3275989420532117 and parameters: {'x': 1.883712443208437, 'y': -4.714516143003611}. Best is trial 249 with value: 0.004556208545386644.\n",
      "[I 2025-08-11 10:26:14,893] Trial 407 finished with value: 2.9355936695771474 and parameters: {'x': 2.5599782651868086, 'y': -3.3441091393243525}. Best is trial 249 with value: 0.004556208545386644.\n",
      "[I 2025-08-11 10:26:14,893] Trial 408 finished with value: 1.8700998591437292 and parameters: {'x': 3.7070673059787493, 'y': -6.17053649407427}. Best is trial 249 with value: 0.004556208545386644.\n",
      "[I 2025-08-11 10:26:14,903] Trial 409 finished with value: 0.027318456956025403 and parameters: {'x': 3.1187369707980728, 'y': -5.114978209769169}. Best is trial 249 with value: 0.004556208545386644.\n",
      "[I 2025-08-11 10:26:14,918] Trial 410 finished with value: 1.5942928431029406 and parameters: {'x': 4.186019760538191, 'y': -5.433185838544929}. Best is trial 249 with value: 0.004556208545386644.\n",
      "[I 2025-08-11 10:26:14,925] Trial 411 finished with value: 0.9426170080194786 and parameters: {'x': 3.3955645508174426, 'y': -4.1133514257858}. Best is trial 249 with value: 0.004556208545386644.\n",
      "[I 2025-08-11 10:26:14,936] Trial 412 finished with value: 0.06822804952605135 and parameters: {'x': 2.7411408828497312, 'y': -5.034928598515182}. Best is trial 249 with value: 0.004556208545386644.\n",
      "[I 2025-08-11 10:26:14,948] Trial 413 finished with value: 1.2427927958073597 and parameters: {'x': 2.350261357646943, 'y': -5.905887682022758}. Best is trial 249 with value: 0.004556208545386644.\n",
      "[I 2025-08-11 10:26:14,961] Trial 414 finished with value: 0.06777645400998163 and parameters: {'x': 2.7493674119244584, 'y': -5.070425562152797}. Best is trial 249 with value: 0.004556208545386644.\n",
      "[I 2025-08-11 10:26:14,969] Trial 415 finished with value: 3.078883287127014 and parameters: {'x': 2.073359210342592, 'y': -6.490040312901}. Best is trial 249 with value: 0.004556208545386644.\n",
      "[I 2025-08-11 10:26:14,977] Trial 416 finished with value: 0.4516217463446645 and parameters: {'x': 2.9108431528036376, 'y': -4.333912315875253}. Best is trial 249 with value: 0.004556208545386644.\n",
      "[I 2025-08-11 10:26:14,978] Trial 417 finished with value: 0.5859808440232045 and parameters: {'x': 2.392393527274612, 'y': -5.465612734281846}. Best is trial 249 with value: 0.004556208545386644.\n",
      "[I 2025-08-11 10:26:14,988] Trial 418 finished with value: 0.05469868435129825 and parameters: {'x': 3.0850035282011747, 'y': -4.782116809862141}. Best is trial 249 with value: 0.004556208545386644.\n",
      "[I 2025-08-11 10:26:14,998] Trial 419 finished with value: 122.55898386016703 and parameters: {'x': 3.8792291068873275, 'y': 6.0356667237539}. Best is trial 249 with value: 0.004556208545386644.\n",
      "[I 2025-08-11 10:26:14,998] Trial 420 finished with value: 9.67448774173197 and parameters: {'x': 5.95004449073452, 'y': -4.014238748773884}. Best is trial 249 with value: 0.004556208545386644.\n",
      "[I 2025-08-11 10:26:15,009] Trial 421 finished with value: 0.238719048798816 and parameters: {'x': 3.2813708561042323, 'y': -4.600563534296144}. Best is trial 249 with value: 0.004556208545386644.\n",
      "[I 2025-08-11 10:26:15,019] Trial 422 finished with value: 2.257391220502115 and parameters: {'x': 3.4988581345452436, 'y': -3.582773207245871}. Best is trial 249 with value: 0.004556208545386644.\n",
      "[I 2025-08-11 10:26:15,025] Trial 423 finished with value: 4.29339564333066 and parameters: {'x': 3.1917935682716236, 'y': -2.9368444386085915}. Best is trial 249 with value: 0.004556208545386644.\n",
      "[I 2025-08-11 10:26:15,029] Trial 424 finished with value: 0.774994998400164 and parameters: {'x': 2.9404511954731194, 'y': -5.87832165991713}. Best is trial 249 with value: 0.004556208545386644.\n",
      "[I 2025-08-11 10:26:15,039] Trial 425 finished with value: 0.6653984633198488 and parameters: {'x': 3.678865814898903, 'y': -4.547739379691867}. Best is trial 249 with value: 0.004556208545386644.\n",
      "[I 2025-08-11 10:26:15,039] Trial 426 finished with value: 3.929267616115071 and parameters: {'x': 2.589025460929651, 'y': -6.939166713913733}. Best is trial 249 with value: 0.004556208545386644.\n",
      "[I 2025-08-11 10:26:15,049] Trial 427 finished with value: 1.4800650120592136 and parameters: {'x': 1.8662278780836428, 'y': -5.441164127762553}. Best is trial 249 with value: 0.004556208545386644.\n",
      "[I 2025-08-11 10:26:15,060] Trial 428 finished with value: 1.2018845823117292 and parameters: {'x': 4.087852071557437, 'y': -4.8641233915645445}. Best is trial 249 with value: 0.004556208545386644.\n",
      "[I 2025-08-11 10:26:15,060] Trial 429 finished with value: 1.6915673629440942 and parameters: {'x': 3.248426347541549, 'y': -6.276656458406591}. Best is trial 249 with value: 0.004556208545386644.\n",
      "[I 2025-08-11 10:26:15,073] Trial 430 finished with value: 1.4028206285470648 and parameters: {'x': 3.018915057290222, 'y': -3.81574375697032}. Best is trial 249 with value: 0.004556208545386644.\n",
      "[I 2025-08-11 10:26:15,073] Trial 431 finished with value: 0.4081493616835405 and parameters: {'x': 3.618830965521141, 'y': -5.158737512251242}. Best is trial 249 with value: 0.004556208545386644.\n",
      "[I 2025-08-11 10:26:15,089] Trial 432 finished with value: 0.6887700746652028 and parameters: {'x': 2.4696976833698465, 'y': -4.361603941395394}. Best is trial 249 with value: 0.004556208545386644.\n",
      "[I 2025-08-11 10:26:15,089] Trial 433 finished with value: 0.6326155932723256 and parameters: {'x': 2.8126080593599982, 'y': -5.772981147153991}. Best is trial 249 with value: 0.004556208545386644.\n",
      "[I 2025-08-11 10:26:15,099] Trial 434 finished with value: 0.6743640815317522 and parameters: {'x': 2.178840821367395, 'y': -5.007853972191061}. Best is trial 249 with value: 0.004556208545386644.\n",
      "[I 2025-08-11 10:26:15,109] Trial 435 finished with value: 0.7836280699196629 and parameters: {'x': 3.447457906651019, 'y': -4.2361875284501105}. Best is trial 249 with value: 0.004556208545386644.\n",
      "[I 2025-08-11 10:26:15,109] Trial 436 finished with value: 6.783300591424496 and parameters: {'x': 5.112505899391851, 'y': -3.476642058983142}. Best is trial 249 with value: 0.004556208545386644.\n",
      "[I 2025-08-11 10:26:15,122] Trial 437 finished with value: 1.726333290372498 and parameters: {'x': 3.9937462031683033, 'y': -5.859535789866297}. Best is trial 249 with value: 0.004556208545386644.\n",
      "[I 2025-08-11 10:26:15,129] Trial 438 finished with value: 2.3345335788411647 and parameters: {'x': 4.479398951769495, 'y': -5.381984712186868}. Best is trial 249 with value: 0.004556208545386644.\n",
      "[I 2025-08-11 10:26:15,132] Trial 439 finished with value: 2.6471155057959677 and parameters: {'x': 3.0702044749438566, 'y': -6.625480494344311}. Best is trial 249 with value: 0.004556208545386644.\n",
      "[I 2025-08-11 10:26:15,143] Trial 440 finished with value: 0.36884693348393965 and parameters: {'x': 2.545866438448783, 'y': -4.596751141654751}. Best is trial 249 with value: 0.004556208545386644.\n",
      "[I 2025-08-11 10:26:15,150] Trial 441 finished with value: 2.866539115973879 and parameters: {'x': 1.3308211230860836, 'y': -5.283515419048551}. Best is trial 249 with value: 0.004556208545386644.\n",
      "[I 2025-08-11 10:26:15,157] Trial 442 finished with value: 1.0343393089688029 and parameters: {'x': 3.1023642956592803, 'y': -3.9881399010026226}. Best is trial 249 with value: 0.004556208545386644.\n",
      "[I 2025-08-11 10:26:15,157] Trial 443 finished with value: 1.536920637316703 and parameters: {'x': 3.450607554463357, 'y': -6.154934400378331}. Best is trial 249 with value: 0.004556208545386644.\n",
      "[I 2025-08-11 10:26:15,172] Trial 444 finished with value: 0.15586096192631593 and parameters: {'x': 2.642114091542278, 'y': -4.833330751325546}. Best is trial 249 with value: 0.004556208545386644.\n",
      "[I 2025-08-11 10:26:15,179] Trial 445 finished with value: 6.973313551167442 and parameters: {'x': 3.7420635572641587, 'y': -2.4657041948209946}. Best is trial 249 with value: 0.004556208545386644.\n",
      "[I 2025-08-11 10:26:15,186] Trial 446 finished with value: 81.19807528012345 and parameters: {'x': 1.954651434882189, 'y': 3.9501576331106927}. Best is trial 249 with value: 0.004556208545386644.\n",
      "[I 2025-08-11 10:26:15,193] Trial 447 finished with value: 0.2361134583997093 and parameters: {'x': 3.0125759091877393, 'y': -4.514247691814222}. Best is trial 249 with value: 0.004556208545386644.\n",
      "[I 2025-08-11 10:26:15,201] Trial 448 finished with value: 0.8849365938778146 and parameters: {'x': 2.2803326602290115, 'y': -5.605818053498543}. Best is trial 249 with value: 0.004556208545386644.\n",
      "[I 2025-08-11 10:26:15,205] Trial 449 finished with value: 6.554229782145864 and parameters: {'x': 2.724976458208152, 'y': -7.545307807241814}. Best is trial 249 with value: 0.004556208545386644.\n",
      "[I 2025-08-11 10:26:15,205] Trial 450 finished with value: 102.20024605743448 and parameters: {'x': -7.1093516024450265, 'y': -5.035443413727165}. Best is trial 249 with value: 0.004556208545386644.\n",
      "[I 2025-08-11 10:26:15,222] Trial 451 finished with value: 2.6476912454695563 and parameters: {'x': 3.382746773684216, 'y': -3.4184829584529037}. Best is trial 249 with value: 0.004556208545386644.\n",
      "[I 2025-08-11 10:26:15,223] Trial 452 finished with value: 2.677999208857959 and parameters: {'x': 4.2889022004989705, 'y': -6.00833046488087}. Best is trial 249 with value: 0.004556208545386644.\n",
      "[I 2025-08-11 10:26:15,232] Trial 453 finished with value: 1.4133813429329853 and parameters: {'x': 3.769749553016779, 'y': -4.093982909342515}. Best is trial 249 with value: 0.004556208545386644.\n",
      "[I 2025-08-11 10:26:15,246] Trial 454 finished with value: 0.22770202863376313 and parameters: {'x': 3.0010527087783183, 'y': -5.4771801760739764}. Best is trial 249 with value: 0.004556208545386644.\n",
      "[I 2025-08-11 10:26:15,253] Trial 455 finished with value: 3.631314312549766 and parameters: {'x': 2.4144895201325376, 'y': -6.813419915660777}. Best is trial 249 with value: 0.004556208545386644.\n",
      "[I 2025-08-11 10:26:15,262] Trial 456 finished with value: 0.16472344895303148 and parameters: {'x': 3.1003351406587374, 'y': -4.606736337170566}. Best is trial 249 with value: 0.004556208545386644.\n",
      "[I 2025-08-11 10:26:15,269] Trial 457 finished with value: 0.21583497779319585 and parameters: {'x': 3.464189215392913, 'y': -5.019061744571462}. Best is trial 249 with value: 0.004556208545386644.\n",
      "[I 2025-08-11 10:26:15,280] Trial 458 finished with value: 1.6795556501376412 and parameters: {'x': 2.702853571817116, 'y': -6.261451406260184}. Best is trial 249 with value: 0.004556208545386644.\n",
      "[I 2025-08-11 10:26:15,293] Trial 459 finished with value: 11.975819662485206 and parameters: {'x': -0.2672504391932162, 'y': -3.859432496483903}. Best is trial 249 with value: 0.004556208545386644.\n",
      "[I 2025-08-11 10:26:15,299] Trial 460 finished with value: 5.549317718057532 and parameters: {'x': 1.7948209486310018, 'y': -2.9759295535483816}. Best is trial 249 with value: 0.004556208545386644.\n",
      "[I 2025-08-11 10:26:15,310] Trial 461 finished with value: 0.8183511285268716 and parameters: {'x': 3.71101300757591, 'y': -5.5592956566832346}. Best is trial 249 with value: 0.004556208545386644.\n",
      "[I 2025-08-11 10:26:15,316] Trial 462 finished with value: 0.2343542591312898 and parameters: {'x': 3.164548308527123, 'y': -4.544721938490166}. Best is trial 249 with value: 0.004556208545386644.\n",
      "[I 2025-08-11 10:26:15,326] Trial 463 finished with value: 0.6261207054541857 and parameters: {'x': 2.208754708173282, 'y': -4.9928171303619076}. Best is trial 249 with value: 0.004556208545386644.\n",
      "[I 2025-08-11 10:26:15,326] Trial 464 finished with value: 1.7514084085036652 and parameters: {'x': 4.0535334759629595, 'y': -5.800921733710023}. Best is trial 249 with value: 0.004556208545386644.\n",
      "[I 2025-08-11 10:26:15,336] Trial 465 finished with value: 0.753986203089923 and parameters: {'x': 2.808184453954077, 'y': -4.153127518817014}. Best is trial 249 with value: 0.004556208545386644.\n",
      "[I 2025-08-11 10:26:15,346] Trial 466 finished with value: 0.25828621770923815 and parameters: {'x': 3.454409879875636, 'y': -5.227591473435734}. Best is trial 249 with value: 0.004556208545386644.\n",
      "[I 2025-08-11 10:26:15,357] Trial 467 finished with value: 2.307815391551496 and parameters: {'x': 2.5099019988111744, 'y': -6.437921882712066}. Best is trial 249 with value: 0.004556208545386644.\n",
      "[I 2025-08-11 10:26:15,357] Trial 468 finished with value: 0.08253783143650031 and parameters: {'x': 3.20318043081498, 'y': -4.79688539203115}. Best is trial 249 with value: 0.004556208545386644.\n",
      "[I 2025-08-11 10:26:15,367] Trial 469 finished with value: 2.1509107913909724 and parameters: {'x': 2.7998865893030946, 'y': -3.547118238035103}. Best is trial 249 with value: 0.004556208545386644.\n",
      "[I 2025-08-11 10:26:15,377] Trial 470 finished with value: 3.0701387163694505 and parameters: {'x': 4.614284890417242, 'y': -5.681339129171402}. Best is trial 249 with value: 0.004556208545386644.\n",
      "[I 2025-08-11 10:26:15,377] Trial 471 finished with value: 1.26463382422141 and parameters: {'x': 3.890048573669685, 'y': -4.312651936257932}. Best is trial 249 with value: 0.004556208545386644.\n",
      "[I 2025-08-11 10:26:15,391] Trial 472 finished with value: 52.39734931464606 and parameters: {'x': 9.938849003276953, 'y': -7.0614858292912155}. Best is trial 249 with value: 0.004556208545386644.\n",
      "[I 2025-08-11 10:26:15,397] Trial 473 finished with value: 0.5031481880667092 and parameters: {'x': 2.3102435540359343, 'y': -5.165481821713837}. Best is trial 249 with value: 0.004556208545386644.\n",
      "[I 2025-08-11 10:26:15,399] Trial 474 finished with value: 7.4223723234428585 and parameters: {'x': 0.5465798429262843, 'y': -6.184526004909661}. Best is trial 249 with value: 0.004556208545386644.\n",
      "[I 2025-08-11 10:26:15,405] Trial 475 finished with value: 0.3616770174353522 and parameters: {'x': 3.3767669131710503, 'y': -4.5312530420633}. Best is trial 249 with value: 0.004556208545386644.\n",
      "[I 2025-08-11 10:26:15,415] Trial 476 finished with value: 1.2511562771232778 and parameters: {'x': 2.932849294525493, 'y': -3.8834664985422274}. Best is trial 249 with value: 0.004556208545386644.\n",
      "[I 2025-08-11 10:26:15,426] Trial 477 finished with value: 0.7261448608516305 and parameters: {'x': 3.61554676515733, 'y': -5.589276709836709}. Best is trial 249 with value: 0.004556208545386644.\n",
      "[I 2025-08-11 10:26:15,426] Trial 478 finished with value: 1.9520082115842499 and parameters: {'x': 1.6053887586797628, 'y': -4.91593040283505}. Best is trial 249 with value: 0.004556208545386644.\n",
      "[I 2025-08-11 10:26:15,439] Trial 479 finished with value: 0.32538140933012505 and parameters: {'x': 2.6513569777704205, 'y': -5.451474752761159}. Best is trial 249 with value: 0.004556208545386644.\n",
      "[I 2025-08-11 10:26:15,439] Trial 480 finished with value: 3.836621069808251 and parameters: {'x': 2.1414132148546265, 'y': -3.239474566448419}. Best is trial 249 with value: 0.004556208545386644.\n",
      "[I 2025-08-11 10:26:15,449] Trial 481 finished with value: 0.31604912179134353 and parameters: {'x': 3.110766172647537, 'y': -4.448837613050056}. Best is trial 249 with value: 0.004556208545386644.\n",
      "[I 2025-08-11 10:26:15,459] Trial 482 finished with value: 1.3312065847685377 and parameters: {'x': 3.3278913852019087, 'y': -6.106206953638835}. Best is trial 249 with value: 0.004556208545386644.\n",
      "[I 2025-08-11 10:26:15,469] Trial 483 finished with value: 13.323910212007918 and parameters: {'x': 2.5357113274782472, 'y': -8.620545019824489}. Best is trial 249 with value: 0.004556208545386644.\n",
      "[I 2025-08-11 10:26:15,477] Trial 484 finished with value: 0.8475927943076245 and parameters: {'x': 3.9205228149823634, 'y': -4.98481641002365}. Best is trial 249 with value: 0.004556208545386644.\n",
      "[I 2025-08-11 10:26:15,482] Trial 485 finished with value: 0.970602606004103 and parameters: {'x': 2.919011432607441, 'y': -4.0181428525718195}. Best is trial 249 with value: 0.004556208545386644.\n",
      "[I 2025-08-11 10:26:15,492] Trial 486 finished with value: 2.949836797934777 and parameters: {'x': 3.5730836678782047, 'y': -6.619077486578712}. Best is trial 249 with value: 0.004556208545386644.\n",
      "[I 2025-08-11 10:26:15,492] Trial 487 finished with value: 37.59779556050681 and parameters: {'x': 1.973256957635034, 'y': 1.0451297988928192}. Best is trial 249 with value: 0.004556208545386644.\n",
      "[I 2025-08-11 10:26:15,503] Trial 488 finished with value: 0.5611727631925804 and parameters: {'x': 3.104918303871435, 'y': -5.741731024499664}. Best is trial 249 with value: 0.004556208545386644.\n",
      "[I 2025-08-11 10:26:15,513] Trial 489 finished with value: 20.935483109270226 and parameters: {'x': 2.620425761549019, 'y': -0.44024052095128763}. Best is trial 249 with value: 0.004556208545386644.\n",
      "[I 2025-08-11 10:26:15,513] Trial 490 finished with value: 0.2536524362231396 and parameters: {'x': 3.378504353899694, 'y': -4.667754773846012}. Best is trial 249 with value: 0.004556208545386644.\n",
      "[I 2025-08-11 10:26:15,530] Trial 491 finished with value: 0.4961866500552752 and parameters: {'x': 2.3311974902539614, 'y': -5.221110499553221}. Best is trial 249 with value: 0.004556208545386644.\n",
      "[I 2025-08-11 10:26:15,534] Trial 492 finished with value: 1.483650532365744 and parameters: {'x': 2.8882199340389407, 'y': -3.787087905403081}. Best is trial 249 with value: 0.004556208545386644.\n",
      "[I 2025-08-11 10:26:15,539] Trial 493 finished with value: 2.039906343361928 and parameters: {'x': 4.260478971663504, 'y': -4.3283608816067645}. Best is trial 249 with value: 0.004556208545386644.\n",
      "[I 2025-08-11 10:26:15,549] Trial 494 finished with value: 0.798337609844306 and parameters: {'x': 3.6595759965636545, 'y': -5.6027413330786}. Best is trial 249 with value: 0.004556208545386644.\n",
      "[I 2025-08-11 10:26:15,557] Trial 495 finished with value: 19.25995004245084 and parameters: {'x': -0.8194405352869838, 'y': -2.8385597302128573}. Best is trial 249 with value: 0.004556208545386644.\n",
      "[I 2025-08-11 10:26:15,567] Trial 496 finished with value: 0.01849483283360096 and parameters: {'x': 3.129101923127179, 'y': -4.957250423645784}. Best is trial 249 with value: 0.004556208545386644.\n",
      "[I 2025-08-11 10:26:15,574] Trial 497 finished with value: 1.1441822604623961 and parameters: {'x': 2.695614284036649, 'y': -6.02544214677371}. Best is trial 249 with value: 0.004556208545386644.\n",
      "[I 2025-08-11 10:26:15,574] Trial 498 finished with value: 0.7493174908882847 and parameters: {'x': 2.13483711900654, 'y': -5.028472447021297}. Best is trial 249 with value: 0.004556208545386644.\n",
      "[I 2025-08-11 10:26:15,589] Trial 499 finished with value: 2.813954371568637 and parameters: {'x': 3.1655756152091956, 'y': -6.669292990225722}. Best is trial 249 with value: 0.004556208545386644.\n"
     ]
    }
   ],
   "source": [
    "import optuna\n",
    "\n",
    "# 목적 함수\n",
    "def objective(trial):\n",
    "    x = trial.suggest_uniform('x', -10, 10)\n",
    "    y = trial.suggest_uniform('y', -15, 15)\n",
    "    return (x - 3) ** 2 + (y + 5) ** 2\n",
    "\n",
    "# 스터디 생성\n",
    "study = optuna.create_study(direction='minimize')\n",
    "\n",
    "# 최적화 실행\n",
    "study.optimize(objective, n_trials=500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "519c2570",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.004556208545386644"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "study.best_value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "821ad2f0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'x': 3.066422930433542, 'y': -4.987991550557733}"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "study.best_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "b6092be6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.plotly.v1+json": {
       "config": {
        "plotlyServerURL": "https://plot.ly"
       },
       "data": [
        {
         "cliponaxis": false,
         "hovertemplate": [
          "x (FloatDistribution): 0.08690149274307377<extra></extra>",
          "y (FloatDistribution): 0.9130985072569262<extra></extra>"
         ],
         "name": "Objective Value",
         "orientation": "h",
         "text": [
          "0.09",
          "0.91"
         ],
         "textposition": "outside",
         "type": "bar",
         "x": [
          0.08690149274307377,
          0.9130985072569262
         ],
         "y": [
          "x",
          "y"
         ]
        }
       ],
       "layout": {
        "template": {
         "data": {
          "bar": [
           {
            "error_x": {
             "color": "#2a3f5f"
            },
            "error_y": {
             "color": "#2a3f5f"
            },
            "marker": {
             "line": {
              "color": "#E5ECF6",
              "width": 0.5
             },
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "bar"
           }
          ],
          "barpolar": [
           {
            "marker": {
             "line": {
              "color": "#E5ECF6",
              "width": 0.5
             },
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "barpolar"
           }
          ],
          "carpet": [
           {
            "aaxis": {
             "endlinecolor": "#2a3f5f",
             "gridcolor": "white",
             "linecolor": "white",
             "minorgridcolor": "white",
             "startlinecolor": "#2a3f5f"
            },
            "baxis": {
             "endlinecolor": "#2a3f5f",
             "gridcolor": "white",
             "linecolor": "white",
             "minorgridcolor": "white",
             "startlinecolor": "#2a3f5f"
            },
            "type": "carpet"
           }
          ],
          "choropleth": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "choropleth"
           }
          ],
          "contour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "contour"
           }
          ],
          "contourcarpet": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "contourcarpet"
           }
          ],
          "heatmap": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "heatmap"
           }
          ],
          "histogram": [
           {
            "marker": {
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "histogram"
           }
          ],
          "histogram2d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "histogram2d"
           }
          ],
          "histogram2dcontour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "histogram2dcontour"
           }
          ],
          "mesh3d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "mesh3d"
           }
          ],
          "parcoords": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "parcoords"
           }
          ],
          "pie": [
           {
            "automargin": true,
            "type": "pie"
           }
          ],
          "scatter": [
           {
            "fillpattern": {
             "fillmode": "overlay",
             "size": 10,
             "solidity": 0.2
            },
            "type": "scatter"
           }
          ],
          "scatter3d": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatter3d"
           }
          ],
          "scattercarpet": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattercarpet"
           }
          ],
          "scattergeo": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattergeo"
           }
          ],
          "scattergl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattergl"
           }
          ],
          "scattermap": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattermap"
           }
          ],
          "scattermapbox": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattermapbox"
           }
          ],
          "scatterpolar": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterpolar"
           }
          ],
          "scatterpolargl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterpolargl"
           }
          ],
          "scatterternary": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterternary"
           }
          ],
          "surface": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "surface"
           }
          ],
          "table": [
           {
            "cells": {
             "fill": {
              "color": "#EBF0F8"
             },
             "line": {
              "color": "white"
             }
            },
            "header": {
             "fill": {
              "color": "#C8D4E3"
             },
             "line": {
              "color": "white"
             }
            },
            "type": "table"
           }
          ]
         },
         "layout": {
          "annotationdefaults": {
           "arrowcolor": "#2a3f5f",
           "arrowhead": 0,
           "arrowwidth": 1
          },
          "autotypenumbers": "strict",
          "coloraxis": {
           "colorbar": {
            "outlinewidth": 0,
            "ticks": ""
           }
          },
          "colorscale": {
           "diverging": [
            [
             0,
             "#8e0152"
            ],
            [
             0.1,
             "#c51b7d"
            ],
            [
             0.2,
             "#de77ae"
            ],
            [
             0.3,
             "#f1b6da"
            ],
            [
             0.4,
             "#fde0ef"
            ],
            [
             0.5,
             "#f7f7f7"
            ],
            [
             0.6,
             "#e6f5d0"
            ],
            [
             0.7,
             "#b8e186"
            ],
            [
             0.8,
             "#7fbc41"
            ],
            [
             0.9,
             "#4d9221"
            ],
            [
             1,
             "#276419"
            ]
           ],
           "sequential": [
            [
             0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1,
             "#f0f921"
            ]
           ],
           "sequentialminus": [
            [
             0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1,
             "#f0f921"
            ]
           ]
          },
          "colorway": [
           "#636efa",
           "#EF553B",
           "#00cc96",
           "#ab63fa",
           "#FFA15A",
           "#19d3f3",
           "#FF6692",
           "#B6E880",
           "#FF97FF",
           "#FECB52"
          ],
          "font": {
           "color": "#2a3f5f"
          },
          "geo": {
           "bgcolor": "white",
           "lakecolor": "white",
           "landcolor": "#E5ECF6",
           "showlakes": true,
           "showland": true,
           "subunitcolor": "white"
          },
          "hoverlabel": {
           "align": "left"
          },
          "hovermode": "closest",
          "mapbox": {
           "style": "light"
          },
          "paper_bgcolor": "white",
          "plot_bgcolor": "#E5ECF6",
          "polar": {
           "angularaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "bgcolor": "#E5ECF6",
           "radialaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           }
          },
          "scene": {
           "xaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           },
           "yaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           },
           "zaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           }
          },
          "shapedefaults": {
           "line": {
            "color": "#2a3f5f"
           }
          },
          "ternary": {
           "aaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "baxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "bgcolor": "#E5ECF6",
           "caxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           }
          },
          "title": {
           "x": 0.05
          },
          "xaxis": {
           "automargin": true,
           "gridcolor": "white",
           "linecolor": "white",
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "white",
           "zerolinewidth": 2
          },
          "yaxis": {
           "automargin": true,
           "gridcolor": "white",
           "linecolor": "white",
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "white",
           "zerolinewidth": 2
          }
         }
        },
        "title": {
         "text": "Hyperparameter Importances"
        },
        "xaxis": {
         "title": {
          "text": "Hyperparameter Importance"
         }
        },
        "yaxis": {
         "title": {
          "text": "Hyperparameter"
         }
        }
       }
      }
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import optuna.visualization as vis\n",
    "\n",
    "vis.plot_param_importances(study).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "28193a11",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.plotly.v1+json": {
       "config": {
        "plotlyServerURL": "https://plot.ly"
       },
       "data": [
        {
         "mode": "markers",
         "name": "Objective Value",
         "type": "scatter",
         "x": [
          0,
          1,
          2,
          3,
          4,
          5,
          6,
          7,
          8,
          9,
          10,
          11,
          12,
          13,
          14,
          15,
          16,
          17,
          18,
          19,
          20,
          21,
          22,
          23,
          24,
          25,
          26,
          27,
          28,
          29,
          30,
          31,
          32,
          33,
          34,
          35,
          36,
          37,
          38,
          39,
          40,
          41,
          42,
          43,
          44,
          45,
          46,
          47,
          48,
          49,
          50,
          51,
          52,
          53,
          54,
          55,
          56,
          57,
          58,
          59,
          60,
          61,
          62,
          63,
          64,
          65,
          66,
          67,
          68,
          69,
          70,
          71,
          72,
          73,
          74,
          75,
          76,
          77,
          78,
          79,
          80,
          81,
          82,
          83,
          84,
          85,
          86,
          87,
          88,
          89,
          90,
          91,
          92,
          93,
          94,
          95,
          96,
          97,
          98,
          99,
          100,
          101,
          102,
          103,
          104,
          105,
          106,
          107,
          108,
          109,
          110,
          111,
          112,
          113,
          114,
          115,
          116,
          117,
          118,
          119,
          120,
          121,
          122,
          123,
          124,
          125,
          126,
          127,
          128,
          129,
          130,
          131,
          132,
          133,
          134,
          135,
          136,
          137,
          138,
          139,
          140,
          141,
          142,
          143,
          144,
          145,
          146,
          147,
          148,
          149,
          150,
          151,
          152,
          153,
          154,
          155,
          156,
          157,
          158,
          159,
          160,
          161,
          162,
          163,
          164,
          165,
          166,
          167,
          168,
          169,
          170,
          171,
          172,
          173,
          174,
          175,
          176,
          177,
          178,
          179,
          180,
          181,
          182,
          183,
          184,
          185,
          186,
          187,
          188,
          189,
          190,
          191,
          192,
          193,
          194,
          195,
          196,
          197,
          198,
          199,
          200,
          201,
          202,
          203,
          204,
          205,
          206,
          207,
          208,
          209,
          210,
          211,
          212,
          213,
          214,
          215,
          216,
          217,
          218,
          219,
          220,
          221,
          222,
          223,
          224,
          225,
          226,
          227,
          228,
          229,
          230,
          231,
          232,
          233,
          234,
          235,
          236,
          237,
          238,
          239,
          240,
          241,
          242,
          243,
          244,
          245,
          246,
          247,
          248,
          249,
          250,
          251,
          252,
          253,
          254,
          255,
          256,
          257,
          258,
          259,
          260,
          261,
          262,
          263,
          264,
          265,
          266,
          267,
          268,
          269,
          270,
          271,
          272,
          273,
          274,
          275,
          276,
          277,
          278,
          279,
          280,
          281,
          282,
          283,
          284,
          285,
          286,
          287,
          288,
          289,
          290,
          291,
          292,
          293,
          294,
          295,
          296,
          297,
          298,
          299,
          300,
          301,
          302,
          303,
          304,
          305,
          306,
          307,
          308,
          309,
          310,
          311,
          312,
          313,
          314,
          315,
          316,
          317,
          318,
          319,
          320,
          321,
          322,
          323,
          324,
          325,
          326,
          327,
          328,
          329,
          330,
          331,
          332,
          333,
          334,
          335,
          336,
          337,
          338,
          339,
          340,
          341,
          342,
          343,
          344,
          345,
          346,
          347,
          348,
          349,
          350,
          351,
          352,
          353,
          354,
          355,
          356,
          357,
          358,
          359,
          360,
          361,
          362,
          363,
          364,
          365,
          366,
          367,
          368,
          369,
          370,
          371,
          372,
          373,
          374,
          375,
          376,
          377,
          378,
          379,
          380,
          381,
          382,
          383,
          384,
          385,
          386,
          387,
          388,
          389,
          390,
          391,
          392,
          393,
          394,
          395,
          396,
          397,
          398,
          399,
          400,
          401,
          402,
          403,
          404,
          405,
          406,
          407,
          408,
          409,
          410,
          411,
          412,
          413,
          414,
          415,
          416,
          417,
          418,
          419,
          420,
          421,
          422,
          423,
          424,
          425,
          426,
          427,
          428,
          429,
          430,
          431,
          432,
          433,
          434,
          435,
          436,
          437,
          438,
          439,
          440,
          441,
          442,
          443,
          444,
          445,
          446,
          447,
          448,
          449,
          450,
          451,
          452,
          453,
          454,
          455,
          456,
          457,
          458,
          459,
          460,
          461,
          462,
          463,
          464,
          465,
          466,
          467,
          468,
          469,
          470,
          471,
          472,
          473,
          474,
          475,
          476,
          477,
          478,
          479,
          480,
          481,
          482,
          483,
          484,
          485,
          486,
          487,
          488,
          489,
          490,
          491,
          492,
          493,
          494,
          495,
          496,
          497,
          498,
          499
         ],
         "y": [
          169.68452849813104,
          218.09856034625034,
          28.79093183574342,
          198.7464772705225,
          47.867473878610646,
          80.29378765063848,
          111.59862009039892,
          45.311983574566334,
          68.64753861608453,
          216.50510672658362,
          374.7464023183077,
          0.13945106485291422,
          6.342224515479275,
          4.253606722159322,
          2.1798324588656524,
          117.94523572421785,
          33.0489762854837,
          7.349294362444711,
          11.376432914769293,
          104.50497831687464,
          231.16791452913225,
          0.16159845004157633,
          0.16151304154714283,
          5.531997231388986,
          35.781097499597976,
          30.650605057805073,
          0.9016158171935257,
          80.14228841267426,
          21.27841596829137,
          93.87267401544248,
          51.132446686284325,
          2.76152918503606,
          6.290456483345596,
          20.472449731214603,
          106.21307291975768,
          1.0292473807444293,
          27.91711467650979,
          2.9866376822838046,
          56.735028740355,
          128.8133281444933,
          16.580491357456374,
          1.1820565716299125,
          2.0590773262977558,
          5.513521089024907,
          12.204345884370692,
          14.329372750179612,
          33.494541624078394,
          41.01208975630721,
          31.849713085511176,
          3.0818796430950557,
          4.444771610935387,
          1.3576927768085991,
          2.0078172582812988,
          1.9174345227104432,
          13.785171582049635,
          0.6526585151122586,
          0.5715226017612687,
          19.71530601799366,
          7.614863537253336,
          2.896557565126603,
          69.52724950199725,
          0.11673220944970891,
          19.032232391011597,
          0.1105309959386112,
          330.02526259983284,
          13.70034408175564,
          7.134135598048483,
          19.486716472308526,
          23.588103894270645,
          0.049758510577362525,
          12.745789635284227,
          0.08982390182431449,
          129.59132027345967,
          19.3017621222766,
          0.6054347458000364,
          3.0408555253179808,
          21.26387537793923,
          7.070847096675649,
          13.66831978543052,
          10.414110077883944,
          59.09236879136305,
          0.5569889402593455,
          1.3106982464643973,
          0.1760980597950048,
          14.729829668129852,
          3.835775172983286,
          2.986931959981259,
          86.67066226557024,
          22.58868213941567,
          2.521602767404871,
          0.9757069047026693,
          2.1988320101170893,
          5.496859286140379,
          1.485505814905443,
          31.47700190395583,
          12.289684939335682,
          8.554816122357622,
          6.380116115079267,
          5.934832328266354,
          3.2835396180949874,
          1.9025552055237038,
          0.26074170675481967,
          0.37872712880705267,
          1.8209427334087285,
          2.432684272055606,
          4.784268631407924,
          179.64720808749394,
          5.000579983005084,
          0.21078330305895554,
          0.03782481730133801,
          7.819751676586001,
          0.09094733650951657,
          0.03142981240916103,
          0.8405798034440775,
          3.5398970131960272,
          3.6178177286384616,
          4.248904895854643,
          3.5672270197864018,
          0.291245319828709,
          11.529530075165017,
          9.960751688776028,
          0.0807271777129555,
          0.011279016250261325,
          1.2095924716802693,
          10.942485666671677,
          1.7466898496670744,
          6.838799566651692,
          3.160185738285767,
          3.1702888523874866,
          59.074200346470306,
          1.9125052069232873,
          0.2875858502437086,
          0.3870668600957358,
          3.2647199272889584,
          0.13627653474864138,
          0.8846549044289321,
          6.013766485401282,
          1.4399308672599327,
          3.9258833958469577,
          0.3983397620896014,
          1.100401894465359,
          0.37665388655504467,
          0.08479651752327201,
          116.82467185560388,
          1.6281002836296725,
          3.4893070354061964,
          1.9890315113208628,
          8.19170812046244,
          3.0660986319973733,
          3.05105668383397,
          261.0350258323148,
          0.5070556593718536,
          0.05105905940082875,
          1.2866661183882802,
          1.3379281250022008,
          0.9767516177264917,
          5.158268089097001,
          3.705355637980072,
          2.514565052646192,
          4.7120927994312884,
          2.1140847222873105,
          0.24403673177077917,
          0.6082237130360045,
          0.6964628175268608,
          0.19379734902128723,
          1.7107621230464745,
          56.4296253022859,
          169.86002538065839,
          1.7731520450840927,
          0.85913359555198,
          5.908050806699115,
          0.07482785631642895,
          1.1323769184025314,
          0.045830069221147046,
          1.1968040331482084,
          3.566379344113704,
          0.15068374425483483,
          0.8899896453413052,
          0.35465621607121633,
          2.988070773114175,
          2.4370845326766153,
          0.10473430876697808,
          0.05178834284188221,
          0.13068999424954958,
          0.017289902395266798,
          0.08373802841750382,
          0.10146878651377632,
          0.9911819502562875,
          0.1357065505844749,
          6.100845572193614,
          2.518757234488948,
          0.1222848782970853,
          0.06958290416714935,
          1.0143042348142821,
          0.7874115209168707,
          0.7436450452422267,
          0.017722254851223588,
          3.0382163590142133,
          2.04484382726396,
          0.8947150691067616,
          0.9308902282374885,
          0.1997283248551017,
          0.06224509740630875,
          1.1393113561388255,
          0.17418686468637157,
          0.9749384755258161,
          1.001187857882979,
          0.11488607743576063,
          2.0569986727766874,
          2.1853744597648688,
          1.3466272113328386,
          0.43097791080795017,
          0.39075635474069553,
          0.2478496013505844,
          1.0503969066883156,
          21.899725215071687,
          0.9259167877099967,
          0.07409589201808632,
          0.6662303908714694,
          2.116057712540142,
          2.982892058695401,
          0.018678656179442116,
          0.05564492336326254,
          0.7116917299543213,
          0.034031283314572176,
          0.80949370395913,
          0.31697014410062524,
          0.48424282472328245,
          1.0108709982319615,
          3.915380342661038,
          0.6051609635105327,
          0.05509349056962093,
          0.023121004798637112,
          0.5241009170932889,
          0.28880925346467373,
          1.8169775306702098,
          1.009537336516867,
          0.19992477435889094,
          0.718051998524948,
          1.6196983731969663,
          0.9822733545358919,
          0.08218009958484118,
          0.14518377577937303,
          0.06132653750544571,
          0.30656261507083105,
          0.4691667186740495,
          1.7727032541962027,
          0.6173794224262155,
          0.7558854941695041,
          0.004556208545386644,
          1.1656113059941746,
          0.6794582740317435,
          3.4523931876863037,
          1.659738419414913,
          0.4102583427225936,
          0.6281668138825364,
          0.44614842406944033,
          42.56439815549288,
          1.6160373249229896,
          1.9893864038590328,
          115.07508359062307,
          5.4337525446661035,
          0.1721834901344072,
          1.4829621434591886,
          0.35930178446331773,
          2.116520062313344,
          0.4216942644556364,
          1.0220732735472597,
          2.5832952493599377,
          1.4809882433532595,
          3.630076923094361,
          0.049350886454438116,
          0.8939093780093351,
          0.4115053195633227,
          0.42836309440207143,
          0.1644284310484891,
          93.0168912316616,
          2.785350944612435,
          2.106025092562045,
          0.12850878183644804,
          7.376650353263173,
          1.6753404238364258,
          0.6658904171982563,
          0.18530137720208995,
          3.766881042667568,
          0.016681883819957218,
          59.80540805624196,
          378.5417430144145,
          2.5408620920272877,
          33.073234170529716,
          1.1149468632834971,
          1.1017492001123705,
          0.19427316924314803,
          0.7169374753782847,
          25.787041929172766,
          3.5409940644001567,
          0.8765844869591555,
          18.350430847043036,
          6.836568500371695,
          1.4914138882711279,
          2.2585803491848133,
          0.2128585034356926,
          1.0351002785535766,
          0.05003268347980553,
          0.961462250583047,
          0.49039993599325954,
          1.0912723539305031,
          0.7919987317406686,
          0.43813225807163575,
          11.137316817277757,
          0.07361711911735642,
          0.2909061119523927,
          1.1740568238727105,
          5.130270117340402,
          5.5501981009672345,
          13.72442076584482,
          1.4885318377250234,
          0.12265671218075783,
          0.4902733316733953,
          0.9399854554613553,
          2.2365063139579764,
          2.2864070848652456,
          0.2665818684400262,
          2.127060032534213,
          0.8369987793771977,
          298.7965463155458,
          1.929007866207286,
          0.15657177749922774,
          1.7793966077467283,
          0.5123893121890628,
          0.25318429804751125,
          2.0458958468775603,
          3.491276834582039,
          61.906148024990294,
          0.25676396980832494,
          0.6783210303057743,
          1.030929152589071,
          0.32879267216340846,
          2.1173462873162348,
          6.635135779502612,
          0.2939378221873528,
          2.7236296506393436,
          0.27007894977343017,
          2.223380914116727,
          1.0367304791813705,
          5.900541571891986,
          9.751466395463181,
          0.09513635092969558,
          0.20071611546093943,
          3.527460683327013,
          1.537536676801524,
          0.04109722516603268,
          4.653800776634386,
          0.11243326594121997,
          2.558763818540041,
          48.03756800434769,
          0.3401410912643791,
          2.7953105409313483,
          38.574209195780305,
          68.5792815310728,
          162.49085401415905,
          1.8549997253998363,
          1.9362478163489674,
          0.20941457776660627,
          4.143487025130611,
          1.2589173052383202,
          3.77401553656659,
          3.9254884819024194,
          0.6624119244347197,
          1.8185047418012474,
          1.3686966950797952,
          221.072117554469,
          0.44241212107609307,
          87.5399104708697,
          1.587495865235867,
          1.821171166872543,
          1.0448835997975425,
          0.010065118312072602,
          0.3568494783688127,
          0.6614695457246093,
          1.3203135640953856,
          145.9001848655649,
          8.983027938411174,
          0.016313673251775,
          0.32210940840769664,
          17.094112958248395,
          71.49079770012737,
          17.394934714164883,
          4.903726647621583,
          4.363597373858236,
          1.555925613754114,
          0.7353600075979605,
          0.4596782636834647,
          0.5160434150966323,
          2.3453111178195014,
          0.07740646690659249,
          0.5808246669763284,
          3.2149149399589048,
          30.107520936100535,
          29.091983421491207,
          2.5155522759165683,
          0.13642634293055755,
          2.700746981131613,
          6.066420745045941,
          1.2336431359200173,
          0.40084303343182315,
          1.3275989420532117,
          2.9355936695771474,
          1.8700998591437292,
          0.027318456956025403,
          1.5942928431029406,
          0.9426170080194786,
          0.06822804952605135,
          1.2427927958073597,
          0.06777645400998163,
          3.078883287127014,
          0.4516217463446645,
          0.5859808440232045,
          0.05469868435129825,
          122.55898386016703,
          9.67448774173197,
          0.238719048798816,
          2.257391220502115,
          4.29339564333066,
          0.774994998400164,
          0.6653984633198488,
          3.929267616115071,
          1.4800650120592136,
          1.2018845823117292,
          1.6915673629440942,
          1.4028206285470648,
          0.4081493616835405,
          0.6887700746652028,
          0.6326155932723256,
          0.6743640815317522,
          0.7836280699196629,
          6.783300591424496,
          1.726333290372498,
          2.3345335788411647,
          2.6471155057959677,
          0.36884693348393965,
          2.866539115973879,
          1.0343393089688029,
          1.536920637316703,
          0.15586096192631593,
          6.973313551167442,
          81.19807528012345,
          0.2361134583997093,
          0.8849365938778146,
          6.554229782145864,
          102.20024605743448,
          2.6476912454695563,
          2.677999208857959,
          1.4133813429329853,
          0.22770202863376313,
          3.631314312549766,
          0.16472344895303148,
          0.21583497779319585,
          1.6795556501376412,
          11.975819662485206,
          5.549317718057532,
          0.8183511285268716,
          0.2343542591312898,
          0.6261207054541857,
          1.7514084085036652,
          0.753986203089923,
          0.25828621770923815,
          2.307815391551496,
          0.08253783143650031,
          2.1509107913909724,
          3.0701387163694505,
          1.26463382422141,
          52.39734931464606,
          0.5031481880667092,
          7.4223723234428585,
          0.3616770174353522,
          1.2511562771232778,
          0.7261448608516305,
          1.9520082115842499,
          0.32538140933012505,
          3.836621069808251,
          0.31604912179134353,
          1.3312065847685377,
          13.323910212007918,
          0.8475927943076245,
          0.970602606004103,
          2.949836797934777,
          37.59779556050681,
          0.5611727631925804,
          20.935483109270226,
          0.2536524362231396,
          0.4961866500552752,
          1.483650532365744,
          2.039906343361928,
          0.798337609844306,
          19.25995004245084,
          0.01849483283360096,
          1.1441822604623961,
          0.7493174908882847,
          2.813954371568637
         ]
        },
        {
         "mode": "lines",
         "name": "Best Value",
         "type": "scatter",
         "x": [
          0,
          1,
          2,
          3,
          4,
          5,
          6,
          7,
          8,
          9,
          10,
          11,
          12,
          13,
          14,
          15,
          16,
          17,
          18,
          19,
          20,
          21,
          22,
          23,
          24,
          25,
          26,
          27,
          28,
          29,
          30,
          31,
          32,
          33,
          34,
          35,
          36,
          37,
          38,
          39,
          40,
          41,
          42,
          43,
          44,
          45,
          46,
          47,
          48,
          49,
          50,
          51,
          52,
          53,
          54,
          55,
          56,
          57,
          58,
          59,
          60,
          61,
          62,
          63,
          64,
          65,
          66,
          67,
          68,
          69,
          70,
          71,
          72,
          73,
          74,
          75,
          76,
          77,
          78,
          79,
          80,
          81,
          82,
          83,
          84,
          85,
          86,
          87,
          88,
          89,
          90,
          91,
          92,
          93,
          94,
          95,
          96,
          97,
          98,
          99,
          100,
          101,
          102,
          103,
          104,
          105,
          106,
          107,
          108,
          109,
          110,
          111,
          112,
          113,
          114,
          115,
          116,
          117,
          118,
          119,
          120,
          121,
          122,
          123,
          124,
          125,
          126,
          127,
          128,
          129,
          130,
          131,
          132,
          133,
          134,
          135,
          136,
          137,
          138,
          139,
          140,
          141,
          142,
          143,
          144,
          145,
          146,
          147,
          148,
          149,
          150,
          151,
          152,
          153,
          154,
          155,
          156,
          157,
          158,
          159,
          160,
          161,
          162,
          163,
          164,
          165,
          166,
          167,
          168,
          169,
          170,
          171,
          172,
          173,
          174,
          175,
          176,
          177,
          178,
          179,
          180,
          181,
          182,
          183,
          184,
          185,
          186,
          187,
          188,
          189,
          190,
          191,
          192,
          193,
          194,
          195,
          196,
          197,
          198,
          199,
          200,
          201,
          202,
          203,
          204,
          205,
          206,
          207,
          208,
          209,
          210,
          211,
          212,
          213,
          214,
          215,
          216,
          217,
          218,
          219,
          220,
          221,
          222,
          223,
          224,
          225,
          226,
          227,
          228,
          229,
          230,
          231,
          232,
          233,
          234,
          235,
          236,
          237,
          238,
          239,
          240,
          241,
          242,
          243,
          244,
          245,
          246,
          247,
          248,
          249,
          250,
          251,
          252,
          253,
          254,
          255,
          256,
          257,
          258,
          259,
          260,
          261,
          262,
          263,
          264,
          265,
          266,
          267,
          268,
          269,
          270,
          271,
          272,
          273,
          274,
          275,
          276,
          277,
          278,
          279,
          280,
          281,
          282,
          283,
          284,
          285,
          286,
          287,
          288,
          289,
          290,
          291,
          292,
          293,
          294,
          295,
          296,
          297,
          298,
          299,
          300,
          301,
          302,
          303,
          304,
          305,
          306,
          307,
          308,
          309,
          310,
          311,
          312,
          313,
          314,
          315,
          316,
          317,
          318,
          319,
          320,
          321,
          322,
          323,
          324,
          325,
          326,
          327,
          328,
          329,
          330,
          331,
          332,
          333,
          334,
          335,
          336,
          337,
          338,
          339,
          340,
          341,
          342,
          343,
          344,
          345,
          346,
          347,
          348,
          349,
          350,
          351,
          352,
          353,
          354,
          355,
          356,
          357,
          358,
          359,
          360,
          361,
          362,
          363,
          364,
          365,
          366,
          367,
          368,
          369,
          370,
          371,
          372,
          373,
          374,
          375,
          376,
          377,
          378,
          379,
          380,
          381,
          382,
          383,
          384,
          385,
          386,
          387,
          388,
          389,
          390,
          391,
          392,
          393,
          394,
          395,
          396,
          397,
          398,
          399,
          400,
          401,
          402,
          403,
          404,
          405,
          406,
          407,
          408,
          409,
          410,
          411,
          412,
          413,
          414,
          415,
          416,
          417,
          418,
          419,
          420,
          421,
          422,
          423,
          424,
          425,
          426,
          427,
          428,
          429,
          430,
          431,
          432,
          433,
          434,
          435,
          436,
          437,
          438,
          439,
          440,
          441,
          442,
          443,
          444,
          445,
          446,
          447,
          448,
          449,
          450,
          451,
          452,
          453,
          454,
          455,
          456,
          457,
          458,
          459,
          460,
          461,
          462,
          463,
          464,
          465,
          466,
          467,
          468,
          469,
          470,
          471,
          472,
          473,
          474,
          475,
          476,
          477,
          478,
          479,
          480,
          481,
          482,
          483,
          484,
          485,
          486,
          487,
          488,
          489,
          490,
          491,
          492,
          493,
          494,
          495,
          496,
          497,
          498,
          499
         ],
         "y": [
          169.68452849813104,
          169.68452849813104,
          28.79093183574342,
          28.79093183574342,
          28.79093183574342,
          28.79093183574342,
          28.79093183574342,
          28.79093183574342,
          28.79093183574342,
          28.79093183574342,
          28.79093183574342,
          0.13945106485291422,
          0.13945106485291422,
          0.13945106485291422,
          0.13945106485291422,
          0.13945106485291422,
          0.13945106485291422,
          0.13945106485291422,
          0.13945106485291422,
          0.13945106485291422,
          0.13945106485291422,
          0.13945106485291422,
          0.13945106485291422,
          0.13945106485291422,
          0.13945106485291422,
          0.13945106485291422,
          0.13945106485291422,
          0.13945106485291422,
          0.13945106485291422,
          0.13945106485291422,
          0.13945106485291422,
          0.13945106485291422,
          0.13945106485291422,
          0.13945106485291422,
          0.13945106485291422,
          0.13945106485291422,
          0.13945106485291422,
          0.13945106485291422,
          0.13945106485291422,
          0.13945106485291422,
          0.13945106485291422,
          0.13945106485291422,
          0.13945106485291422,
          0.13945106485291422,
          0.13945106485291422,
          0.13945106485291422,
          0.13945106485291422,
          0.13945106485291422,
          0.13945106485291422,
          0.13945106485291422,
          0.13945106485291422,
          0.13945106485291422,
          0.13945106485291422,
          0.13945106485291422,
          0.13945106485291422,
          0.13945106485291422,
          0.13945106485291422,
          0.13945106485291422,
          0.13945106485291422,
          0.13945106485291422,
          0.13945106485291422,
          0.11673220944970891,
          0.11673220944970891,
          0.1105309959386112,
          0.1105309959386112,
          0.1105309959386112,
          0.1105309959386112,
          0.1105309959386112,
          0.1105309959386112,
          0.049758510577362525,
          0.049758510577362525,
          0.049758510577362525,
          0.049758510577362525,
          0.049758510577362525,
          0.049758510577362525,
          0.049758510577362525,
          0.049758510577362525,
          0.049758510577362525,
          0.049758510577362525,
          0.049758510577362525,
          0.049758510577362525,
          0.049758510577362525,
          0.049758510577362525,
          0.049758510577362525,
          0.049758510577362525,
          0.049758510577362525,
          0.049758510577362525,
          0.049758510577362525,
          0.049758510577362525,
          0.049758510577362525,
          0.049758510577362525,
          0.049758510577362525,
          0.049758510577362525,
          0.049758510577362525,
          0.049758510577362525,
          0.049758510577362525,
          0.049758510577362525,
          0.049758510577362525,
          0.049758510577362525,
          0.049758510577362525,
          0.049758510577362525,
          0.049758510577362525,
          0.049758510577362525,
          0.049758510577362525,
          0.049758510577362525,
          0.049758510577362525,
          0.049758510577362525,
          0.049758510577362525,
          0.049758510577362525,
          0.03782481730133801,
          0.03782481730133801,
          0.03782481730133801,
          0.03142981240916103,
          0.03142981240916103,
          0.03142981240916103,
          0.03142981240916103,
          0.03142981240916103,
          0.03142981240916103,
          0.03142981240916103,
          0.03142981240916103,
          0.03142981240916103,
          0.03142981240916103,
          0.011279016250261325,
          0.011279016250261325,
          0.011279016250261325,
          0.011279016250261325,
          0.011279016250261325,
          0.011279016250261325,
          0.011279016250261325,
          0.011279016250261325,
          0.011279016250261325,
          0.011279016250261325,
          0.011279016250261325,
          0.011279016250261325,
          0.011279016250261325,
          0.011279016250261325,
          0.011279016250261325,
          0.011279016250261325,
          0.011279016250261325,
          0.011279016250261325,
          0.011279016250261325,
          0.011279016250261325,
          0.011279016250261325,
          0.011279016250261325,
          0.011279016250261325,
          0.011279016250261325,
          0.011279016250261325,
          0.011279016250261325,
          0.011279016250261325,
          0.011279016250261325,
          0.011279016250261325,
          0.011279016250261325,
          0.011279016250261325,
          0.011279016250261325,
          0.011279016250261325,
          0.011279016250261325,
          0.011279016250261325,
          0.011279016250261325,
          0.011279016250261325,
          0.011279016250261325,
          0.011279016250261325,
          0.011279016250261325,
          0.011279016250261325,
          0.011279016250261325,
          0.011279016250261325,
          0.011279016250261325,
          0.011279016250261325,
          0.011279016250261325,
          0.011279016250261325,
          0.011279016250261325,
          0.011279016250261325,
          0.011279016250261325,
          0.011279016250261325,
          0.011279016250261325,
          0.011279016250261325,
          0.011279016250261325,
          0.011279016250261325,
          0.011279016250261325,
          0.011279016250261325,
          0.011279016250261325,
          0.011279016250261325,
          0.011279016250261325,
          0.011279016250261325,
          0.011279016250261325,
          0.011279016250261325,
          0.011279016250261325,
          0.011279016250261325,
          0.011279016250261325,
          0.011279016250261325,
          0.011279016250261325,
          0.011279016250261325,
          0.011279016250261325,
          0.011279016250261325,
          0.011279016250261325,
          0.011279016250261325,
          0.011279016250261325,
          0.011279016250261325,
          0.011279016250261325,
          0.011279016250261325,
          0.011279016250261325,
          0.011279016250261325,
          0.011279016250261325,
          0.011279016250261325,
          0.011279016250261325,
          0.011279016250261325,
          0.011279016250261325,
          0.011279016250261325,
          0.011279016250261325,
          0.011279016250261325,
          0.011279016250261325,
          0.011279016250261325,
          0.011279016250261325,
          0.011279016250261325,
          0.011279016250261325,
          0.011279016250261325,
          0.011279016250261325,
          0.011279016250261325,
          0.011279016250261325,
          0.011279016250261325,
          0.011279016250261325,
          0.011279016250261325,
          0.011279016250261325,
          0.011279016250261325,
          0.011279016250261325,
          0.011279016250261325,
          0.011279016250261325,
          0.011279016250261325,
          0.011279016250261325,
          0.011279016250261325,
          0.011279016250261325,
          0.011279016250261325,
          0.011279016250261325,
          0.011279016250261325,
          0.011279016250261325,
          0.011279016250261325,
          0.011279016250261325,
          0.011279016250261325,
          0.011279016250261325,
          0.011279016250261325,
          0.011279016250261325,
          0.011279016250261325,
          0.011279016250261325,
          0.011279016250261325,
          0.011279016250261325,
          0.011279016250261325,
          0.011279016250261325,
          0.011279016250261325,
          0.011279016250261325,
          0.011279016250261325,
          0.004556208545386644,
          0.004556208545386644,
          0.004556208545386644,
          0.004556208545386644,
          0.004556208545386644,
          0.004556208545386644,
          0.004556208545386644,
          0.004556208545386644,
          0.004556208545386644,
          0.004556208545386644,
          0.004556208545386644,
          0.004556208545386644,
          0.004556208545386644,
          0.004556208545386644,
          0.004556208545386644,
          0.004556208545386644,
          0.004556208545386644,
          0.004556208545386644,
          0.004556208545386644,
          0.004556208545386644,
          0.004556208545386644,
          0.004556208545386644,
          0.004556208545386644,
          0.004556208545386644,
          0.004556208545386644,
          0.004556208545386644,
          0.004556208545386644,
          0.004556208545386644,
          0.004556208545386644,
          0.004556208545386644,
          0.004556208545386644,
          0.004556208545386644,
          0.004556208545386644,
          0.004556208545386644,
          0.004556208545386644,
          0.004556208545386644,
          0.004556208545386644,
          0.004556208545386644,
          0.004556208545386644,
          0.004556208545386644,
          0.004556208545386644,
          0.004556208545386644,
          0.004556208545386644,
          0.004556208545386644,
          0.004556208545386644,
          0.004556208545386644,
          0.004556208545386644,
          0.004556208545386644,
          0.004556208545386644,
          0.004556208545386644,
          0.004556208545386644,
          0.004556208545386644,
          0.004556208545386644,
          0.004556208545386644,
          0.004556208545386644,
          0.004556208545386644,
          0.004556208545386644,
          0.004556208545386644,
          0.004556208545386644,
          0.004556208545386644,
          0.004556208545386644,
          0.004556208545386644,
          0.004556208545386644,
          0.004556208545386644,
          0.004556208545386644,
          0.004556208545386644,
          0.004556208545386644,
          0.004556208545386644,
          0.004556208545386644,
          0.004556208545386644,
          0.004556208545386644,
          0.004556208545386644,
          0.004556208545386644,
          0.004556208545386644,
          0.004556208545386644,
          0.004556208545386644,
          0.004556208545386644,
          0.004556208545386644,
          0.004556208545386644,
          0.004556208545386644,
          0.004556208545386644,
          0.004556208545386644,
          0.004556208545386644,
          0.004556208545386644,
          0.004556208545386644,
          0.004556208545386644,
          0.004556208545386644,
          0.004556208545386644,
          0.004556208545386644,
          0.004556208545386644,
          0.004556208545386644,
          0.004556208545386644,
          0.004556208545386644,
          0.004556208545386644,
          0.004556208545386644,
          0.004556208545386644,
          0.004556208545386644,
          0.004556208545386644,
          0.004556208545386644,
          0.004556208545386644,
          0.004556208545386644,
          0.004556208545386644,
          0.004556208545386644,
          0.004556208545386644,
          0.004556208545386644,
          0.004556208545386644,
          0.004556208545386644,
          0.004556208545386644,
          0.004556208545386644,
          0.004556208545386644,
          0.004556208545386644,
          0.004556208545386644,
          0.004556208545386644,
          0.004556208545386644,
          0.004556208545386644,
          0.004556208545386644,
          0.004556208545386644,
          0.004556208545386644,
          0.004556208545386644,
          0.004556208545386644,
          0.004556208545386644,
          0.004556208545386644,
          0.004556208545386644,
          0.004556208545386644,
          0.004556208545386644,
          0.004556208545386644,
          0.004556208545386644,
          0.004556208545386644,
          0.004556208545386644,
          0.004556208545386644,
          0.004556208545386644,
          0.004556208545386644,
          0.004556208545386644,
          0.004556208545386644,
          0.004556208545386644,
          0.004556208545386644,
          0.004556208545386644,
          0.004556208545386644,
          0.004556208545386644,
          0.004556208545386644,
          0.004556208545386644,
          0.004556208545386644,
          0.004556208545386644,
          0.004556208545386644,
          0.004556208545386644,
          0.004556208545386644,
          0.004556208545386644,
          0.004556208545386644,
          0.004556208545386644,
          0.004556208545386644,
          0.004556208545386644,
          0.004556208545386644,
          0.004556208545386644,
          0.004556208545386644,
          0.004556208545386644,
          0.004556208545386644,
          0.004556208545386644,
          0.004556208545386644,
          0.004556208545386644,
          0.004556208545386644,
          0.004556208545386644,
          0.004556208545386644,
          0.004556208545386644,
          0.004556208545386644,
          0.004556208545386644,
          0.004556208545386644,
          0.004556208545386644,
          0.004556208545386644,
          0.004556208545386644,
          0.004556208545386644,
          0.004556208545386644,
          0.004556208545386644,
          0.004556208545386644,
          0.004556208545386644,
          0.004556208545386644,
          0.004556208545386644,
          0.004556208545386644,
          0.004556208545386644,
          0.004556208545386644,
          0.004556208545386644,
          0.004556208545386644,
          0.004556208545386644,
          0.004556208545386644,
          0.004556208545386644,
          0.004556208545386644,
          0.004556208545386644,
          0.004556208545386644,
          0.004556208545386644,
          0.004556208545386644,
          0.004556208545386644,
          0.004556208545386644,
          0.004556208545386644,
          0.004556208545386644,
          0.004556208545386644,
          0.004556208545386644,
          0.004556208545386644,
          0.004556208545386644,
          0.004556208545386644,
          0.004556208545386644,
          0.004556208545386644,
          0.004556208545386644,
          0.004556208545386644,
          0.004556208545386644,
          0.004556208545386644,
          0.004556208545386644,
          0.004556208545386644,
          0.004556208545386644,
          0.004556208545386644,
          0.004556208545386644,
          0.004556208545386644,
          0.004556208545386644,
          0.004556208545386644,
          0.004556208545386644,
          0.004556208545386644,
          0.004556208545386644,
          0.004556208545386644,
          0.004556208545386644,
          0.004556208545386644,
          0.004556208545386644,
          0.004556208545386644,
          0.004556208545386644,
          0.004556208545386644,
          0.004556208545386644,
          0.004556208545386644,
          0.004556208545386644,
          0.004556208545386644,
          0.004556208545386644,
          0.004556208545386644,
          0.004556208545386644,
          0.004556208545386644,
          0.004556208545386644,
          0.004556208545386644,
          0.004556208545386644,
          0.004556208545386644,
          0.004556208545386644,
          0.004556208545386644,
          0.004556208545386644,
          0.004556208545386644,
          0.004556208545386644,
          0.004556208545386644,
          0.004556208545386644,
          0.004556208545386644,
          0.004556208545386644,
          0.004556208545386644,
          0.004556208545386644,
          0.004556208545386644,
          0.004556208545386644,
          0.004556208545386644,
          0.004556208545386644,
          0.004556208545386644,
          0.004556208545386644
         ]
        },
        {
         "marker": {
          "color": "#cccccc"
         },
         "mode": "markers",
         "name": "Infeasible Trial",
         "showlegend": false,
         "type": "scatter",
         "x": [],
         "y": []
        }
       ],
       "layout": {
        "template": {
         "data": {
          "bar": [
           {
            "error_x": {
             "color": "#2a3f5f"
            },
            "error_y": {
             "color": "#2a3f5f"
            },
            "marker": {
             "line": {
              "color": "#E5ECF6",
              "width": 0.5
             },
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "bar"
           }
          ],
          "barpolar": [
           {
            "marker": {
             "line": {
              "color": "#E5ECF6",
              "width": 0.5
             },
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "barpolar"
           }
          ],
          "carpet": [
           {
            "aaxis": {
             "endlinecolor": "#2a3f5f",
             "gridcolor": "white",
             "linecolor": "white",
             "minorgridcolor": "white",
             "startlinecolor": "#2a3f5f"
            },
            "baxis": {
             "endlinecolor": "#2a3f5f",
             "gridcolor": "white",
             "linecolor": "white",
             "minorgridcolor": "white",
             "startlinecolor": "#2a3f5f"
            },
            "type": "carpet"
           }
          ],
          "choropleth": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "choropleth"
           }
          ],
          "contour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "contour"
           }
          ],
          "contourcarpet": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "contourcarpet"
           }
          ],
          "heatmap": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "heatmap"
           }
          ],
          "histogram": [
           {
            "marker": {
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "histogram"
           }
          ],
          "histogram2d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "histogram2d"
           }
          ],
          "histogram2dcontour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "histogram2dcontour"
           }
          ],
          "mesh3d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "mesh3d"
           }
          ],
          "parcoords": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "parcoords"
           }
          ],
          "pie": [
           {
            "automargin": true,
            "type": "pie"
           }
          ],
          "scatter": [
           {
            "fillpattern": {
             "fillmode": "overlay",
             "size": 10,
             "solidity": 0.2
            },
            "type": "scatter"
           }
          ],
          "scatter3d": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatter3d"
           }
          ],
          "scattercarpet": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattercarpet"
           }
          ],
          "scattergeo": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattergeo"
           }
          ],
          "scattergl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattergl"
           }
          ],
          "scattermap": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattermap"
           }
          ],
          "scattermapbox": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattermapbox"
           }
          ],
          "scatterpolar": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterpolar"
           }
          ],
          "scatterpolargl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterpolargl"
           }
          ],
          "scatterternary": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterternary"
           }
          ],
          "surface": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "surface"
           }
          ],
          "table": [
           {
            "cells": {
             "fill": {
              "color": "#EBF0F8"
             },
             "line": {
              "color": "white"
             }
            },
            "header": {
             "fill": {
              "color": "#C8D4E3"
             },
             "line": {
              "color": "white"
             }
            },
            "type": "table"
           }
          ]
         },
         "layout": {
          "annotationdefaults": {
           "arrowcolor": "#2a3f5f",
           "arrowhead": 0,
           "arrowwidth": 1
          },
          "autotypenumbers": "strict",
          "coloraxis": {
           "colorbar": {
            "outlinewidth": 0,
            "ticks": ""
           }
          },
          "colorscale": {
           "diverging": [
            [
             0,
             "#8e0152"
            ],
            [
             0.1,
             "#c51b7d"
            ],
            [
             0.2,
             "#de77ae"
            ],
            [
             0.3,
             "#f1b6da"
            ],
            [
             0.4,
             "#fde0ef"
            ],
            [
             0.5,
             "#f7f7f7"
            ],
            [
             0.6,
             "#e6f5d0"
            ],
            [
             0.7,
             "#b8e186"
            ],
            [
             0.8,
             "#7fbc41"
            ],
            [
             0.9,
             "#4d9221"
            ],
            [
             1,
             "#276419"
            ]
           ],
           "sequential": [
            [
             0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1,
             "#f0f921"
            ]
           ],
           "sequentialminus": [
            [
             0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1,
             "#f0f921"
            ]
           ]
          },
          "colorway": [
           "#636efa",
           "#EF553B",
           "#00cc96",
           "#ab63fa",
           "#FFA15A",
           "#19d3f3",
           "#FF6692",
           "#B6E880",
           "#FF97FF",
           "#FECB52"
          ],
          "font": {
           "color": "#2a3f5f"
          },
          "geo": {
           "bgcolor": "white",
           "lakecolor": "white",
           "landcolor": "#E5ECF6",
           "showlakes": true,
           "showland": true,
           "subunitcolor": "white"
          },
          "hoverlabel": {
           "align": "left"
          },
          "hovermode": "closest",
          "mapbox": {
           "style": "light"
          },
          "paper_bgcolor": "white",
          "plot_bgcolor": "#E5ECF6",
          "polar": {
           "angularaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "bgcolor": "#E5ECF6",
           "radialaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           }
          },
          "scene": {
           "xaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           },
           "yaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           },
           "zaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           }
          },
          "shapedefaults": {
           "line": {
            "color": "#2a3f5f"
           }
          },
          "ternary": {
           "aaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "baxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "bgcolor": "#E5ECF6",
           "caxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           }
          },
          "title": {
           "x": 0.05
          },
          "xaxis": {
           "automargin": true,
           "gridcolor": "white",
           "linecolor": "white",
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "white",
           "zerolinewidth": 2
          },
          "yaxis": {
           "automargin": true,
           "gridcolor": "white",
           "linecolor": "white",
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "white",
           "zerolinewidth": 2
          }
         }
        },
        "title": {
         "text": "Optimization History Plot"
        },
        "xaxis": {
         "title": {
          "text": "Trial"
         }
        },
        "yaxis": {
         "title": {
          "text": "Objective Value"
         }
        }
       }
      }
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "vis.plot_optimization_history(study).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d66ce991",
   "metadata": {},
   "source": [
    "- optuna를 활용한 XGBoost 하이퍼 파라미터 튜닝"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "5c82af2d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-11 10:26:20,973] A new study created in memory with name: no-name-811deb45-fb77-4ff8-995e-03330007b698\n",
      "C:\\Users\\Playdata\\AppData\\Local\\Temp\\ipykernel_9840\\1653561151.py:4: FutureWarning:\n",
      "\n",
      "suggest_int() got {'step'} as positional arguments but they were expected to be given as keyword arguments.\n",
      "Positional arguments ['self', 'name', 'low', 'high', 'step', 'log'] in suggest_int() have been deprecated since v3.5.0. They will be replaced with the corresponding keyword arguments in v5.0.0, so please use the keyword specification instead. See https://github.com/optuna/optuna/releases/tag/v3.5.0 for details.\n",
      "\n",
      "[I 2025-08-11 10:26:21,159] Trial 0 finished with value: 0.9577464788732395 and parameters: {'n_estimators': 300, 'max_depth': 5, 'learning_rate': 0.1904060540304981, 'colsample_bytree': 0.8447521616138891}. Best is trial 0 with value: 0.9577464788732395.\n",
      "C:\\Users\\Playdata\\AppData\\Local\\Temp\\ipykernel_9840\\1653561151.py:4: FutureWarning:\n",
      "\n",
      "suggest_int() got {'step'} as positional arguments but they were expected to be given as keyword arguments.\n",
      "Positional arguments ['self', 'name', 'low', 'high', 'step', 'log'] in suggest_int() have been deprecated since v3.5.0. They will be replaced with the corresponding keyword arguments in v5.0.0, so please use the keyword specification instead. See https://github.com/optuna/optuna/releases/tag/v3.5.0 for details.\n",
      "\n",
      "[I 2025-08-11 10:26:21,465] Trial 1 finished with value: 0.960093896713615 and parameters: {'n_estimators': 400, 'max_depth': 3, 'learning_rate': 0.06241480435079843, 'colsample_bytree': 0.7246663015957232}. Best is trial 1 with value: 0.960093896713615.\n",
      "C:\\Users\\Playdata\\AppData\\Local\\Temp\\ipykernel_9840\\1653561151.py:4: FutureWarning:\n",
      "\n",
      "suggest_int() got {'step'} as positional arguments but they were expected to be given as keyword arguments.\n",
      "Positional arguments ['self', 'name', 'low', 'high', 'step', 'log'] in suggest_int() have been deprecated since v3.5.0. They will be replaced with the corresponding keyword arguments in v5.0.0, so please use the keyword specification instead. See https://github.com/optuna/optuna/releases/tag/v3.5.0 for details.\n",
      "\n",
      "[I 2025-08-11 10:26:21,713] Trial 2 finished with value: 0.9624413145539906 and parameters: {'n_estimators': 400, 'max_depth': 5, 'learning_rate': 0.17360195006208615, 'colsample_bytree': 0.5907109298176876}. Best is trial 2 with value: 0.9624413145539906.\n",
      "C:\\Users\\Playdata\\AppData\\Local\\Temp\\ipykernel_9840\\1653561151.py:4: FutureWarning:\n",
      "\n",
      "suggest_int() got {'step'} as positional arguments but they were expected to be given as keyword arguments.\n",
      "Positional arguments ['self', 'name', 'low', 'high', 'step', 'log'] in suggest_int() have been deprecated since v3.5.0. They will be replaced with the corresponding keyword arguments in v5.0.0, so please use the keyword specification instead. See https://github.com/optuna/optuna/releases/tag/v3.5.0 for details.\n",
      "\n",
      "[I 2025-08-11 10:26:21,872] Trial 3 finished with value: 0.960093896713615 and parameters: {'n_estimators': 200, 'max_depth': 10, 'learning_rate': 0.19314903246382947, 'colsample_bytree': 0.8002672006767283}. Best is trial 2 with value: 0.9624413145539906.\n",
      "C:\\Users\\Playdata\\AppData\\Local\\Temp\\ipykernel_9840\\1653561151.py:4: FutureWarning:\n",
      "\n",
      "suggest_int() got {'step'} as positional arguments but they were expected to be given as keyword arguments.\n",
      "Positional arguments ['self', 'name', 'low', 'high', 'step', 'log'] in suggest_int() have been deprecated since v3.5.0. They will be replaced with the corresponding keyword arguments in v5.0.0, so please use the keyword specification instead. See https://github.com/optuna/optuna/releases/tag/v3.5.0 for details.\n",
      "\n",
      "[I 2025-08-11 10:26:22,153] Trial 4 finished with value: 0.9694835680751174 and parameters: {'n_estimators': 500, 'max_depth': 8, 'learning_rate': 0.158770660868747, 'colsample_bytree': 0.5219703568844161}. Best is trial 4 with value: 0.9694835680751174.\n",
      "C:\\Users\\Playdata\\AppData\\Local\\Temp\\ipykernel_9840\\1653561151.py:4: FutureWarning:\n",
      "\n",
      "suggest_int() got {'step'} as positional arguments but they were expected to be given as keyword arguments.\n",
      "Positional arguments ['self', 'name', 'low', 'high', 'step', 'log'] in suggest_int() have been deprecated since v3.5.0. They will be replaced with the corresponding keyword arguments in v5.0.0, so please use the keyword specification instead. See https://github.com/optuna/optuna/releases/tag/v3.5.0 for details.\n",
      "\n",
      "[I 2025-08-11 10:26:22,527] Trial 5 finished with value: 0.960093896713615 and parameters: {'n_estimators': 300, 'max_depth': 5, 'learning_rate': 0.019803824086438965, 'colsample_bytree': 0.8736264629454917}. Best is trial 4 with value: 0.9694835680751174.\n",
      "C:\\Users\\Playdata\\AppData\\Local\\Temp\\ipykernel_9840\\1653561151.py:4: FutureWarning:\n",
      "\n",
      "suggest_int() got {'step'} as positional arguments but they were expected to be given as keyword arguments.\n",
      "Positional arguments ['self', 'name', 'low', 'high', 'step', 'log'] in suggest_int() have been deprecated since v3.5.0. They will be replaced with the corresponding keyword arguments in v5.0.0, so please use the keyword specification instead. See https://github.com/optuna/optuna/releases/tag/v3.5.0 for details.\n",
      "\n",
      "[I 2025-08-11 10:26:22,775] Trial 6 finished with value: 0.9647887323943664 and parameters: {'n_estimators': 400, 'max_depth': 10, 'learning_rate': 0.13694889050217618, 'colsample_bytree': 0.5972023939981773}. Best is trial 4 with value: 0.9694835680751174.\n",
      "C:\\Users\\Playdata\\AppData\\Local\\Temp\\ipykernel_9840\\1653561151.py:4: FutureWarning:\n",
      "\n",
      "suggest_int() got {'step'} as positional arguments but they were expected to be given as keyword arguments.\n",
      "Positional arguments ['self', 'name', 'low', 'high', 'step', 'log'] in suggest_int() have been deprecated since v3.5.0. They will be replaced with the corresponding keyword arguments in v5.0.0, so please use the keyword specification instead. See https://github.com/optuna/optuna/releases/tag/v3.5.0 for details.\n",
      "\n",
      "[I 2025-08-11 10:26:22,982] Trial 7 finished with value: 0.9671361502347419 and parameters: {'n_estimators': 300, 'max_depth': 9, 'learning_rate': 0.15610501653836, 'colsample_bytree': 0.5043153600063843}. Best is trial 4 with value: 0.9694835680751174.\n",
      "C:\\Users\\Playdata\\AppData\\Local\\Temp\\ipykernel_9840\\1653561151.py:4: FutureWarning:\n",
      "\n",
      "suggest_int() got {'step'} as positional arguments but they were expected to be given as keyword arguments.\n",
      "Positional arguments ['self', 'name', 'low', 'high', 'step', 'log'] in suggest_int() have been deprecated since v3.5.0. They will be replaced with the corresponding keyword arguments in v5.0.0, so please use the keyword specification instead. See https://github.com/optuna/optuna/releases/tag/v3.5.0 for details.\n",
      "\n",
      "[I 2025-08-11 10:26:23,202] Trial 8 finished with value: 0.960093896713615 and parameters: {'n_estimators': 300, 'max_depth': 8, 'learning_rate': 0.11250214851070842, 'colsample_bytree': 0.9049157231536012}. Best is trial 4 with value: 0.9694835680751174.\n",
      "C:\\Users\\Playdata\\AppData\\Local\\Temp\\ipykernel_9840\\1653561151.py:4: FutureWarning:\n",
      "\n",
      "suggest_int() got {'step'} as positional arguments but they were expected to be given as keyword arguments.\n",
      "Positional arguments ['self', 'name', 'low', 'high', 'step', 'log'] in suggest_int() have been deprecated since v3.5.0. They will be replaced with the corresponding keyword arguments in v5.0.0, so please use the keyword specification instead. See https://github.com/optuna/optuna/releases/tag/v3.5.0 for details.\n",
      "\n",
      "[I 2025-08-11 10:26:23,358] Trial 9 finished with value: 0.948356807511737 and parameters: {'n_estimators': 100, 'max_depth': 4, 'learning_rate': 0.012271711752434638, 'colsample_bytree': 0.7165851555798238}. Best is trial 4 with value: 0.9694835680751174.\n",
      "C:\\Users\\Playdata\\AppData\\Local\\Temp\\ipykernel_9840\\1653561151.py:4: FutureWarning:\n",
      "\n",
      "suggest_int() got {'step'} as positional arguments but they were expected to be given as keyword arguments.\n",
      "Positional arguments ['self', 'name', 'low', 'high', 'step', 'log'] in suggest_int() have been deprecated since v3.5.0. They will be replaced with the corresponding keyword arguments in v5.0.0, so please use the keyword specification instead. See https://github.com/optuna/optuna/releases/tag/v3.5.0 for details.\n",
      "\n",
      "[I 2025-08-11 10:26:23,709] Trial 10 finished with value: 0.9647887323943661 and parameters: {'n_estimators': 500, 'max_depth': 7, 'learning_rate': 0.08829901093555934, 'colsample_bytree': 0.6307283393277228}. Best is trial 4 with value: 0.9694835680751174.\n",
      "C:\\Users\\Playdata\\AppData\\Local\\Temp\\ipykernel_9840\\1653561151.py:4: FutureWarning:\n",
      "\n",
      "suggest_int() got {'step'} as positional arguments but they were expected to be given as keyword arguments.\n",
      "Positional arguments ['self', 'name', 'low', 'high', 'step', 'log'] in suggest_int() have been deprecated since v3.5.0. They will be replaced with the corresponding keyword arguments in v5.0.0, so please use the keyword specification instead. See https://github.com/optuna/optuna/releases/tag/v3.5.0 for details.\n",
      "\n",
      "[I 2025-08-11 10:26:23,996] Trial 11 finished with value: 0.971830985915493 and parameters: {'n_estimators': 500, 'max_depth': 8, 'learning_rate': 0.14602160998782585, 'colsample_bytree': 0.5009353245744279}. Best is trial 11 with value: 0.971830985915493.\n",
      "C:\\Users\\Playdata\\AppData\\Local\\Temp\\ipykernel_9840\\1653561151.py:4: FutureWarning:\n",
      "\n",
      "suggest_int() got {'step'} as positional arguments but they were expected to be given as keyword arguments.\n",
      "Positional arguments ['self', 'name', 'low', 'high', 'step', 'log'] in suggest_int() have been deprecated since v3.5.0. They will be replaced with the corresponding keyword arguments in v5.0.0, so please use the keyword specification instead. See https://github.com/optuna/optuna/releases/tag/v3.5.0 for details.\n",
      "\n",
      "[I 2025-08-11 10:26:24,308] Trial 12 finished with value: 0.9694835680751174 and parameters: {'n_estimators': 500, 'max_depth': 7, 'learning_rate': 0.14270499372944556, 'colsample_bytree': 0.5145267995640875}. Best is trial 11 with value: 0.971830985915493.\n",
      "C:\\Users\\Playdata\\AppData\\Local\\Temp\\ipykernel_9840\\1653561151.py:4: FutureWarning:\n",
      "\n",
      "suggest_int() got {'step'} as positional arguments but they were expected to be given as keyword arguments.\n",
      "Positional arguments ['self', 'name', 'low', 'high', 'step', 'log'] in suggest_int() have been deprecated since v3.5.0. They will be replaced with the corresponding keyword arguments in v5.0.0, so please use the keyword specification instead. See https://github.com/optuna/optuna/releases/tag/v3.5.0 for details.\n",
      "\n",
      "[I 2025-08-11 10:26:24,624] Trial 13 finished with value: 0.9647887323943664 and parameters: {'n_estimators': 500, 'max_depth': 8, 'learning_rate': 0.11162915393538188, 'colsample_bytree': 0.9629285980802114}. Best is trial 11 with value: 0.971830985915493.\n",
      "C:\\Users\\Playdata\\AppData\\Local\\Temp\\ipykernel_9840\\1653561151.py:4: FutureWarning:\n",
      "\n",
      "suggest_int() got {'step'} as positional arguments but they were expected to be given as keyword arguments.\n",
      "Positional arguments ['self', 'name', 'low', 'high', 'step', 'log'] in suggest_int() have been deprecated since v3.5.0. They will be replaced with the corresponding keyword arguments in v5.0.0, so please use the keyword specification instead. See https://github.com/optuna/optuna/releases/tag/v3.5.0 for details.\n",
      "\n",
      "[I 2025-08-11 10:26:24,923] Trial 14 finished with value: 0.9647887323943661 and parameters: {'n_estimators': 500, 'max_depth': 8, 'learning_rate': 0.1611684536950992, 'colsample_bytree': 0.662104619253569}. Best is trial 11 with value: 0.971830985915493.\n",
      "C:\\Users\\Playdata\\AppData\\Local\\Temp\\ipykernel_9840\\1653561151.py:4: FutureWarning:\n",
      "\n",
      "suggest_int() got {'step'} as positional arguments but they were expected to be given as keyword arguments.\n",
      "Positional arguments ['self', 'name', 'low', 'high', 'step', 'log'] in suggest_int() have been deprecated since v3.5.0. They will be replaced with the corresponding keyword arguments in v5.0.0, so please use the keyword specification instead. See https://github.com/optuna/optuna/releases/tag/v3.5.0 for details.\n",
      "\n",
      "[I 2025-08-11 10:26:25,203] Trial 15 finished with value: 0.9694835680751174 and parameters: {'n_estimators': 400, 'max_depth': 6, 'learning_rate': 0.130450825536306, 'colsample_bytree': 0.5532925348997528}. Best is trial 11 with value: 0.971830985915493.\n",
      "C:\\Users\\Playdata\\AppData\\Local\\Temp\\ipykernel_9840\\1653561151.py:4: FutureWarning:\n",
      "\n",
      "suggest_int() got {'step'} as positional arguments but they were expected to be given as keyword arguments.\n",
      "Positional arguments ['self', 'name', 'low', 'high', 'step', 'log'] in suggest_int() have been deprecated since v3.5.0. They will be replaced with the corresponding keyword arguments in v5.0.0, so please use the keyword specification instead. See https://github.com/optuna/optuna/releases/tag/v3.5.0 for details.\n",
      "\n",
      "[I 2025-08-11 10:26:25,548] Trial 16 finished with value: 0.9624413145539906 and parameters: {'n_estimators': 500, 'max_depth': 8, 'learning_rate': 0.08890990274162612, 'colsample_bytree': 0.682279926824649}. Best is trial 11 with value: 0.971830985915493.\n",
      "C:\\Users\\Playdata\\AppData\\Local\\Temp\\ipykernel_9840\\1653561151.py:4: FutureWarning:\n",
      "\n",
      "suggest_int() got {'step'} as positional arguments but they were expected to be given as keyword arguments.\n",
      "Positional arguments ['self', 'name', 'low', 'high', 'step', 'log'] in suggest_int() have been deprecated since v3.5.0. They will be replaced with the corresponding keyword arguments in v5.0.0, so please use the keyword specification instead. See https://github.com/optuna/optuna/releases/tag/v3.5.0 for details.\n",
      "\n",
      "[I 2025-08-11 10:26:25,756] Trial 17 finished with value: 0.971830985915493 and parameters: {'n_estimators': 200, 'max_depth': 9, 'learning_rate': 0.17060164728820637, 'colsample_bytree': 0.554380626368289}. Best is trial 11 with value: 0.971830985915493.\n",
      "C:\\Users\\Playdata\\AppData\\Local\\Temp\\ipykernel_9840\\1653561151.py:4: FutureWarning:\n",
      "\n",
      "suggest_int() got {'step'} as positional arguments but they were expected to be given as keyword arguments.\n",
      "Positional arguments ['self', 'name', 'low', 'high', 'step', 'log'] in suggest_int() have been deprecated since v3.5.0. They will be replaced with the corresponding keyword arguments in v5.0.0, so please use the keyword specification instead. See https://github.com/optuna/optuna/releases/tag/v3.5.0 for details.\n",
      "\n",
      "[I 2025-08-11 10:26:25,873] Trial 18 finished with value: 0.9624413145539906 and parameters: {'n_estimators': 100, 'max_depth': 9, 'learning_rate': 0.17312300316951823, 'colsample_bytree': 0.5797096073570854}. Best is trial 11 with value: 0.971830985915493.\n",
      "C:\\Users\\Playdata\\AppData\\Local\\Temp\\ipykernel_9840\\1653561151.py:4: FutureWarning:\n",
      "\n",
      "suggest_int() got {'step'} as positional arguments but they were expected to be given as keyword arguments.\n",
      "Positional arguments ['self', 'name', 'low', 'high', 'step', 'log'] in suggest_int() have been deprecated since v3.5.0. They will be replaced with the corresponding keyword arguments in v5.0.0, so please use the keyword specification instead. See https://github.com/optuna/optuna/releases/tag/v3.5.0 for details.\n",
      "\n",
      "[I 2025-08-11 10:26:26,050] Trial 19 finished with value: 0.9624413145539906 and parameters: {'n_estimators': 200, 'max_depth': 9, 'learning_rate': 0.19633587891321364, 'colsample_bytree': 0.617684126276852}. Best is trial 11 with value: 0.971830985915493.\n",
      "C:\\Users\\Playdata\\AppData\\Local\\Temp\\ipykernel_9840\\1653561151.py:4: FutureWarning:\n",
      "\n",
      "suggest_int() got {'step'} as positional arguments but they were expected to be given as keyword arguments.\n",
      "Positional arguments ['self', 'name', 'low', 'high', 'step', 'log'] in suggest_int() have been deprecated since v3.5.0. They will be replaced with the corresponding keyword arguments in v5.0.0, so please use the keyword specification instead. See https://github.com/optuna/optuna/releases/tag/v3.5.0 for details.\n",
      "\n",
      "[I 2025-08-11 10:26:26,296] Trial 20 finished with value: 0.9647887323943664 and parameters: {'n_estimators': 200, 'max_depth': 10, 'learning_rate': 0.05009324933862695, 'colsample_bytree': 0.7800131582469896}. Best is trial 11 with value: 0.971830985915493.\n",
      "C:\\Users\\Playdata\\AppData\\Local\\Temp\\ipykernel_9840\\1653561151.py:4: FutureWarning:\n",
      "\n",
      "suggest_int() got {'step'} as positional arguments but they were expected to be given as keyword arguments.\n",
      "Positional arguments ['self', 'name', 'low', 'high', 'step', 'log'] in suggest_int() have been deprecated since v3.5.0. They will be replaced with the corresponding keyword arguments in v5.0.0, so please use the keyword specification instead. See https://github.com/optuna/optuna/releases/tag/v3.5.0 for details.\n",
      "\n",
      "[I 2025-08-11 10:26:26,469] Trial 21 finished with value: 0.9647887323943661 and parameters: {'n_estimators': 200, 'max_depth': 9, 'learning_rate': 0.15568686320771374, 'colsample_bytree': 0.5412276007761276}. Best is trial 11 with value: 0.971830985915493.\n",
      "C:\\Users\\Playdata\\AppData\\Local\\Temp\\ipykernel_9840\\1653561151.py:4: FutureWarning:\n",
      "\n",
      "suggest_int() got {'step'} as positional arguments but they were expected to be given as keyword arguments.\n",
      "Positional arguments ['self', 'name', 'low', 'high', 'step', 'log'] in suggest_int() have been deprecated since v3.5.0. They will be replaced with the corresponding keyword arguments in v5.0.0, so please use the keyword specification instead. See https://github.com/optuna/optuna/releases/tag/v3.5.0 for details.\n",
      "\n",
      "[I 2025-08-11 10:26:26,748] Trial 22 finished with value: 0.9671361502347419 and parameters: {'n_estimators': 400, 'max_depth': 7, 'learning_rate': 0.12677102337903307, 'colsample_bytree': 0.5050629221707371}. Best is trial 11 with value: 0.971830985915493.\n",
      "C:\\Users\\Playdata\\AppData\\Local\\Temp\\ipykernel_9840\\1653561151.py:4: FutureWarning:\n",
      "\n",
      "suggest_int() got {'step'} as positional arguments but they were expected to be given as keyword arguments.\n",
      "Positional arguments ['self', 'name', 'low', 'high', 'step', 'log'] in suggest_int() have been deprecated since v3.5.0. They will be replaced with the corresponding keyword arguments in v5.0.0, so please use the keyword specification instead. See https://github.com/optuna/optuna/releases/tag/v3.5.0 for details.\n",
      "\n",
      "[I 2025-08-11 10:26:26,865] Trial 23 finished with value: 0.9647887323943661 and parameters: {'n_estimators': 100, 'max_depth': 6, 'learning_rate': 0.17492869428376276, 'colsample_bytree': 0.5497960731412956}. Best is trial 11 with value: 0.971830985915493.\n",
      "C:\\Users\\Playdata\\AppData\\Local\\Temp\\ipykernel_9840\\1653561151.py:4: FutureWarning:\n",
      "\n",
      "suggest_int() got {'step'} as positional arguments but they were expected to be given as keyword arguments.\n",
      "Positional arguments ['self', 'name', 'low', 'high', 'step', 'log'] in suggest_int() have been deprecated since v3.5.0. They will be replaced with the corresponding keyword arguments in v5.0.0, so please use the keyword specification instead. See https://github.com/optuna/optuna/releases/tag/v3.5.0 for details.\n",
      "\n",
      "[I 2025-08-11 10:26:27,169] Trial 24 finished with value: 0.9694835680751174 and parameters: {'n_estimators': 500, 'max_depth': 8, 'learning_rate': 0.14620714427023696, 'colsample_bytree': 0.5569551937531567}. Best is trial 11 with value: 0.971830985915493.\n",
      "C:\\Users\\Playdata\\AppData\\Local\\Temp\\ipykernel_9840\\1653561151.py:4: FutureWarning:\n",
      "\n",
      "suggest_int() got {'step'} as positional arguments but they were expected to be given as keyword arguments.\n",
      "Positional arguments ['self', 'name', 'low', 'high', 'step', 'log'] in suggest_int() have been deprecated since v3.5.0. They will be replaced with the corresponding keyword arguments in v5.0.0, so please use the keyword specification instead. See https://github.com/optuna/optuna/releases/tag/v3.5.0 for details.\n",
      "\n",
      "[I 2025-08-11 10:26:27,352] Trial 25 finished with value: 0.9624413145539906 and parameters: {'n_estimators': 200, 'max_depth': 9, 'learning_rate': 0.1701597026832398, 'colsample_bytree': 0.6358459402380968}. Best is trial 11 with value: 0.971830985915493.\n",
      "C:\\Users\\Playdata\\AppData\\Local\\Temp\\ipykernel_9840\\1653561151.py:4: FutureWarning:\n",
      "\n",
      "suggest_int() got {'step'} as positional arguments but they were expected to be given as keyword arguments.\n",
      "Positional arguments ['self', 'name', 'low', 'high', 'step', 'log'] in suggest_int() have been deprecated since v3.5.0. They will be replaced with the corresponding keyword arguments in v5.0.0, so please use the keyword specification instead. See https://github.com/optuna/optuna/releases/tag/v3.5.0 for details.\n",
      "\n",
      "[I 2025-08-11 10:26:27,641] Trial 26 finished with value: 0.9647887323943661 and parameters: {'n_estimators': 400, 'max_depth': 7, 'learning_rate': 0.12174875413266392, 'colsample_bytree': 0.6668259459282768}. Best is trial 11 with value: 0.971830985915493.\n",
      "C:\\Users\\Playdata\\AppData\\Local\\Temp\\ipykernel_9840\\1653561151.py:4: FutureWarning:\n",
      "\n",
      "suggest_int() got {'step'} as positional arguments but they were expected to be given as keyword arguments.\n",
      "Positional arguments ['self', 'name', 'low', 'high', 'step', 'log'] in suggest_int() have been deprecated since v3.5.0. They will be replaced with the corresponding keyword arguments in v5.0.0, so please use the keyword specification instead. See https://github.com/optuna/optuna/releases/tag/v3.5.0 for details.\n",
      "\n",
      "[I 2025-08-11 10:26:27,902] Trial 27 finished with value: 0.960093896713615 and parameters: {'n_estimators': 300, 'max_depth': 8, 'learning_rate': 0.09752548804297656, 'colsample_bytree': 0.5009665994741966}. Best is trial 11 with value: 0.971830985915493.\n",
      "C:\\Users\\Playdata\\AppData\\Local\\Temp\\ipykernel_9840\\1653561151.py:4: FutureWarning:\n",
      "\n",
      "suggest_int() got {'step'} as positional arguments but they were expected to be given as keyword arguments.\n",
      "Positional arguments ['self', 'name', 'low', 'high', 'step', 'log'] in suggest_int() have been deprecated since v3.5.0. They will be replaced with the corresponding keyword arguments in v5.0.0, so please use the keyword specification instead. See https://github.com/optuna/optuna/releases/tag/v3.5.0 for details.\n",
      "\n",
      "[I 2025-08-11 10:26:28,194] Trial 28 finished with value: 0.960093896713615 and parameters: {'n_estimators': 500, 'max_depth': 10, 'learning_rate': 0.18553433862023858, 'colsample_bytree': 0.5759856732518494}. Best is trial 11 with value: 0.971830985915493.\n",
      "C:\\Users\\Playdata\\AppData\\Local\\Temp\\ipykernel_9840\\1653561151.py:4: FutureWarning:\n",
      "\n",
      "suggest_int() got {'step'} as positional arguments but they were expected to be given as keyword arguments.\n",
      "Positional arguments ['self', 'name', 'low', 'high', 'step', 'log'] in suggest_int() have been deprecated since v3.5.0. They will be replaced with the corresponding keyword arguments in v5.0.0, so please use the keyword specification instead. See https://github.com/optuna/optuna/releases/tag/v3.5.0 for details.\n",
      "\n",
      "[I 2025-08-11 10:26:28,430] Trial 29 finished with value: 0.9694835680751174 and parameters: {'n_estimators': 300, 'max_depth': 6, 'learning_rate': 0.14615072211081104, 'colsample_bytree': 0.5343844299057641}. Best is trial 11 with value: 0.971830985915493.\n",
      "C:\\Users\\Playdata\\AppData\\Local\\Temp\\ipykernel_9840\\1653561151.py:4: FutureWarning:\n",
      "\n",
      "suggest_int() got {'step'} as positional arguments but they were expected to be given as keyword arguments.\n",
      "Positional arguments ['self', 'name', 'low', 'high', 'step', 'log'] in suggest_int() have been deprecated since v3.5.0. They will be replaced with the corresponding keyword arguments in v5.0.0, so please use the keyword specification instead. See https://github.com/optuna/optuna/releases/tag/v3.5.0 for details.\n",
      "\n",
      "[I 2025-08-11 10:26:28,701] Trial 30 finished with value: 0.9577464788732395 and parameters: {'n_estimators': 400, 'max_depth': 9, 'learning_rate': 0.18331711235257003, 'colsample_bytree': 0.9976716673542523}. Best is trial 11 with value: 0.971830985915493.\n",
      "C:\\Users\\Playdata\\AppData\\Local\\Temp\\ipykernel_9840\\1653561151.py:4: FutureWarning:\n",
      "\n",
      "suggest_int() got {'step'} as positional arguments but they were expected to be given as keyword arguments.\n",
      "Positional arguments ['self', 'name', 'low', 'high', 'step', 'log'] in suggest_int() have been deprecated since v3.5.0. They will be replaced with the corresponding keyword arguments in v5.0.0, so please use the keyword specification instead. See https://github.com/optuna/optuna/releases/tag/v3.5.0 for details.\n",
      "\n",
      "[I 2025-08-11 10:26:29,057] Trial 31 finished with value: 0.9741784037558686 and parameters: {'n_estimators': 500, 'max_depth': 7, 'learning_rate': 0.1438440611670294, 'colsample_bytree': 0.5257773175292658}. Best is trial 31 with value: 0.9741784037558686.\n",
      "C:\\Users\\Playdata\\AppData\\Local\\Temp\\ipykernel_9840\\1653561151.py:4: FutureWarning:\n",
      "\n",
      "suggest_int() got {'step'} as positional arguments but they were expected to be given as keyword arguments.\n",
      "Positional arguments ['self', 'name', 'low', 'high', 'step', 'log'] in suggest_int() have been deprecated since v3.5.0. They will be replaced with the corresponding keyword arguments in v5.0.0, so please use the keyword specification instead. See https://github.com/optuna/optuna/releases/tag/v3.5.0 for details.\n",
      "\n",
      "[I 2025-08-11 10:26:29,349] Trial 32 finished with value: 0.9694835680751174 and parameters: {'n_estimators': 500, 'max_depth': 7, 'learning_rate': 0.1614320952464206, 'colsample_bytree': 0.5329150332175477}. Best is trial 31 with value: 0.9741784037558686.\n",
      "C:\\Users\\Playdata\\AppData\\Local\\Temp\\ipykernel_9840\\1653561151.py:4: FutureWarning:\n",
      "\n",
      "suggest_int() got {'step'} as positional arguments but they were expected to be given as keyword arguments.\n",
      "Positional arguments ['self', 'name', 'low', 'high', 'step', 'log'] in suggest_int() have been deprecated since v3.5.0. They will be replaced with the corresponding keyword arguments in v5.0.0, so please use the keyword specification instead. See https://github.com/optuna/optuna/releases/tag/v3.5.0 for details.\n",
      "\n",
      "[I 2025-08-11 10:26:29,634] Trial 33 finished with value: 0.9671361502347419 and parameters: {'n_estimators': 500, 'max_depth': 8, 'learning_rate': 0.1503254226598687, 'colsample_bytree': 0.5948784982194266}. Best is trial 31 with value: 0.9741784037558686.\n",
      "C:\\Users\\Playdata\\AppData\\Local\\Temp\\ipykernel_9840\\1653561151.py:4: FutureWarning:\n",
      "\n",
      "suggest_int() got {'step'} as positional arguments but they were expected to be given as keyword arguments.\n",
      "Positional arguments ['self', 'name', 'low', 'high', 'step', 'log'] in suggest_int() have been deprecated since v3.5.0. They will be replaced with the corresponding keyword arguments in v5.0.0, so please use the keyword specification instead. See https://github.com/optuna/optuna/releases/tag/v3.5.0 for details.\n",
      "\n",
      "[I 2025-08-11 10:26:29,877] Trial 34 finished with value: 0.9671361502347419 and parameters: {'n_estimators': 400, 'max_depth': 5, 'learning_rate': 0.16490235427907304, 'colsample_bytree': 0.5683881121502575}. Best is trial 31 with value: 0.9741784037558686.\n",
      "C:\\Users\\Playdata\\AppData\\Local\\Temp\\ipykernel_9840\\1653561151.py:4: FutureWarning:\n",
      "\n",
      "suggest_int() got {'step'} as positional arguments but they were expected to be given as keyword arguments.\n",
      "Positional arguments ['self', 'name', 'low', 'high', 'step', 'log'] in suggest_int() have been deprecated since v3.5.0. They will be replaced with the corresponding keyword arguments in v5.0.0, so please use the keyword specification instead. See https://github.com/optuna/optuna/releases/tag/v3.5.0 for details.\n",
      "\n",
      "[I 2025-08-11 10:26:30,190] Trial 35 finished with value: 0.960093896713615 and parameters: {'n_estimators': 500, 'max_depth': 3, 'learning_rate': 0.13568067602014458, 'colsample_bytree': 0.7103467368843412}. Best is trial 31 with value: 0.9741784037558686.\n",
      "C:\\Users\\Playdata\\AppData\\Local\\Temp\\ipykernel_9840\\1653561151.py:4: FutureWarning:\n",
      "\n",
      "suggest_int() got {'step'} as positional arguments but they were expected to be given as keyword arguments.\n",
      "Positional arguments ['self', 'name', 'low', 'high', 'step', 'log'] in suggest_int() have been deprecated since v3.5.0. They will be replaced with the corresponding keyword arguments in v5.0.0, so please use the keyword specification instead. See https://github.com/optuna/optuna/releases/tag/v3.5.0 for details.\n",
      "\n",
      "[I 2025-08-11 10:26:30,430] Trial 36 finished with value: 0.9671361502347419 and parameters: {'n_estimators': 400, 'max_depth': 7, 'learning_rate': 0.18426231129662657, 'colsample_bytree': 0.613002659813015}. Best is trial 31 with value: 0.9741784037558686.\n",
      "C:\\Users\\Playdata\\AppData\\Local\\Temp\\ipykernel_9840\\1653561151.py:4: FutureWarning:\n",
      "\n",
      "suggest_int() got {'step'} as positional arguments but they were expected to be given as keyword arguments.\n",
      "Positional arguments ['self', 'name', 'low', 'high', 'step', 'log'] in suggest_int() have been deprecated since v3.5.0. They will be replaced with the corresponding keyword arguments in v5.0.0, so please use the keyword specification instead. See https://github.com/optuna/optuna/releases/tag/v3.5.0 for details.\n",
      "\n",
      "[I 2025-08-11 10:26:30,752] Trial 37 finished with value: 0.9553990610328639 and parameters: {'n_estimators': 500, 'max_depth': 6, 'learning_rate': 0.11953309110589383, 'colsample_bytree': 0.766086162969765}. Best is trial 31 with value: 0.9741784037558686.\n",
      "C:\\Users\\Playdata\\AppData\\Local\\Temp\\ipykernel_9840\\1653561151.py:4: FutureWarning:\n",
      "\n",
      "suggest_int() got {'step'} as positional arguments but they were expected to be given as keyword arguments.\n",
      "Positional arguments ['self', 'name', 'low', 'high', 'step', 'log'] in suggest_int() have been deprecated since v3.5.0. They will be replaced with the corresponding keyword arguments in v5.0.0, so please use the keyword specification instead. See https://github.com/optuna/optuna/releases/tag/v3.5.0 for details.\n",
      "\n",
      "[I 2025-08-11 10:26:30,965] Trial 38 finished with value: 0.9624413145539906 and parameters: {'n_estimators': 300, 'max_depth': 9, 'learning_rate': 0.19959617277914626, 'colsample_bytree': 0.8258463684090849}. Best is trial 31 with value: 0.9741784037558686.\n",
      "C:\\Users\\Playdata\\AppData\\Local\\Temp\\ipykernel_9840\\1653561151.py:4: FutureWarning:\n",
      "\n",
      "suggest_int() got {'step'} as positional arguments but they were expected to be given as keyword arguments.\n",
      "Positional arguments ['self', 'name', 'low', 'high', 'step', 'log'] in suggest_int() have been deprecated since v3.5.0. They will be replaced with the corresponding keyword arguments in v5.0.0, so please use the keyword specification instead. See https://github.com/optuna/optuna/releases/tag/v3.5.0 for details.\n",
      "\n",
      "[I 2025-08-11 10:26:31,216] Trial 39 finished with value: 0.971830985915493 and parameters: {'n_estimators': 400, 'max_depth': 10, 'learning_rate': 0.17836168837838914, 'colsample_bytree': 0.5241373609448785}. Best is trial 31 with value: 0.9741784037558686.\n",
      "C:\\Users\\Playdata\\AppData\\Local\\Temp\\ipykernel_9840\\1653561151.py:4: FutureWarning:\n",
      "\n",
      "suggest_int() got {'step'} as positional arguments but they were expected to be given as keyword arguments.\n",
      "Positional arguments ['self', 'name', 'low', 'high', 'step', 'log'] in suggest_int() have been deprecated since v3.5.0. They will be replaced with the corresponding keyword arguments in v5.0.0, so please use the keyword specification instead. See https://github.com/optuna/optuna/releases/tag/v3.5.0 for details.\n",
      "\n",
      "[I 2025-08-11 10:26:31,467] Trial 40 finished with value: 0.9671361502347419 and parameters: {'n_estimators': 400, 'max_depth': 10, 'learning_rate': 0.17660418154015867, 'colsample_bytree': 0.5271074125865846}. Best is trial 31 with value: 0.9741784037558686.\n",
      "C:\\Users\\Playdata\\AppData\\Local\\Temp\\ipykernel_9840\\1653561151.py:4: FutureWarning:\n",
      "\n",
      "suggest_int() got {'step'} as positional arguments but they were expected to be given as keyword arguments.\n",
      "Positional arguments ['self', 'name', 'low', 'high', 'step', 'log'] in suggest_int() have been deprecated since v3.5.0. They will be replaced with the corresponding keyword arguments in v5.0.0, so please use the keyword specification instead. See https://github.com/optuna/optuna/releases/tag/v3.5.0 for details.\n",
      "\n",
      "[I 2025-08-11 10:26:31,769] Trial 41 finished with value: 0.9671361502347419 and parameters: {'n_estimators': 500, 'max_depth': 10, 'learning_rate': 0.16701398284062527, 'colsample_bytree': 0.5244688793213064}. Best is trial 31 with value: 0.9741784037558686.\n",
      "C:\\Users\\Playdata\\AppData\\Local\\Temp\\ipykernel_9840\\1653561151.py:4: FutureWarning:\n",
      "\n",
      "suggest_int() got {'step'} as positional arguments but they were expected to be given as keyword arguments.\n",
      "Positional arguments ['self', 'name', 'low', 'high', 'step', 'log'] in suggest_int() have been deprecated since v3.5.0. They will be replaced with the corresponding keyword arguments in v5.0.0, so please use the keyword specification instead. See https://github.com/optuna/optuna/releases/tag/v3.5.0 for details.\n",
      "\n",
      "[I 2025-08-11 10:26:32,023] Trial 42 finished with value: 0.9694835680751174 and parameters: {'n_estimators': 400, 'max_depth': 8, 'learning_rate': 0.1515832389081224, 'colsample_bytree': 0.5012792060524038}. Best is trial 31 with value: 0.9741784037558686.\n",
      "C:\\Users\\Playdata\\AppData\\Local\\Temp\\ipykernel_9840\\1653561151.py:4: FutureWarning:\n",
      "\n",
      "suggest_int() got {'step'} as positional arguments but they were expected to be given as keyword arguments.\n",
      "Positional arguments ['self', 'name', 'low', 'high', 'step', 'log'] in suggest_int() have been deprecated since v3.5.0. They will be replaced with the corresponding keyword arguments in v5.0.0, so please use the keyword specification instead. See https://github.com/optuna/optuna/releases/tag/v3.5.0 for details.\n",
      "\n",
      "[I 2025-08-11 10:26:32,348] Trial 43 finished with value: 0.9647887323943664 and parameters: {'n_estimators': 500, 'max_depth': 9, 'learning_rate': 0.13711080979146037, 'colsample_bytree': 0.5926691496279836}. Best is trial 31 with value: 0.9741784037558686.\n",
      "C:\\Users\\Playdata\\AppData\\Local\\Temp\\ipykernel_9840\\1653561151.py:4: FutureWarning:\n",
      "\n",
      "suggest_int() got {'step'} as positional arguments but they were expected to be given as keyword arguments.\n",
      "Positional arguments ['self', 'name', 'low', 'high', 'step', 'log'] in suggest_int() have been deprecated since v3.5.0. They will be replaced with the corresponding keyword arguments in v5.0.0, so please use the keyword specification instead. See https://github.com/optuna/optuna/releases/tag/v3.5.0 for details.\n",
      "\n",
      "[I 2025-08-11 10:26:32,615] Trial 44 finished with value: 0.9694835680751174 and parameters: {'n_estimators': 400, 'max_depth': 10, 'learning_rate': 0.19013598009662372, 'colsample_bytree': 0.5612933116965282}. Best is trial 31 with value: 0.9741784037558686.\n",
      "C:\\Users\\Playdata\\AppData\\Local\\Temp\\ipykernel_9840\\1653561151.py:4: FutureWarning:\n",
      "\n",
      "suggest_int() got {'step'} as positional arguments but they were expected to be given as keyword arguments.\n",
      "Positional arguments ['self', 'name', 'low', 'high', 'step', 'log'] in suggest_int() have been deprecated since v3.5.0. They will be replaced with the corresponding keyword arguments in v5.0.0, so please use the keyword specification instead. See https://github.com/optuna/optuna/releases/tag/v3.5.0 for details.\n",
      "\n",
      "[I 2025-08-11 10:26:33,006] Trial 45 finished with value: 0.9647887323943661 and parameters: {'n_estimators': 500, 'max_depth': 8, 'learning_rate': 0.061139958795708216, 'colsample_bytree': 0.5299193090031518}. Best is trial 31 with value: 0.9741784037558686.\n",
      "C:\\Users\\Playdata\\AppData\\Local\\Temp\\ipykernel_9840\\1653561151.py:4: FutureWarning:\n",
      "\n",
      "suggest_int() got {'step'} as positional arguments but they were expected to be given as keyword arguments.\n",
      "Positional arguments ['self', 'name', 'low', 'high', 'step', 'log'] in suggest_int() have been deprecated since v3.5.0. They will be replaced with the corresponding keyword arguments in v5.0.0, so please use the keyword specification instead. See https://github.com/optuna/optuna/releases/tag/v3.5.0 for details.\n",
      "\n",
      "[I 2025-08-11 10:26:33,248] Trial 46 finished with value: 0.960093896713615 and parameters: {'n_estimators': 300, 'max_depth': 9, 'learning_rate': 0.15815279025819007, 'colsample_bytree': 0.9110694289704093}. Best is trial 31 with value: 0.9741784037558686.\n",
      "C:\\Users\\Playdata\\AppData\\Local\\Temp\\ipykernel_9840\\1653561151.py:4: FutureWarning:\n",
      "\n",
      "suggest_int() got {'step'} as positional arguments but they were expected to be given as keyword arguments.\n",
      "Positional arguments ['self', 'name', 'low', 'high', 'step', 'log'] in suggest_int() have been deprecated since v3.5.0. They will be replaced with the corresponding keyword arguments in v5.0.0, so please use the keyword specification instead. See https://github.com/optuna/optuna/releases/tag/v3.5.0 for details.\n",
      "\n",
      "[I 2025-08-11 10:26:33,550] Trial 47 finished with value: 0.9671361502347419 and parameters: {'n_estimators': 500, 'max_depth': 7, 'learning_rate': 0.18018009059411072, 'colsample_bytree': 0.6102541943927421}. Best is trial 31 with value: 0.9741784037558686.\n",
      "C:\\Users\\Playdata\\AppData\\Local\\Temp\\ipykernel_9840\\1653561151.py:4: FutureWarning:\n",
      "\n",
      "suggest_int() got {'step'} as positional arguments but they were expected to be given as keyword arguments.\n",
      "Positional arguments ['self', 'name', 'low', 'high', 'step', 'log'] in suggest_int() have been deprecated since v3.5.0. They will be replaced with the corresponding keyword arguments in v5.0.0, so please use the keyword specification instead. See https://github.com/optuna/optuna/releases/tag/v3.5.0 for details.\n",
      "\n",
      "[I 2025-08-11 10:26:33,681] Trial 48 finished with value: 0.9647887323943661 and parameters: {'n_estimators': 100, 'max_depth': 8, 'learning_rate': 0.13975223312731244, 'colsample_bytree': 0.6499192791068997}. Best is trial 31 with value: 0.9741784037558686.\n",
      "C:\\Users\\Playdata\\AppData\\Local\\Temp\\ipykernel_9840\\1653561151.py:4: FutureWarning:\n",
      "\n",
      "suggest_int() got {'step'} as positional arguments but they were expected to be given as keyword arguments.\n",
      "Positional arguments ['self', 'name', 'low', 'high', 'step', 'log'] in suggest_int() have been deprecated since v3.5.0. They will be replaced with the corresponding keyword arguments in v5.0.0, so please use the keyword specification instead. See https://github.com/optuna/optuna/releases/tag/v3.5.0 for details.\n",
      "\n",
      "[I 2025-08-11 10:26:34,024] Trial 49 finished with value: 0.9694835680751174 and parameters: {'n_estimators': 400, 'max_depth': 9, 'learning_rate': 0.10678439411284069, 'colsample_bytree': 0.5803009983470583}. Best is trial 31 with value: 0.9741784037558686.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'n_estimators': 500, 'max_depth': 7, 'learning_rate': 0.1438440611670294, 'colsample_bytree': 0.5257773175292658}\n",
      "0.9741784037558686\n"
     ]
    }
   ],
   "source": [
    "# 1. 목적 함수\n",
    "def xgb_optuna_objective(trial):\n",
    "    params = {\n",
    "        'n_estimators': trial.suggest_int('n_estimators', 100, 500, 100),\n",
    "        'max_depth': trial.suggest_int('max_depth', 3, 10),\n",
    "        'learning_rate': trial.suggest_float('learning_rate', 0.01, 0.2),\n",
    "        'colsample_bytree': trial.suggest_float('colsample_bytree', 0.5, 1.0)\n",
    "    }\n",
    "    xgb_clf = XGBClassifier(**params)\n",
    "    return cross_val_score(xgb_clf, X_train, y_train, scoring='accuracy', cv=3).mean()\n",
    "\n",
    "# 2. study 객체 생성 -> 최적화\n",
    "study = optuna.create_study(direction='maximize')\n",
    "study.optimize(xgb_optuna_objective, n_trials=50)\n",
    "\n",
    "# 3. 결과 출력\n",
    "print(study.best_params)\n",
    "print(study.best_value)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c36bb54",
   "metadata": {},
   "source": [
    "##### HyperOpt vs Optuna\n",
    "\n",
    "- HyperOpt\n",
    "    - 'n_estimators': np.float64(500.0)\n",
    "    - 'max_dapth': np.float64(6.0)\n",
    "    - 'learning_rate': np.float64(0.16532913013986236)\n",
    "    - 'colsample_bytree': np.float64(0.5010247093957608)\n",
    "\n",
    "- Optuna\n",
    "    - 'n_estimators': 500\n",
    "    - 'max_depth': 7\n",
    "    - 'learning_rate': 0.1438440611670294\n",
    "    - 'colsample_bytree': 0.5257773175292658"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "1f14eb7c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HyperOpt 최적 파라미터 적용\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      0.94      0.94        54\n",
      "           1       0.97      0.97      0.97        89\n",
      "\n",
      "    accuracy                           0.96       143\n",
      "   macro avg       0.96      0.96      0.96       143\n",
      "weighted avg       0.96      0.96      0.96       143\n",
      "\n",
      "Optuna 최적 파라미터 적용\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      0.94      0.94        54\n",
      "           1       0.97      0.97      0.97        89\n",
      "\n",
      "    accuracy                           0.96       143\n",
      "   macro avg       0.96      0.96      0.96       143\n",
      "weighted avg       0.96      0.96      0.96       143\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "\n",
    "xgb_hopt = XGBClassifier(\n",
    "    n_estimators=500,\n",
    "    max_depth=6,\n",
    "    learning_rate=0.17,\n",
    "    colsample_bytree=0.5\n",
    ")\n",
    "\n",
    "xgb_optuna = XGBClassifier(\n",
    "    n_estimators=500,\n",
    "    max_depth=7,\n",
    "    learning_rate=0.14,\n",
    "    colsample_bytree=0.53\n",
    ")\n",
    "\n",
    "xgb_hopt.fit(X_train, y_train)\n",
    "xgb_optuna.fit(X_train, y_train)\n",
    "\n",
    "hopt_pred = xgb_hopt.predict(X_test)\n",
    "optuna_pred = xgb_optuna.predict(X_test)\n",
    "\n",
    "print('HyperOpt 최적 파라미터 적용')\n",
    "print(classification_report(y_test, hopt_pred))\n",
    "print('Optuna 최적 파라미터 적용')\n",
    "print(classification_report(y_test, optuna_pred))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
