{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 학우 보이스 데이터 기반 고민 상담 챗봇\n",
    "##### 데이터 출처 - 정의중님, 최동현님 목소리\n",
    "##### 참고 사이트 - https://github.com/coqui-ai/TTS?tab=readme-ov-file"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 필요 라이브러리 설치"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install dotenv\n",
    "# !pip install openai\n",
    "# !pip install coqui-tts\n",
    "# !pip install hangul_romanize\n",
    "# !pip install pyobjc\n",
    "# !pip install ffmpeg\n",
    "# !pip install coqui-tts\n",
    "# !pip install audio-recorder-streamlit"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 필요 라이브러리 임포트"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv\n",
    "from openai import OpenAI\n",
    "import os\n",
    "\n",
    "from pathlib import Path\n",
    "from TTS.api import TTS\n",
    "import speech_recognition as sr\n",
    "import tempfile, subprocess\n",
    "from pydub import AudioSegment\n",
    "import re\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "load_dotenv()\n",
    "OPENAI_API_KEY = os.getenv('OPENAI_API_KEY')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 메인 함수 정의"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "tts = TTS(model_name=\"tts_models/multilingual/multi-dataset/xtts_v2\")\n",
    "\n",
    "base = Path(\"dataset/wavs\")\n",
    "ref_wavs = [str(base / f\"{i:04}.wav\") for i in range(1, 11)]\n",
    "\n",
    "system_instruction = \"\"\"\n",
    "        당신은 사용자의 고민 해결을 돕는 '고민 상담 봇'이야. 이름은 정의중이고, 다음 원칙을 반드시 지켜줘.\n",
    "\n",
    "        1. 핵심 행동 지침:\n",
    "\n",
    "        경청과 공감: 먼저 판단 없이 사용자의 고민을 듣고, \"그런 고민을 하고 있었구나\"라며 상황 자체를 인정하고 공감한다.\n",
    "\n",
    "        질문을 통한 탐색: \"어떤 점이 가장 힘들어?\", \"네가 진짜 원하는 건 뭐야?\" 와 같은 개방형 질문을 통해, 사용자가 자신의 생각과 감정을 스스로 깊이 들여다보게 한다.\n",
    "\n",
    "        스스로 답 찾기 지원: \"어떤 방법들이 있을 수 있을까?\"라고 질문하며 사용자가 직접 해결의 실마리를 찾도록 돕는다. 정답을 알려주지 않고 사용자의 가능성을 믿고 지지한다.\n",
    "\n",
    "        직접적인 해결책 제시: 사용자가 스스로 찾은 답을 기반으로 더 추가 위로 및 해결책 제시 (\"~하는 게 좋겠어\")\n",
    "\n",
    "        2. 절대 금지:\n",
    "\n",
    "        섣부른 판단, 충고, 평가\n",
    "\n",
    "        다른 사람과의 비교\n",
    "\n",
    "        고민의 경중을 함부로 단정하는 것 (\"그건 별거 아니야\")\n",
    "    \"\"\"\n",
    "\n",
    "def safe_play(seg: AudioSegment):\n",
    "    seg = seg.set_frame_rate(44100).set_channels(1)\n",
    "    with tempfile.NamedTemporaryFile(suffix=\".wav\", delete=False) as f:\n",
    "        seg.export(f.name, format=\"wav\")\n",
    "        subprocess.run([\"afplay\", f.name], check=True)\n",
    "        \n",
    "def worry_man(temperature=0.3):\n",
    "    client = OpenAI()\n",
    "    messages = [{'role': 'system', 'content': system_instruction}]\n",
    "\n",
    "    out_path = Path(\"/Users/woojin/Desktop/SK Networks Family AI Camp_17/SKN-17-Family-AI-Camp/LLM/01_openai_api/practice/JeongUiJung_Answer.wav\")\n",
    "\n",
    "    print(\"고민상담맨 정의중님과 상담이 연결되었습니다. '종료'를 원하면 종료를 입력하세요.\")\n",
    "    sound_1 = AudioSegment.from_mp3(\"/Users/woojin/Desktop/SK Networks Family AI Camp_17/SKN-17-Family-AI-Camp/LLM/01_openai_api/practice/guideline_0.mp3\")\n",
    "    safe_play(sound_1)\n",
    "    \n",
    "    print(\"안녕, 나는 너의 친구 고민상담맨 정의중이야.\")\n",
    "    sound_2 = AudioSegment.from_wav(\"/Users/woojin/Desktop/SK Networks Family AI Camp_17/SKN-17-Family-AI-Camp/LLM/01_openai_api/practice/guideline_1.wav\")\n",
    "    safe_play(sound_2)\n",
    "    \n",
    "    print(\"오늘 무슨 고민이 있어서 날 찾은 거야?\")\n",
    "    sound_3 = AudioSegment.from_wav(\"/Users/woojin/Desktop/SK Networks Family AI Camp_17/SKN-17-Family-AI-Camp/LLM/01_openai_api/practice/guideline_2.wav\")\n",
    "    safe_play(sound_3)\n",
    "\n",
    "    while True:\n",
    "        recognizer = sr.Recognizer()\n",
    "        \n",
    "        with sr.Microphone() as source:\n",
    "            audio = recognizer.listen(source, timeout=5)\n",
    "            user_input = recognizer.recognize_google(audio, language='ko-KR')\n",
    "            \n",
    "            if user_input == '종료':\n",
    "                print('정의중: 오늘 이야기 나눠줘서 고마워. 여기서 마무리할게.')\n",
    "                sound_4 = AudioSegment.from_mp3(\"/Users/woojin/Desktop/SK Networks Family AI Camp_17/SKN-17-Family-AI-Camp/LLM/01_openai_api/practice/guideline_3.wav\")\n",
    "                safe_play(sound_4)\n",
    "                break\n",
    "            \n",
    "            if not user_input:\n",
    "                continue\n",
    "\n",
    "        messages.append({'role': 'user', 'content': f'고민: {user_input}'})\n",
    "\n",
    "        response = client.chat.completions.create(\n",
    "            model='gpt-4o',\n",
    "            messages=messages,\n",
    "            temperature=temperature,\n",
    "            max_tokens=2048,\n",
    "            top_p=1,\n",
    "            frequency_penalty=1,\n",
    "            presence_penalty=1\n",
    "        )\n",
    "\n",
    "        assistant_text = response.choices[0].message.content\n",
    "\n",
    "        sentences = [s.strip() for s in re.split(r'(?<=[.!?。！？])\\s+', assistant_text) if s.strip()]\n",
    "        if not sentences:\n",
    "            sentences = [assistant_text.strip()]\n",
    "\n",
    "        full_text = \" \".join(sentences)\n",
    "        tts.tts_to_file(\n",
    "            text=full_text,\n",
    "            speaker_wav=ref_wavs,\n",
    "            language=\"ko\",\n",
    "            file_path=str(out_path)\n",
    "        )\n",
    "\n",
    "        audio = AudioSegment.from_wav(str(out_path))\n",
    "        safe_play(audio)\n",
    "\n",
    "        print(f'나: {user_input}\\n')\n",
    "        print(f'정의중: {assistant_text}\\n')\n",
    "        messages.append({'role': 'assistant', 'content': assistant_text})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 실행"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "worry_man(temperature=0.3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "llm_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
