{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "830da992",
   "metadata": {},
   "source": [
    "# n-gram 언어 모델링"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "05227122",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "from nltk.util import ngrams\n",
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0167bde",
   "metadata": {},
   "outputs": [],
   "source": [
    "text = \"오늘은 날씨가 좋다. 오늘은 기분이 좋다. 오늘은 일이 많다. 오늘은 사람이 많다. 오늘은 날씨가 맑다.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c81cbb34",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokens = nltk.word_tokenize(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "16ce1e3e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Counter({('.', '오늘은'): 4,\n",
       "         ('오늘은', '날씨가'): 2,\n",
       "         ('좋다', '.'): 2,\n",
       "         ('많다', '.'): 2,\n",
       "         ('날씨가', '좋다'): 1,\n",
       "         ('오늘은', '기분이'): 1,\n",
       "         ('기분이', '좋다'): 1,\n",
       "         ('오늘은', '일이'): 1,\n",
       "         ('일이', '많다'): 1,\n",
       "         ('오늘은', '사람이'): 1,\n",
       "         ('사람이', '많다'): 1,\n",
       "         ('날씨가', '맑다'): 1,\n",
       "         ('맑다', '.'): 1})"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 1-gram, 2-gram\n",
    "unigram = tokens\n",
    "bigram = list(ngrams(tokens, 2))\n",
    "\n",
    "unigram_freq = Counter(unigram)\n",
    "bigram_freq = Counter(bigram)\n",
    "bigram_freq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05e34ed1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "P(날씨가|오늘은) = 0.400\n",
      "P(좋다|날씨가) = 0.500\n",
      "P(.|좋다) = 1.000\n",
      "P(오늘은|.) = 0.800\n",
      "P(기분이|오늘은) = 0.200\n",
      "P(좋다|기분이) = 1.000\n",
      "P(일이|오늘은) = 0.200\n",
      "P(많다|일이) = 1.000\n",
      "P(.|많다) = 1.000\n",
      "P(사람이|오늘은) = 0.200\n",
      "P(많다|사람이) = 1.000\n",
      "P(맑다|날씨가) = 0.500\n",
      "P(.|맑다) = 1.000\n"
     ]
    }
   ],
   "source": [
    "for (w1, w2), freq in bigram_freq.items():\n",
    "    prob = freq / unigram_freq[w1]      # 조건부 확률 계산 (w1 뒤에 w2가 올 확률)\n",
    "    print(f'P({w2}|{w1}) = {prob:.3f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac3fbda4",
   "metadata": {},
   "source": [
    "### Perplexity 계산"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1d0a5cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "\n",
    "# Perplexity의 평가 기준\n",
    "# - 모델이 테스트 데이터에서 얼마나 적은 불확실성을 가지며 다음 단어를 잘 예측하는가\n",
    "def compute_bigram_perplexity(test_text, unigram_freq, bigram_freq):\n",
    "    test_tokens = nltk.word_tokenize(test_text)\n",
    "    test_bigrams = list(ngrams(test_tokens, 2))\n",
    "\n",
    "    log_prob_sum = 0\n",
    "    N = len(test_bigrams)\n",
    "\n",
    "    for bigram in test_bigrams:\n",
    "        w1, w2 = bigram\n",
    "        prob = bigram_freq.get(bigram, 0) / unigram_freq.get(w1, 1)\n",
    "        if prob == 0:\n",
    "            prob = 1e-10\n",
    "        log_prob_sum += math.log2(prob)\n",
    "\n",
    "    cross_entropy = -log_prob_sum / N\n",
    "    perplexity = math.pow(2, cross_entropy)\n",
    "\n",
    "    return perplexity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3676ce7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_text = \"자연어 처리는 재미있다. 자연어 처리는 어렵지만 도전하고 싶다. 오늘은 날씨가 좋다.\"\n",
    "\n",
    "train_tokens = nltk.word_tokenize(train_text)\n",
    "\n",
    "unigram = train_tokens\n",
    "bigrams = list(ngrams(train_tokens, 2))\n",
    "\n",
    "unigram_freq = Counter(unigram)\n",
    "bigrams_freq = Counter(bigrams)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a10c9213",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "자연어 처리는 재미있다. perplexity: 1.2599210498948732\n",
      "자연어 처리는 어렵지만 도전하고 싶다. perplexity: 1.148698354997035\n",
      "오늘은 날씨가 좋다. perplexity: 1.0\n",
      "기계 번역은 어렵다. perplexity: 10000000000.000008\n",
      "자연어 처리에 도전하고 싶다. perplexity: 100000.00000000003\n",
      "오늘 날씨가 흐리다. perplexity: 10000000000.000008\n"
     ]
    }
   ],
   "source": [
    "test_sentences = [\n",
    "    \"자연어 처리는 재미있다.\",\n",
    "    \"자연어 처리는 어렵지만 도전하고 싶다.\",\n",
    "    \"오늘은 날씨가 좋다.\",\n",
    "    \"기계 번역은 어렵다.\",\n",
    "    \"자연어 처리에 도전하고 싶다.\",\n",
    "    \"오늘 날씨가 흐리다.\"\n",
    "]\n",
    "\n",
    "for sentence in test_sentences:\n",
    "    pp = compute_bigram_perplexity(sentence, unigram_freq, bigrams_freq)\n",
    "    print(sentence, \"perplexity:\", pp)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nlp_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
